{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "ML Thesis  \n",
    "Gwen Hirsch  \n",
    "2022\n",
    "\n",
    "# ACD Code (notebook version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\base2\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "#my imports\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import networkx as nx\n",
    "# from datetime import datetime\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import cm\n",
    "from matplotlib import colors\n",
    "import matplotlib.ticker as mticker\n",
    "import matplotlib.dates as mdates\n",
    "import pytz\n",
    "\n",
    "from scipy import stats\n",
    "from statsmodels.tsa.stattools import grangercausalitytests\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "import gc\n",
    "pd.options.display.max_rows = 4000\n",
    "pd.options.display.max_columns = 4000\n",
    "\n",
    "#acd imports\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "import time\n",
    "\n",
    "import argparse\n",
    "\n",
    "import os\n",
    "import math\n",
    "import itertools\n",
    "\n",
    "from torch.utils.data.dataset import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.distributions as tdist\n",
    "from torch.autograd import Variable\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "from abc import abstractmethod"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## ACD Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### -------------------- model files --------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### utils.py\n",
    "\n",
    "from model  \n",
    "called in train.py main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import torch\n",
    "# import torch.nn.functional as F\n",
    "# import torch.distributions as tdist\n",
    "# from torch.autograd import Variable\n",
    "# from sklearn.metrics import roc_auc_score\n",
    "# from collections import defaultdict\n",
    "\n",
    "\n",
    "def my_softmax(input, axis=1):\n",
    "    \"\"\"Based on https://github.com/ethanfetaya/NRI (MIT License).\"\"\"\n",
    "    trans_input = input.transpose(axis, 0).contiguous()\n",
    "    soft_max_1d = F.softmax(trans_input, dim=0)\n",
    "    return soft_max_1d.transpose(axis, 0)\n",
    "\n",
    "\n",
    "def sample_gumbel(shape, eps=1e-10):\n",
    "    \"\"\"\n",
    "    NOTE: Stolen from https://github.com/pytorch/pytorch/pull/3341/commits/327fcfed4c44c62b208f750058d14d4dc1b9a9d3\n",
    "\n",
    "    Sample from Gumbel(0, 1)\n",
    "\n",
    "    based on\n",
    "    https://github.com/ericjang/gumbel-softmax/blob/3c8584924603869e90ca74ac20a6a03d99a91ef9/Categorical%20VAE.ipynb ,\n",
    "    (MIT license)\n",
    "    \"\"\"\n",
    "    U = torch.rand(shape).float()\n",
    "    return -torch.log(eps - torch.log(U + eps))\n",
    "\n",
    "\n",
    "def gumbel_softmax_sample(logits, tau=1, eps=1e-10):\n",
    "    \"\"\"\n",
    "    NOTE: Stolen from https://github.com/pytorch/pytorch/pull/3341/commits/327fcfed4c44c62b208f750058d14d4dc1b9a9d3\n",
    "\n",
    "    Draw a sample from the Gumbel-Softmax distribution\n",
    "\n",
    "    based on\n",
    "    https://github.com/ericjang/gumbel-softmax/blob/3c8584924603869e90ca74ac20a6a03d99a91ef9/Categorical%20VAE.ipynb\n",
    "    (MIT license)\n",
    "    \"\"\"\n",
    "    gumbel_noise = sample_gumbel(logits.size(), eps=eps)\n",
    "    if logits.is_cuda:\n",
    "        gumbel_noise = gumbel_noise.cuda()\n",
    "    y = logits + Variable(gumbel_noise)\n",
    "    return my_softmax(y / tau, axis=-1)\n",
    "\n",
    "\n",
    "def gumbel_softmax(logits, tau=1, hard=False, eps=1e-10):\n",
    "    \"\"\"\n",
    "    NOTE: Stolen from https://github.com/pytorch/pytorch/pull/3341/commits/327fcfed4c44c62b208f750058d14d4dc1b9a9d3\n",
    "\n",
    "    Sample from the Gumbel-Softmax distribution and optionally discretize.\n",
    "    Args:\n",
    "      logits: [batch_size, n_class] unnormalized log-probs\n",
    "      tau: non-negative scalar temperature\n",
    "      hard: if True, take argmax, but differentiate w.r.t. soft sample y\n",
    "    Returns:\n",
    "      [batch_size, n_class] sample from the Gumbel-Softmax distribution.\n",
    "      If hard=True, then the returned sample will be one-hot, otherwise it will\n",
    "      be a probability distribution that sums to 1 across classes\n",
    "\n",
    "    Constraints:\n",
    "    - this implementation only works on batch_size x num_features tensor for now\n",
    "\n",
    "    based on\n",
    "    https://github.com/ericjang/gumbel-softmax/blob/3c8584924603869e90ca74ac20a6a03d99a91ef9/Categorical%20VAE.ipynb ,\n",
    "    (MIT license)\n",
    "    \"\"\"\n",
    "    y_soft = gumbel_softmax_sample(logits, tau=tau, eps=eps)\n",
    "    if hard:\n",
    "        shape = logits.size()\n",
    "        _, k = y_soft.data.max(-1)\n",
    "        # this bit is based on\n",
    "        # https://discuss.pytorch.org/t/stop-gradients-for-st-gumbel-softmax/530/5\n",
    "        y_hard = torch.zeros(*shape)\n",
    "        if y_soft.is_cuda:\n",
    "            y_hard = y_hard.cuda()\n",
    "        y_hard = y_hard.zero_().scatter_(-1, k.view(shape[:-1] + (1,)), 1.0)\n",
    "        # this cool bit of code achieves two things:\n",
    "        # - makes the output value exactly one-hot (since we add then\n",
    "        #   subtract y_soft value)\n",
    "        # - makes the gradient equal to y_soft gradient (since we strip\n",
    "        #   all other gradients)\n",
    "        y = Variable(y_hard - y_soft.data) + y_soft\n",
    "    else:\n",
    "        y = y_soft\n",
    "    return y\n",
    "\n",
    "\n",
    "def encode_onehot(labels):\n",
    "    \"\"\"Based on https://github.com/ethanfetaya/NRI (MIT License).\"\"\"\n",
    "    classes = set(labels)\n",
    "    classes_dict = {c: np.identity(len(classes))[i, :] for i, c in enumerate(classes)}\n",
    "    labels_onehot = np.array(list(map(classes_dict.get, labels)), dtype=np.int32)\n",
    "    return labels_onehot\n",
    "\n",
    "\n",
    "def kl_categorical(preds, log_prior, num_atoms, eps=1e-16):\n",
    "    \"\"\"Based on https://github.com/ethanfetaya/NRI (MIT License).\"\"\"\n",
    "    kl_div = preds * (torch.log(preds + eps) - log_prior)\n",
    "    return kl_div.sum() / (num_atoms * preds.size(0))\n",
    "\n",
    "\n",
    "def kl_categorical_uniform(\n",
    "    preds, num_atoms, num_edge_types, add_const=False, eps=1e-16\n",
    "):\n",
    "    \"\"\"Based on https://github.com/ethanfetaya/NRI (MIT License).\"\"\"\n",
    "    kl_div = preds * (torch.log(preds + eps))\n",
    "    if add_const:\n",
    "        const = np.log(num_edge_types)\n",
    "        kl_div += const\n",
    "    return kl_div.sum() / (num_atoms * preds.size(0))\n",
    "\n",
    "\n",
    "def nll_gaussian(preds, target, variance, add_const=False):\n",
    "    \"\"\"Based on https://github.com/ethanfetaya/NRI (MIT License).\"\"\"\n",
    "    neg_log_p = (preds - target) ** 2 / (2 * variance)\n",
    "    if add_const:\n",
    "        const = 0.5 * np.log(2 * np.pi * variance)\n",
    "        neg_log_p += const\n",
    "    return neg_log_p.sum() / (target.size(0) * target.size(1))\n",
    "\n",
    "\n",
    "def edge_accuracy(preds, target, binary=True):\n",
    "    \"\"\"Based on https://github.com/ethanfetaya/NRI (MIT License).\"\"\"\n",
    "    _, preds = preds.max(-1)\n",
    "    if binary:\n",
    "        preds = (preds >= 1).long()\n",
    "    correct = preds.float().data.eq(target.float().data.view_as(preds)).cpu().sum()\n",
    "    return float(correct) / (target.size(0) * target.size(1))\n",
    "\n",
    "\n",
    "def calc_auroc(pred_edges, GT_edges):\n",
    "    pred_edges = 1 - pred_edges[:, :, 0]\n",
    "    return roc_auc_score(\n",
    "        GT_edges.cpu().detach().flatten(),\n",
    "        pred_edges.cpu().detach().flatten(),  # [:, :, 1]\n",
    "    )\n",
    "\n",
    "\n",
    "def kl_latent(args, prob, log_prior, predicted_atoms):\n",
    "    if args.prior != 1:\n",
    "        return kl_categorical(prob, log_prior, predicted_atoms)\n",
    "    else:\n",
    "        return kl_categorical_uniform(prob, predicted_atoms, args.edge_types)\n",
    "\n",
    "\n",
    "def get_observed_relations_idx(num_atoms):\n",
    "    length = (num_atoms ** 2) - num_atoms * 2\n",
    "    remove_idx = np.arange(length)[:: num_atoms - 1][1:] - 1\n",
    "    idx = np.delete(np.linspace(0, length - 1, length), remove_idx)\n",
    "    return idx\n",
    "\n",
    "\n",
    "def mse_per_sample(output, target):\n",
    "    mse_per_sample = F.mse_loss(output, target, reduction=\"none\")\n",
    "    mse_per_sample = torch.mean(mse_per_sample, dim=(1, 2, 3)).cpu().data.numpy()\n",
    "    return mse_per_sample\n",
    "\n",
    "\n",
    "def edge_accuracy_per_sample(preds, target):\n",
    "    _, preds = preds.max(-1)\n",
    "    acc = torch.sum(torch.eq(preds, target), dim=1, dtype=torch.float64,) / preds.size(\n",
    "        1\n",
    "    )\n",
    "    return acc.cpu().data.numpy()\n",
    "\n",
    "\n",
    "def auroc_per_num_influenced(preds, target, total_num_influenced):\n",
    "    preds = 1 - preds[:, :, 0]\n",
    "    preds = preds.cpu().detach().numpy()\n",
    "    target = target.cpu().detach().numpy()\n",
    "\n",
    "    preds_per_num_influenced = defaultdict(list)\n",
    "    targets_per_num_influenced = defaultdict(list)\n",
    "\n",
    "    for idx, k in enumerate(total_num_influenced):\n",
    "        preds_per_num_influenced[k].append(preds[idx])\n",
    "        targets_per_num_influenced[k].append(target[idx])\n",
    "\n",
    "    auc_per_num_influenced = np.zeros((max(preds_per_num_influenced) + 1))\n",
    "    for num_influenced, elem in preds_per_num_influenced.items():\n",
    "        auc_per_num_influenced[num_influenced] = roc_auc_score(\n",
    "            np.vstack(targets_per_num_influenced[num_influenced]).flatten(),\n",
    "            np.vstack(elem).flatten(),\n",
    "        )\n",
    "\n",
    "    return auc_per_num_influenced\n",
    "\n",
    "\n",
    "def edge_accuracy_observed(preds, target, num_atoms=5):\n",
    "    idx = get_observed_relations_idx(num_atoms)\n",
    "    _, preds = preds.max(-1)\n",
    "    correct = preds[:, idx].eq(target[:, idx]).cpu().sum()\n",
    "    return float(correct) / (target.size(0) * len(idx))\n",
    "\n",
    "\n",
    "def calc_auroc_observed(pred_edges, GT_edges, num_atoms=5):\n",
    "    idx = get_observed_relations_idx(num_atoms)\n",
    "    pred_edges = pred_edges[:, :, 1]\n",
    "    return roc_auc_score(\n",
    "        GT_edges[:, idx].cpu().detach().flatten(),\n",
    "        pred_edges[:, idx].cpu().detach().flatten(),\n",
    "    )\n",
    "\n",
    "\n",
    "def kl_normal_reverse(prior_mean, prior_std, mean, log_std, downscale_factor=1):\n",
    "    std = softplus(log_std) * downscale_factor\n",
    "    d = tdist.Normal(mean, std)\n",
    "    prior_normal = tdist.Normal(prior_mean, prior_std)\n",
    "    return tdist.kl.kl_divergence(d, prior_normal).mean()\n",
    "\n",
    "\n",
    "def sample_normal_from_latents(latent_means, latent_logsigmas, downscale_factor=1):\n",
    "    latent_sigmas = softplus(latent_logsigmas) * downscale_factor\n",
    "    eps = torch.randn_like(latent_sigmas)\n",
    "    latents = latent_means + eps * latent_sigmas\n",
    "    return latents\n",
    "\n",
    "\n",
    "def softplus(x):\n",
    "    return torch.log(1.0 + torch.exp(x))\n",
    "\n",
    "\n",
    "def distribute_over_GPUs(args, model, num_GPU=None):\n",
    "    ## distribute over GPUs\n",
    "    if args.device.type != \"cpu\":\n",
    "        if num_GPU is None:\n",
    "            model = torch.nn.DataParallel(model)\n",
    "            num_GPU = torch.cuda.device_count()\n",
    "            args.batch_size_multiGPU = args.batch_size * num_GPU\n",
    "        else:\n",
    "            assert (\n",
    "                num_GPU <= torch.cuda.device_count()\n",
    "            ), \"You cant use more GPUs than you have.\"\n",
    "            model = torch.nn.DataParallel(model, device_ids=list(range(num_GPU)))\n",
    "            args.batch_size_multiGPU = args.batch_size * num_GPU\n",
    "    else:\n",
    "        model = torch.nn.DataParallel(model)\n",
    "        args.batch_size_multiGPU = args.batch_size\n",
    "\n",
    "    model = model.to(args.device)\n",
    "\n",
    "    return model, num_GPU\n",
    "\n",
    "\n",
    "def create_rel_rec_send(args, num_atoms):\n",
    "    \"\"\"Based on https://github.com/ethanfetaya/NRI (MIT License).\"\"\"\n",
    "    if args.unobserved > 0 and args.model_unobserved == 1:\n",
    "        num_atoms -= args.unobserved\n",
    "\n",
    "    # Generate off-diagonal interaction graph\n",
    "    off_diag = np.ones([num_atoms, num_atoms]) - np.eye(num_atoms)\n",
    "\n",
    "    rel_rec = np.array(encode_onehot(np.where(off_diag)[0]), dtype=np.float32)\n",
    "    rel_send = np.array(encode_onehot(np.where(off_diag)[1]), dtype=np.float32)\n",
    "    rel_rec = torch.FloatTensor(rel_rec)\n",
    "    rel_send = torch.FloatTensor(rel_send)\n",
    "\n",
    "    if args.cuda:\n",
    "        rel_rec = rel_rec.cuda()\n",
    "        rel_send = rel_send.cuda()\n",
    "\n",
    "    return rel_rec, rel_send\n",
    "\n",
    "\n",
    "def append_losses(losses_list, losses):\n",
    "    for loss, value in losses.items():\n",
    "        if type(value) == float:\n",
    "            losses_list[loss].append(value)\n",
    "        elif type(value) == defaultdict:\n",
    "            if losses_list[loss] == []:\n",
    "                losses_list[loss] = defaultdict(list)\n",
    "            for idx, elem in value.items():\n",
    "                losses_list[loss][idx].append(elem)\n",
    "        else:\n",
    "            losses_list[loss].append(value.item())\n",
    "    return losses_list\n",
    "\n",
    "\n",
    "def average_listdict(listdict, num_atoms):\n",
    "    average_list = [None] * num_atoms\n",
    "    for k, v in listdict.items():\n",
    "        average_list[k] = sum(v) / len(v)\n",
    "    return average_list\n",
    "\n",
    "\n",
    "# Latent Temperature Experiment utils\n",
    "def get_uniform_parameters_from_latents(latent_params):\n",
    "    n_params = latent_params.shape[1]\n",
    "    logit_means = latent_params[:, : n_params // 2]\n",
    "    logit_widths = latent_params[:, n_params // 2 :]\n",
    "    means = sigmoid(logit_means)\n",
    "    widths = sigmoid(logit_widths)\n",
    "    mins, _ = torch.min(torch.cat([means, 1 - means], dim=1), dim=1, keepdim=True)\n",
    "    widths = mins * widths\n",
    "    return means, widths\n",
    "\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1.0 / (1.0 + torch.exp(-x))\n",
    "\n",
    "\n",
    "def sample_uniform_from_latents(latent_means, latent_width):\n",
    "    latent_dist = tdist.uniform.Uniform(\n",
    "        latent_means - latent_width, latent_means + latent_width\n",
    "    )\n",
    "    latents = latent_dist.rsample()\n",
    "    return latents\n",
    "\n",
    "\n",
    "def get_categorical_temperature_prior(mid, num_cats, to_torch=True, to_cuda=True):\n",
    "    categories = [mid * (2.0 ** c) for c in np.arange(num_cats) - (num_cats // 2)]\n",
    "    if to_torch:\n",
    "        categories = torch.Tensor(categories)\n",
    "    if to_cuda:\n",
    "        categories = categories.cuda()\n",
    "    return categories\n",
    "\n",
    "\n",
    "def kl_uniform(latent_width, prior_width):\n",
    "    eps = 1e-8\n",
    "    kl = torch.log(prior_width / (latent_width + eps))\n",
    "    return kl.mean()\n",
    "\n",
    "\n",
    "def get_uniform_logprobs(inferred_mu, inferred_width, temperatures):\n",
    "    latent_dist = tdist.uniform.Uniform(\n",
    "        inferred_mu - inferred_width, inferred_mu + inferred_width\n",
    "    )\n",
    "    cdf = latent_dist.cdf(temperatures)\n",
    "    log_prob_default = latent_dist.log_prob(inferred_mu)\n",
    "    probs = torch.where(\n",
    "        cdf * (1 - cdf) > 0.0, log_prob_default, torch.full(cdf.shape, -8).cuda()\n",
    "    )\n",
    "    return probs.mean()\n",
    "\n",
    "\n",
    "def get_preds_from_uniform(inferred_mu, inferred_width, categorical_temperature_prior):\n",
    "    categorical_temperature_prior = torch.reshape(\n",
    "        categorical_temperature_prior, [1, -1]\n",
    "    )\n",
    "    preds = (\n",
    "        (categorical_temperature_prior > inferred_mu - inferred_width)\n",
    "        * (categorical_temperature_prior < inferred_mu + inferred_width)\n",
    "    ).double()\n",
    "    return preds\n",
    "\n",
    "\n",
    "def get_correlation(a, b):\n",
    "    numerator = torch.sum((a - a.mean()) * (b - b.mean()))\n",
    "    denominator = torch.sqrt(torch.sum((a - a.mean()) ** 2)) * torch.sqrt(\n",
    "        torch.sum((b - b.mean()) ** 2)\n",
    "    )\n",
    "    return numerator / denominator\n",
    "\n",
    "\n",
    "def get_offdiag_indices(num_nodes):\n",
    "    \"\"\"Based on https://github.com/ethanfetaya/NRI (MIT License).\"\"\"\n",
    "    ones = torch.ones(num_nodes, num_nodes)\n",
    "    eye = torch.eye(num_nodes, num_nodes)\n",
    "    offdiag_indices = (ones - eye).nonzero().t()\n",
    "    offdiag_indices = offdiag_indices[0] * num_nodes + offdiag_indices[1]\n",
    "    return offdiag_indices\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### utils_unobserved.py\n",
    "\n",
    "from model  \n",
    "called in "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn.functional as F\n",
    "# from collections import defaultdict\n",
    "\n",
    "# from model import utils\n",
    "\n",
    "\n",
    "def remove_unobserved(args, data, mask_idx):\n",
    "    data = torch.cat(\n",
    "        (data[:, :mask_idx, :, :], data[:, mask_idx + args.unobserved :, :, :],), dim=1,\n",
    "    )\n",
    "    return data\n",
    "\n",
    "\n",
    "def baseline_mean_imputation(args, data_encoder, mask_idx):\n",
    "    target_unobserved = data_encoder[:, mask_idx, :, :]\n",
    "    data_encoder = remove_unobserved(args, data_encoder, mask_idx)\n",
    "\n",
    "    unobserved = torch.mean(data_encoder, dim=1).unsqueeze(1)\n",
    "\n",
    "    mse_unobserved = F.mse_loss(\n",
    "        torch.squeeze(unobserved), torch.squeeze(target_unobserved)\n",
    "    )\n",
    "\n",
    "    data_encoder = torch.cat(\n",
    "        (data_encoder[:, :mask_idx, :], unobserved, data_encoder[:, mask_idx:, :],),\n",
    "        dim=1,\n",
    "    )\n",
    "\n",
    "    return data_encoder, unobserved, mse_unobserved\n",
    "\n",
    "\n",
    "def baseline_remove_unobserved(\n",
    "    args, data_encoder, data_decoder, mask_idx, relations, predicted_atoms\n",
    "):\n",
    "    data_encoder = remove_unobserved(args, data_encoder, mask_idx)\n",
    "    data_decoder = remove_unobserved(args, data_decoder, mask_idx)\n",
    "\n",
    "    predicted_atoms -= args.unobserved\n",
    "    observed_relations_idx = get_observed_relations_idx(args.num_atoms)\n",
    "    relations = relations[:, observed_relations_idx]\n",
    "\n",
    "    return data_encoder, data_decoder, predicted_atoms, relations\n",
    "\n",
    "\n",
    "def add_unobserved_to_data(args, data, unobserved, mask_idx, diff_data_enc_dec):\n",
    "    if diff_data_enc_dec:\n",
    "        data = torch.cat(\n",
    "            (\n",
    "                data[:, :mask_idx, :],\n",
    "                torch.unsqueeze(unobserved[:, :, -1, :], 2).repeat(\n",
    "                    1, 1, args.timesteps, 1\n",
    "                ),  # start predicting unobserved path from last point predicted\n",
    "                data[:, mask_idx + 1 :, :],\n",
    "            ),\n",
    "            dim=1,\n",
    "        )\n",
    "    else:\n",
    "        data = torch.cat(\n",
    "            (data[:, :mask_idx, :], unobserved, data[:, mask_idx + 1 :, :],), dim=1,\n",
    "        )\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def calc_mse_observed(args, output, target, mask_idx):\n",
    "    output_observed = remove_unobserved(args, output, mask_idx)\n",
    "    target_observed = remove_unobserved(args, target, mask_idx)\n",
    "    return F.mse_loss(output_observed, target_observed)\n",
    "\n",
    "\n",
    "def calc_performance_per_num_influenced(args, relations, output, target, logits, prob, mask_idx, losses):\n",
    "    if args.model_unobserved == 1:\n",
    "        num_atoms = args.num_atoms - args.unobserved\n",
    "    else:\n",
    "        num_atoms = args.num_atoms\n",
    "\n",
    "    influenced_idx_relations = list(\n",
    "        range(num_atoms - 2, num_atoms ** 2, num_atoms - 1)\n",
    "    )[: num_atoms - 1]\n",
    "    influenced_idx = relations[:, influenced_idx_relations]\n",
    "\n",
    "    ## calculate performance based on how many particles are influenced by unobserved one\n",
    "    total_num_influenced = torch.sum(influenced_idx, 1).tolist()\n",
    "    if args.model_unobserved != 1 and args.unobserved > 0:\n",
    "        observed_idx = get_observed_relations_idx(args.num_atoms).astype(int)\n",
    "        acc_per_sample = edge_accuracy_per_sample(logits[:, observed_idx, :], relations[:, observed_idx])\n",
    "\n",
    "        output_observed = remove_unobserved(args, output, mask_idx)\n",
    "        target_observed = remove_unobserved(args, target, mask_idx)\n",
    "        mse_per_sample = mse_per_sample(output_observed, target_observed)\n",
    "\n",
    "        auroc_per_num_infl = auroc_per_num_influenced(prob[:, observed_idx, :], relations[:, observed_idx], total_num_influenced)\n",
    "    else:\n",
    "        acc_per_sample = edge_accuracy_per_sample(logits, relations)\n",
    "        mse_per_sample = mse_per_sample(output, target)\n",
    "        auroc_per_num_infl= auroc_per_num_influenced(prob, relations, total_num_influenced)\n",
    "\n",
    "    if losses[\"acc_per_num_influenced\"] == 0:\n",
    "        losses[\"acc_per_num_influenced\"] = defaultdict(list)\n",
    "        losses[\"mse_per_num_influenced\"] = defaultdict(list)\n",
    "        losses[\"auroc_per_num_influenced\"] = defaultdict(list)\n",
    "\n",
    "    for idx, k in enumerate(total_num_influenced):\n",
    "        losses[\"acc_per_num_influenced\"][k].append(acc_per_sample[idx])\n",
    "        losses[\"mse_per_num_influenced\"][k].append(mse_per_sample[idx])\n",
    "\n",
    "    for idx, elem in enumerate(auroc_per_num_infl):\n",
    "        losses[\"auroc_per_num_influenced\"][idx].append(elem)\n",
    "\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### model_loader.py\n",
    "\n",
    "from model  \n",
    "called in train.py main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# import torch\n",
    "# import torch.optim as optim\n",
    "# from torch.optim import lr_scheduler\n",
    "\n",
    "# from model.modules import *\n",
    "# from model.MLPEncoder import MLPEncoder\n",
    "# from model.CNNEncoder import CNNEncoder\n",
    "# from model.MLPEncoderUnobserved import MLPEncoderUnobserved\n",
    "# from model.EncoderGlobalTemp import CNNEncoderGlobalTemp\n",
    "\n",
    "# from model.MLPDecoder import MLPDecoder\n",
    "# from model.RNNDecoder import RNNDecoder\n",
    "# from model.SimulationDecoder import SimulationDecoder\n",
    "# from model.DecoderGlobalTemp import MLPDecoderGlobalTemp, SimulationDecoderGlobalTemp\n",
    "\n",
    "# from model import utils\n",
    "\n",
    "\n",
    "def load_distribution(args):\n",
    "    edge_probs = torch.randn(\n",
    "        torch.Size([args.num_atoms ** 2 - args.num_atoms, args.edge_types]),\n",
    "        device=args.device.type,\n",
    "        requires_grad=True,\n",
    "    )\n",
    "    return edge_probs\n",
    "\n",
    "\n",
    "def load_encoder(args):\n",
    "    if args.global_temp:\n",
    "        encoder = CNNEncoderGlobalTemp(\n",
    "            args,\n",
    "            args.dims,\n",
    "            args.encoder_hidden,\n",
    "            args.edge_types,\n",
    "            args.encoder_dropout,\n",
    "            args.factor,\n",
    "        )\n",
    "    elif args.unobserved > 0 and args.model_unobserved == 0:\n",
    "        encoder = MLPEncoderUnobserved(\n",
    "            args,\n",
    "            args.timesteps * args.dims,\n",
    "            args.encoder_hidden,\n",
    "            args.edge_types,\n",
    "            do_prob=args.encoder_dropout,\n",
    "            factor=args.factor,\n",
    "        )\n",
    "    else:\n",
    "        if args.encoder == \"mlp\":\n",
    "            encoder = MLPEncoder(\n",
    "                args,\n",
    "                args.timesteps * args.dims,\n",
    "                args.encoder_hidden,\n",
    "                args.edge_types,\n",
    "                do_prob=args.encoder_dropout,\n",
    "                factor=args.factor,\n",
    "            )\n",
    "        elif args.encoder == \"cnn\":\n",
    "            encoder = CNNEncoder(\n",
    "                args,\n",
    "                args.dims,\n",
    "                args.encoder_hidden,\n",
    "                args.edge_types,\n",
    "                args.encoder_dropout,\n",
    "                args.factor,\n",
    "            )\n",
    "\n",
    "    encoder, num_GPU = distribute_over_GPUs(args, encoder, num_GPU=args.num_GPU)\n",
    "    if args.load_folder:\n",
    "        print(\"Loading model file\")\n",
    "        args.encoder_file = os.path.join(args.load_folder, \"encoder.pt\")\n",
    "        encoder.load_state_dict(torch.load(args.encoder_file, map_location=args.device))\n",
    "\n",
    "    return encoder\n",
    "\n",
    "\n",
    "def load_decoder(args, loc_max, loc_min, vel_max, vel_min):\n",
    "    if args.global_temp:\n",
    "        if args.decoder == \"mlp\":\n",
    "            decoder = MLPDecoderGlobalTemp(\n",
    "                n_in_node=args.dims,\n",
    "                edge_types=args.edge_types,\n",
    "                msg_hid=args.decoder_hidden,\n",
    "                msg_out=args.decoder_hidden,\n",
    "                n_hid=args.decoder_hidden,\n",
    "                do_prob=args.decoder_dropout,\n",
    "                skip_first=args.skip_first,\n",
    "                latent_dim=args.latent_dim,\n",
    "            )\n",
    "        elif args.decoder == \"sim\":\n",
    "            decoder = SimulationDecoderGlobalTemp(\n",
    "                loc_max, loc_min, vel_max, vel_min, args.suffix\n",
    "            )\n",
    "    else:\n",
    "        if args.decoder == \"mlp\":\n",
    "            decoder = MLPDecoder(\n",
    "                args,\n",
    "                n_in_node=args.dims,\n",
    "                edge_types=args.edge_types,\n",
    "                msg_hid=args.decoder_hidden,\n",
    "                msg_out=args.decoder_hidden,\n",
    "                n_hid=args.decoder_hidden,\n",
    "                do_prob=args.decoder_dropout,\n",
    "                skip_first=args.skip_first,\n",
    "            )\n",
    "        elif args.decoder == \"rnn\":\n",
    "            decoder = RNNDecoder(\n",
    "                n_in_node=args.dims,\n",
    "                edge_types=args.edge_types,\n",
    "                n_hid=args.decoder_hidden,\n",
    "                do_prob=args.decoder_dropout,\n",
    "                skip_first=args.skip_first,\n",
    "            )\n",
    "        elif args.decoder == \"sim\":\n",
    "            decoder = SimulationDecoder(loc_max, loc_min, vel_max, vel_min, args.suffix)\n",
    "\n",
    "    decoder, num_GPU = distribute_over_GPUs(args, decoder, num_GPU=args.num_GPU)\n",
    "    # print(\"Let's use\", num_GPU, \"GPUs!\")\n",
    "\n",
    "    if args.load_folder:\n",
    "        print(\"Loading model file\")\n",
    "        args.decoder_file = os.path.join(args.load_folder, \"decoder.pt\")\n",
    "        decoder.load_state_dict(torch.load(args.decoder_file, map_location=args.device))\n",
    "        args.save_folder = False\n",
    "\n",
    "    return decoder\n",
    "\n",
    "\n",
    "def load_model(args, loc_max, loc_min, vel_max, vel_min):\n",
    "\n",
    "    decoder = load_decoder(args, loc_max, loc_min, vel_max, vel_min)\n",
    "\n",
    "    if args.use_encoder:\n",
    "        encoder = load_encoder(args)\n",
    "        edge_probs = None\n",
    "        optimizer = optim.Adam(\n",
    "            list(encoder.parameters()) + list(decoder.parameters()), lr=args.lr,\n",
    "        )\n",
    "    else:\n",
    "        encoder = None\n",
    "        edge_probs = load_distribution(args)\n",
    "        optimizer = optim.Adam(\n",
    "            [{\"params\": edge_probs, \"lr\": args.lr_z}]\n",
    "            + [{\"params\": decoder.parameters(), \"lr\": args.lr}]\n",
    "        )\n",
    "\n",
    "    scheduler = lr_scheduler.StepLR(\n",
    "        optimizer, step_size=args.lr_decay, gamma=args.gamma\n",
    "    )\n",
    "\n",
    "    return (\n",
    "        encoder,\n",
    "        decoder,\n",
    "        optimizer,\n",
    "        scheduler,\n",
    "        edge_probs,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### modules.py\n",
    "\n",
    "from model\n",
    "called in train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "# import math\n",
    "# import torch\n",
    "\n",
    "# from model import utils\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    \"\"\"Based on https://github.com/ethanfetaya/NRI (MIT License).\"\"\"\n",
    "\n",
    "    def __init__(self, n_in, n_hid, n_out, do_prob=0.0, use_batch_norm=True, final_linear=False):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(n_in, n_hid)\n",
    "        self.fc2 = nn.Linear(n_hid, n_out)\n",
    "        self.bn = nn.BatchNorm1d(n_out)\n",
    "        self.dropout_prob = do_prob\n",
    "        self.use_batch_norm = use_batch_norm\n",
    "        self.final_linear = final_linear\n",
    "        if self.final_linear:\n",
    "            self.fc_final = nn.Linear(n_out, n_out)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_normal_(m.weight.data)\n",
    "                m.bias.data.fill_(0.1)\n",
    "            elif isinstance(m, nn.Conv1d):\n",
    "                n = m.kernel_size[0] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2.0 / n))\n",
    "                m.bias.data.fill_(0.1)\n",
    "            elif isinstance(m, nn.BatchNorm1d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def batch_norm(self, inputs):\n",
    "        x = inputs.view(inputs.size(0) * inputs.size(1), -1)\n",
    "        x = self.bn(x)\n",
    "        return x.view(inputs.size(0), inputs.size(1), -1)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # Input shape: [num_sims, num_things, num_features]\n",
    "        x = F.elu(self.fc1(inputs))\n",
    "        x = F.dropout(x, self.dropout_prob, training=self.training)\n",
    "        x = F.elu(self.fc2(x))\n",
    "        if self.final_linear:\n",
    "            x = self.fc_final(x)\n",
    "        if self.use_batch_norm:\n",
    "            return self.batch_norm(x)\n",
    "        else:\n",
    "            return x\n",
    "\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    \"\"\"Based on https://github.com/ethanfetaya/NRI (MIT License).\"\"\"\n",
    "\n",
    "    def __init__(self, n_in, n_hid, n_out, do_prob=0.0):\n",
    "        super(CNN, self).__init__()\n",
    "        self.pool = nn.MaxPool1d(\n",
    "            kernel_size=2,\n",
    "            stride=None,\n",
    "            padding=0,\n",
    "            dilation=1,\n",
    "            return_indices=False,\n",
    "            ceil_mode=False,\n",
    "        )\n",
    "\n",
    "        self.conv1 = nn.Conv1d(n_in, n_hid, kernel_size=5, stride=1, padding=0)\n",
    "        self.bn1 = nn.BatchNorm1d(n_hid)\n",
    "        self.conv2 = nn.Conv1d(n_hid, n_hid, kernel_size=5, stride=1, padding=0)\n",
    "        self.bn2 = nn.BatchNorm1d(n_hid)\n",
    "        self.conv_predict = nn.Conv1d(n_hid, n_out, kernel_size=1)\n",
    "        self.conv_attention = nn.Conv1d(n_hid, 1, kernel_size=1)\n",
    "        self.dropout_prob = do_prob\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv1d):\n",
    "                n = m.kernel_size[0] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2.0 / n))\n",
    "                m.bias.data.fill_(0.1)\n",
    "            elif isinstance(m, nn.BatchNorm1d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # Input shape: [num_sims * num_edges, num_dims, num_timesteps]\n",
    "\n",
    "        x = F.relu(self.conv1(inputs))\n",
    "        x = self.bn1(x)\n",
    "        x = F.dropout(x, self.dropout_prob, training=self.training)\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.bn2(x)\n",
    "        pred = self.conv_predict(x)\n",
    "        attention = my_softmax(self.conv_attention(x), axis=2)\n",
    "\n",
    "        edge_prob = (pred * attention).mean(dim=2)\n",
    "        return edge_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Encoder.py\n",
    "\n",
    "from model  \n",
    "called in all encoders/decoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from abc import abstractmethod\n",
    "# import torch\n",
    "\n",
    "# from model.modules import *\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, args, factor=True):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.args = args\n",
    "        self.factor = factor\n",
    "\n",
    "    def init_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_normal_(m.weight.data)\n",
    "                m.bias.data.fill_(0.1)\n",
    "            elif isinstance(m, nn.Conv1d):\n",
    "                n = m.kernel_size[0] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2.0 / n))\n",
    "                m.bias.data.fill_(0.1)\n",
    "            elif isinstance(m, nn.BatchNorm1d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def node2edge_temporal(self, inputs, rel_rec, rel_send):\n",
    "        \"\"\"Based on https://github.com/ethanfetaya/NRI (MIT License).\"\"\"\n",
    "        # NOTE: Assumes that we have the same graph across all samples.\n",
    "\n",
    "        x = inputs.view(inputs.size(0), inputs.size(1), -1)\n",
    "\n",
    "        receivers = torch.matmul(rel_rec, x)\n",
    "        receivers = receivers.view(\n",
    "            inputs.size(0) * receivers.size(1), inputs.size(2), inputs.size(3)\n",
    "        )\n",
    "        receivers = receivers.transpose(2, 1)\n",
    "\n",
    "        senders = torch.matmul(rel_send, x)\n",
    "        senders = senders.view(\n",
    "            inputs.size(0) * senders.size(1), inputs.size(2), inputs.size(3)\n",
    "        )\n",
    "        senders = senders.transpose(2, 1)\n",
    "\n",
    "        # receivers and senders have shape:\n",
    "        # [num_sims * num_edges, num_dims, num_timesteps]\n",
    "        edges = torch.cat([senders, receivers], dim=1)\n",
    "        return edges\n",
    "\n",
    "    def edge2node(self, x, rel_rec, rel_send):\n",
    "        \"\"\"Based on https://github.com/ethanfetaya/NRI (MIT License).\"\"\"\n",
    "        # NOTE: Assumes that we have the same graph across all samples.\n",
    "        incoming = torch.matmul(rel_rec.t(), x)\n",
    "        return incoming / incoming.size(1)\n",
    "\n",
    "    def node2edge(self, x, rel_rec, rel_send):\n",
    "        \"\"\"Based on https://github.com/ethanfetaya/NRI (MIT License).\"\"\"\n",
    "        # NOTE: Assumes that we have the same graph across all samples.\n",
    "        receivers = torch.matmul(rel_rec, x)\n",
    "        senders = torch.matmul(rel_send, x)\n",
    "        edges = torch.cat([senders,receivers], dim=2)\n",
    "        return edges\n",
    "\n",
    "    @abstractmethod\n",
    "    def forward(self, inputs, rel_rec, rel_send, mask_idx=None):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### MLPEncoder.py\n",
    "\n",
    "from model\n",
    "called in model_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import torch\n",
    "\n",
    "# from model.modules import *\n",
    "# from model.Encoder import Encoder\n",
    "\n",
    "class MLPEncoder(Encoder):\n",
    "    \"\"\"Based on https://github.com/ethanfetaya/NRI (MIT License).\"\"\"\n",
    "\n",
    "    def __init__(self, args, n_in, n_hid, n_out, do_prob=0.0, factor=True):\n",
    "        super().__init__(args, factor)\n",
    "\n",
    "        self.mlp1 = MLP(n_in, n_hid, n_hid, do_prob)\n",
    "        self.mlp2 = MLP(n_hid * 2, n_hid, n_hid, do_prob)\n",
    "        self.mlp3 = MLP(n_hid, n_hid, n_hid, do_prob)\n",
    "        if self.factor:\n",
    "            self.mlp4 = MLP(n_hid * 3, n_hid, n_hid, do_prob)\n",
    "            print(\"Using factor graph MLP encoder.\")\n",
    "        else:\n",
    "            self.mlp4 = MLP(n_hid * 2, n_hid, n_hid, do_prob)\n",
    "            print(\"Using MLP encoder.\")\n",
    "        self.fc_out = nn.Linear(n_hid, n_out)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def forward(self, inputs, rel_rec, rel_send):\n",
    "        # Input shape: [num_sims, num_atoms, num_timesteps, num_dims]\n",
    "        x = inputs.view(inputs.size(0), inputs.size(1), -1)\n",
    "        # New shape: [num_sims, num_atoms, num_timesteps*num_dims]\n",
    "\n",
    "        x = self.mlp1(x)  # 2-layer ELU net per node\n",
    "        x = self.node2edge(x, rel_rec, rel_send)\n",
    "        x = self.mlp2(x)\n",
    "        x_skip = x\n",
    "\n",
    "        if self.factor:\n",
    "            x = self.edge2node(x, rel_rec, rel_send)\n",
    "            x = self.mlp3(x)\n",
    "            x = self.node2edge(x, rel_rec, rel_send)\n",
    "            x = torch.cat((x, x_skip), dim=2)  # Skip connection\n",
    "            x = self.mlp4(x)\n",
    "        else:\n",
    "            x = self.mlp3(x)\n",
    "            x = torch.cat((x, x_skip), dim=2)  # Skip connection\n",
    "            x = self.mlp4(x)\n",
    "\n",
    "        return self.fc_out(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### CNNEncoder.py\n",
    "\n",
    "from model\n",
    "called in model_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from model.modules import *\n",
    "# from model.Encoder import Encoder\n",
    "\n",
    "_EPS = 1e-10\n",
    "\n",
    "\n",
    "class CNNEncoder(Encoder):\n",
    "    \"\"\"Based on https://github.com/ethanfetaya/NRI (MIT License).\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, args, n_in, n_hid, n_out, do_prob=0.0, factor=True, n_in_mlp1=None\n",
    "    ):\n",
    "        super().__init__(args, factor)\n",
    "\n",
    "        self.cnn = CNN(n_in * 2, n_hid, n_hid, do_prob)\n",
    "\n",
    "        if n_in_mlp1 is None:\n",
    "            n_in_mlp1 = n_hid\n",
    "        self.mlp1 = MLP(n_in_mlp1, n_hid, n_hid, do_prob)\n",
    "        self.mlp2 = MLP(n_hid, n_hid, n_hid, do_prob)\n",
    "        self.mlp3 = MLP(n_hid * 3, n_hid, n_hid, do_prob)\n",
    "\n",
    "        self.fc_out = nn.Linear(n_hid, n_out)\n",
    "\n",
    "        if self.factor:\n",
    "            print(\"Using factor graph CNN encoder.\")\n",
    "        else:\n",
    "            print(\"Using CNN encoder.\")\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def forward(self, inputs, rel_rec, rel_send):\n",
    "\n",
    "        # Input has shape: [num_sims, num_atoms, num_timesteps, num_dims]\n",
    "        edges = self.node2edge_temporal(inputs, rel_rec, rel_send)\n",
    "        x = self.cnn(edges)\n",
    "        x = x.view(inputs.size(0), (inputs.size(1) - 1) * inputs.size(1), -1)\n",
    "        x = self.mlp1(x)\n",
    "        x_skip = x\n",
    "\n",
    "        if self.factor:\n",
    "            x = self.edge2node(x, rel_rec, rel_send)\n",
    "            x = self.mlp2(x)\n",
    "\n",
    "            x = self.node2edge(x, rel_rec, rel_send)\n",
    "            x = torch.cat((x, x_skip), dim=2)  # Skip connection\n",
    "            x = self.mlp3(x)\n",
    "\n",
    "        return self.fc_out(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### MLPEncoderUnobserved.py\n",
    "\n",
    "from model\n",
    "called in model_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "\n",
    "# from model import utils, utils_unobserved\n",
    "# from model.MLPEncoder import MLPEncoder\n",
    "\n",
    "_EPS = 1e-10\n",
    "\n",
    "class MLPEncoderUnobserved(MLPEncoder):\n",
    "    def __init__(self, args, n_in, n_hid, n_out, do_prob=0.0, factor=True):\n",
    "        super().__init__(args, n_in, n_hid, n_out, do_prob, factor)\n",
    "\n",
    "        self.unobserved = args.unobserved\n",
    "\n",
    "        self.lstm1 = nn.LSTM(\n",
    "            (args.num_atoms - self.unobserved) * args.dims,\n",
    "            n_hid,\n",
    "            bidirectional=True,\n",
    "            dropout=do_prob,\n",
    "        )\n",
    "        self.lstm2 = nn.LSTM(n_hid * 2, args.dims, bidirectional=False, dropout=do_prob)\n",
    "\n",
    "        self.init_weights()\n",
    "        print(\"Using unobserved encoder.\")\n",
    "\n",
    "    def evaluate_unobserved(self, unobserved, target):\n",
    "        return F.mse_loss(torch.squeeze(unobserved), torch.squeeze(target))\n",
    "\n",
    "    def calc_unobserved_q(self, unobserved):\n",
    "        ### Gaussian prior\n",
    "        unobserved_mu = self.fc_mu(unobserved)\n",
    "        unobserved_log_sigma = self.fc_logsigma(unobserved)\n",
    "\n",
    "        unobserved = sample_normal_from_latents(\n",
    "            unobserved_mu,\n",
    "            unobserved_log_sigma,\n",
    "            downscale_factor=self.args.prior_downscale,\n",
    "        )\n",
    "\n",
    "        loss_kl_latent = kl_normal_reverse(\n",
    "            0,\n",
    "            1,\n",
    "            unobserved_mu,\n",
    "            unobserved_log_sigma,\n",
    "            downscale_factor=self.args.prior_downscale,\n",
    "        )\n",
    "        return unobserved, loss_kl_latent\n",
    "\n",
    "    def forward(self, inputs, rel_rec, rel_send, mask_idx=0):\n",
    "        timesteps = inputs.size(2)\n",
    "\n",
    "        # input shape: [num_sims, num_atoms, num_timesteps, num_dims]\n",
    "        observed = remove_unobserved(self.args, inputs, mask_idx)\n",
    "\n",
    "        observed = observed.permute(2, 0, 1, 3)\n",
    "        observed = observed.reshape(observed.size(0), observed.size(1), -1)\n",
    "        unobserved, _ = self.lstm1(observed)\n",
    "        unobserved, _ = self.lstm2(unobserved)\n",
    "        unobserved = unobserved.unsqueeze(0).permute(2, 0, 1, 3)\n",
    "        unobserved = torch.reshape(\n",
    "            unobserved, [unobserved.size(0), unobserved.size(1), timesteps, -1]\n",
    "        )\n",
    "        # output shape: [num_sims, num_atoms, num_timesteps, num_dims]\n",
    "\n",
    "        target_unobserved = inputs[:, mask_idx, :, :]\n",
    "        mse_unobserved = self.evaluate_unobserved(unobserved, target_unobserved)\n",
    "\n",
    "        data_encoder = torch.cat(\n",
    "            (inputs[:, :mask_idx, :], unobserved, inputs[:, mask_idx + 1 :, :],), dim=1,\n",
    "        )\n",
    "\n",
    "        output = super().forward(data_encoder, rel_rec, rel_send)\n",
    "\n",
    "        return (output, unobserved, mse_unobserved)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### EncoderGlobalTemp.py \n",
    "\n",
    "from model\n",
    "called in model_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from model.modules import *\n",
    "# from model.MLPEncoder import MLPEncoder\n",
    "# from model.CNNEncoder import CNNEncoder\n",
    "\n",
    "\n",
    "class CNNEncoderGlobalTemp(CNNEncoder):\n",
    "    def __init__(\n",
    "        self,\n",
    "        args,\n",
    "        n_in,\n",
    "        n_hid,\n",
    "        n_out,\n",
    "        do_prob=0.0,\n",
    "        factor=True,\n",
    "        latent_dim=2,\n",
    "        latent_sample_dim=1,\n",
    "        num_atoms=5,\n",
    "        num_timesteps=49,\n",
    "    ):\n",
    "        super().__init__(\n",
    "            args,\n",
    "            n_in,\n",
    "            n_hid,\n",
    "            n_out,\n",
    "            do_prob,\n",
    "            factor,\n",
    "            n_in_mlp1=n_hid + latent_sample_dim,\n",
    "        )\n",
    "\n",
    "        self.mlp4_confounder = MLP(\n",
    "            n_in * num_timesteps * num_atoms,\n",
    "            n_hid,\n",
    "            latent_dim,\n",
    "            do_prob,\n",
    "            use_batch_norm=False,\n",
    "            final_linear=True,\n",
    "        )\n",
    "        self.init_weights()\n",
    "\n",
    "    def forward(self, inputs, rel_rec, rel_send):\n",
    "        # New shape: [num_sims, num_atoms, num_timesteps*num_dims]\n",
    "        # Input has shape: [num_sims, num_atoms, num_timesteps, num_dims]\n",
    "        edges = self.node2edge_temporal(inputs, rel_rec, rel_send)\n",
    "        x = self.cnn(edges)\n",
    "        x = x.view(inputs.size(0), (inputs.size(1) - 1) * inputs.size(1), -1)\n",
    "\n",
    "        # Input shape: [num_sims, num_atoms, num_timesteps, num_dims]\n",
    "        x_latent_input = inputs.view(inputs.size(0), 1, -1)\n",
    "        latents = self.mlp4_confounder(x_latent_input).squeeze(1)\n",
    "\n",
    "        inferred_mu, inferred_width = utils.get_uniform_parameters_from_latents(latents)\n",
    "        latent_sample = utils.sample_uniform_from_latents(inferred_mu, inferred_width)\n",
    "        l = latent_sample.view(latent_sample.size(0), 1, latent_sample.size(1)).repeat(\n",
    "            1, x.size(1), 1\n",
    "        )\n",
    "        l = l.detach()\n",
    "        # l = latents.view(latents.size(0), 1, latents.size(1)).repeat(1, x.size(1), 1)\n",
    "\n",
    "        x = self.mlp1(torch.cat([x, l], 2))  # 2-layer ELU net per node\n",
    "        x_skip = x\n",
    "\n",
    "        if self.factor:\n",
    "            x = self.edge2node(x, rel_rec, rel_send)\n",
    "            x = self.mlp2(x)\n",
    "            x = self.node2edge(x, rel_rec, rel_send)\n",
    "            x = torch.cat((x, x_skip), dim=2)  # Skip connection\n",
    "            x = self.mlp3(x)\n",
    "\n",
    "        return self.fc_out(x), latent_sample, inferred_mu, inferred_width\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### MLPDecoder.py\n",
    "\n",
    "from model\n",
    "called in model_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import torch\n",
    "\n",
    "# from model.modules import *\n",
    "\n",
    "class MLPDecoder(nn.Module):\n",
    "    \"\"\"Based on https://github.com/ethanfetaya/NRI (MIT License).\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        args,\n",
    "        n_in_node,\n",
    "        edge_types,\n",
    "        msg_hid,\n",
    "        msg_out,\n",
    "        n_hid,\n",
    "        do_prob=0.0,\n",
    "        skip_first=False,\n",
    "    ):\n",
    "        super(MLPDecoder, self).__init__()\n",
    "        self.msg_fc1 = nn.ModuleList(\n",
    "            [nn.Linear(2 * n_in_node, msg_hid) for _ in range(edge_types)]\n",
    "        )\n",
    "        self.msg_fc2 = nn.ModuleList(\n",
    "            [nn.Linear(msg_hid, msg_out) for _ in range(edge_types)]\n",
    "        )\n",
    "        self.msg_out_shape = msg_out\n",
    "        self.skip_first_edge_type = skip_first\n",
    "\n",
    "        self.out_fc1 = nn.Linear(n_in_node + msg_out, n_hid)\n",
    "        self.out_fc2 = nn.Linear(n_hid, n_hid)\n",
    "        self.out_fc3 = nn.Linear(n_hid, n_in_node)\n",
    "\n",
    "        print(\"Using learned interaction net decoder.\")\n",
    "\n",
    "        self.dropout_prob = do_prob\n",
    "\n",
    "    def single_step_forward(\n",
    "        self, single_timestep_inputs, rel_rec, rel_send, single_timestep_rel_type\n",
    "    ):\n",
    "\n",
    "        # single_timestep_inputs has shape\n",
    "        # [batch_size, num_timesteps, num_atoms, num_dims]\n",
    "\n",
    "        # single_timestep_rel_type has shape:\n",
    "        # [batch_size, num_timesteps, num_atoms*(num_atoms-1), num_edge_types]\n",
    "\n",
    "        # Node2edge\n",
    "        receivers = torch.matmul(rel_rec, single_timestep_inputs)\n",
    "        senders = torch.matmul(rel_send, single_timestep_inputs)\n",
    "        pre_msg = torch.cat([senders, receivers], dim=-1)\n",
    "\n",
    "        all_msgs = torch.zeros(\n",
    "            pre_msg.size(0), pre_msg.size(1), pre_msg.size(2), self.msg_out_shape\n",
    "        )\n",
    "\n",
    "        if single_timestep_inputs.is_cuda:\n",
    "            all_msgs = all_msgs.cuda()\n",
    "\n",
    "        if self.skip_first_edge_type:\n",
    "            start_idx = 1\n",
    "        else:\n",
    "            start_idx = 0\n",
    "\n",
    "        # Run separate MLP for every edge type\n",
    "        # NOTE: To exclude one edge type, simply offset range by 1\n",
    "        for i in range(start_idx, len(self.msg_fc2)):\n",
    "            msg = F.relu(self.msg_fc1[i](pre_msg))\n",
    "            msg = F.dropout(msg, p=self.dropout_prob)\n",
    "            msg = F.relu(self.msg_fc2[i](msg))\n",
    "            msg = msg * single_timestep_rel_type[:, :, :, i : i + 1]\n",
    "            all_msgs += msg\n",
    "\n",
    "        # Aggregate all msgs to receiver\n",
    "        agg_msgs = all_msgs.transpose(-2, -1).matmul(rel_rec).transpose(-2, -1)\n",
    "        agg_msgs = agg_msgs.contiguous()\n",
    "\n",
    "        # Skip connection\n",
    "        aug_inputs = torch.cat([single_timestep_inputs, agg_msgs], dim=-1)\n",
    "\n",
    "        # Output MLP\n",
    "        pred = F.dropout(F.relu(self.out_fc1(aug_inputs)), p=self.dropout_prob)\n",
    "        pred = F.dropout(F.relu(self.out_fc2(pred)), p=self.dropout_prob)\n",
    "        pred = self.out_fc3(pred)\n",
    "\n",
    "        # Predict position/velocity difference\n",
    "        return single_timestep_inputs + pred\n",
    "\n",
    "    def forward(self, inputs, rel_type, rel_rec, rel_send, pred_steps=1):\n",
    "        # NOTE: Assumes that we have the same graph across all samples.\n",
    "\n",
    "        inputs = inputs.transpose(1, 2).contiguous()\n",
    "\n",
    "        sizes = [\n",
    "            rel_type.size(0),\n",
    "            inputs.size(1),\n",
    "            rel_type.size(1),\n",
    "            rel_type.size(2),\n",
    "        ]  # batch, sequence length, interactions between particles, interaction types\n",
    "        rel_type = rel_type.unsqueeze(1).expand(\n",
    "            sizes\n",
    "        )  # copy relations over sequence length\n",
    "\n",
    "        time_steps = inputs.size(1)\n",
    "        assert pred_steps <= time_steps\n",
    "        preds = []\n",
    "\n",
    "        # Only take n-th timesteps as starting points (n: pred_steps)\n",
    "        last_pred = inputs[:, 0::pred_steps, :, :]\n",
    "        curr_rel_type = rel_type[:, 0::pred_steps, :, :]\n",
    "        # NOTE: Assumes rel_type is constant (i.e. same across all time steps).\n",
    "\n",
    "        # Run n prediction steps\n",
    "        for step in range(0, pred_steps):\n",
    "            last_pred = self.single_step_forward(\n",
    "                last_pred, rel_rec, rel_send, curr_rel_type\n",
    "            )\n",
    "            preds.append(last_pred)\n",
    "\n",
    "        sizes = [\n",
    "            preds[0].size(0),\n",
    "            preds[0].size(1) * pred_steps,\n",
    "            preds[0].size(2),\n",
    "            preds[0].size(3),\n",
    "        ]\n",
    "\n",
    "        output = torch.zeros(sizes)\n",
    "        if inputs.is_cuda:\n",
    "            output = output.cuda()\n",
    "\n",
    "        # Re-assemble correct timeline\n",
    "        for i in range(len(preds)):\n",
    "            output[:, i::pred_steps, :, :] = preds[i]\n",
    "\n",
    "        pred_all = output[:, : (inputs.size(1) - 1), :, :]\n",
    "\n",
    "        return pred_all.transpose(1, 2).contiguous()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### RNNDecoder.py\n",
    "\n",
    "from model\n",
    "called in model_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import torch\n",
    "\n",
    "# from model.modules import *\n",
    "# from model import utils\n",
    "\n",
    "\n",
    "class RNNDecoder(nn.Module):\n",
    "    \"\"\"Based on https://github.com/ethanfetaya/NRI (MIT License).\"\"\"\n",
    "\n",
    "    def __init__(self, n_in_node, edge_types, n_hid, do_prob=0.0, skip_first=False):\n",
    "        super(RNNDecoder, self).__init__()\n",
    "        self.msg_fc1 = nn.ModuleList(\n",
    "            [nn.Linear(2 * n_hid, n_hid) for _ in range(edge_types)]\n",
    "        )\n",
    "        self.msg_fc2 = nn.ModuleList(\n",
    "            [nn.Linear(n_hid, n_hid) for _ in range(edge_types)]\n",
    "        )\n",
    "        self.msg_out_shape = n_hid\n",
    "        self.skip_first_edge_type = skip_first\n",
    "\n",
    "        self.hidden_r = nn.Linear(n_hid, n_hid, bias=False)\n",
    "        self.hidden_i = nn.Linear(n_hid, n_hid, bias=False)\n",
    "        self.hidden_h = nn.Linear(n_hid, n_hid, bias=False)\n",
    "\n",
    "        self.input_r = nn.Linear(n_in_node, n_hid, bias=True)\n",
    "        self.input_i = nn.Linear(n_in_node, n_hid, bias=True)\n",
    "        self.input_n = nn.Linear(n_in_node, n_hid, bias=True)\n",
    "\n",
    "        self.out_fc1 = nn.Linear(n_hid, n_hid)\n",
    "        self.out_fc2 = nn.Linear(n_hid, n_hid)\n",
    "        self.out_fc3 = nn.Linear(n_hid, n_in_node)\n",
    "\n",
    "        print(\"Using learned recurrent interaction net decoder.\")\n",
    "\n",
    "        self.dropout_prob = do_prob\n",
    "\n",
    "    def single_step_forward(self, inputs, rel_rec, rel_send, rel_type, hidden):\n",
    "\n",
    "        # node2edge\n",
    "        receivers = torch.matmul(rel_rec, hidden)\n",
    "        senders = torch.matmul(rel_send, hidden)\n",
    "        pre_msg = torch.cat([senders, receivers], dim=-1)\n",
    "\n",
    "        all_msgs = torch.zeros(pre_msg.size(0), pre_msg.size(1), self.msg_out_shape)\n",
    "\n",
    "        if inputs.is_cuda:\n",
    "            all_msgs = all_msgs.cuda()\n",
    "\n",
    "        if self.skip_first_edge_type:\n",
    "            start_idx = 1\n",
    "            norm = float(len(self.msg_fc2)) - 1.0\n",
    "        else:\n",
    "            start_idx = 0\n",
    "            norm = float(len(self.msg_fc2))\n",
    "\n",
    "        # Run separate MLP for every edge type\n",
    "        # NOTE: To exclude one edge type, simply offset range by 1\n",
    "        for i in range(start_idx, len(self.msg_fc2)):\n",
    "            msg = torch.tanh(self.msg_fc1[i](pre_msg))\n",
    "            msg = F.dropout(msg, p=self.dropout_prob)\n",
    "            msg = torch.tanh(self.msg_fc2[i](msg))\n",
    "            msg = msg * rel_type[:, :, i : i + 1]\n",
    "            all_msgs += msg / norm\n",
    "\n",
    "        agg_msgs = all_msgs.transpose(-2, -1).matmul(rel_rec).transpose(-2, -1)\n",
    "        agg_msgs = agg_msgs.contiguous() / inputs.size(2)  # Average\n",
    "\n",
    "        # GRU-style gated aggregation\n",
    "        r = torch.sigmoid(self.input_r(inputs) + self.hidden_r(agg_msgs))\n",
    "        i = torch.sigmoid(self.input_i(inputs) + self.hidden_i(agg_msgs))\n",
    "        n = torch.tanh(self.input_n(inputs) + r * self.hidden_h(agg_msgs))\n",
    "        hidden = (1 - i) * n + i * hidden\n",
    "\n",
    "        # Output MLP\n",
    "        pred = F.dropout(F.relu(self.out_fc1(hidden)), p=self.dropout_prob)\n",
    "        pred = F.dropout(F.relu(self.out_fc2(pred)), p=self.dropout_prob)\n",
    "        pred = self.out_fc3(pred)\n",
    "\n",
    "        # Predict position/velocity difference\n",
    "        pred = inputs + pred\n",
    "\n",
    "        return pred, hidden\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        data,\n",
    "        rel_type,\n",
    "        rel_rec,\n",
    "        rel_send,\n",
    "        pred_steps=1,\n",
    "        burn_in=False,\n",
    "        burn_in_steps=1,\n",
    "        dynamic_graph=False,\n",
    "        encoder=None,\n",
    "        temp=None,\n",
    "    ):\n",
    "\n",
    "        inputs = data.transpose(1, 2).contiguous()\n",
    "\n",
    "        time_steps = inputs.size(1)\n",
    "\n",
    "        # inputs has shape\n",
    "        # [batch_size, num_timesteps, num_atoms, num_dims]\n",
    "\n",
    "        # rel_type has shape:\n",
    "        # [batch_size, num_atoms*(num_atoms-1), num_edge_types]\n",
    "\n",
    "        hidden = torch.zeros(inputs.size(0), inputs.size(2), self.msg_out_shape)\n",
    "\n",
    "        if inputs.is_cuda:\n",
    "            hidden = hidden.cuda()\n",
    "\n",
    "        pred_all = []\n",
    "\n",
    "        for step in range(0, inputs.size(1) - 1):\n",
    "\n",
    "            if burn_in:\n",
    "                if step <= burn_in_steps:\n",
    "                    ins = inputs[:, step, :, :]\n",
    "                else:\n",
    "                    ins = pred_all[step - 1]\n",
    "            else:\n",
    "                assert pred_steps <= time_steps\n",
    "                # Use ground truth trajectory input vs. last prediction\n",
    "                if not step % pred_steps:\n",
    "                    ins = inputs[:, step, :, :]\n",
    "                else:\n",
    "                    ins = pred_all[step - 1]\n",
    "\n",
    "            if dynamic_graph and step >= burn_in_steps:\n",
    "                # NOTE: Assumes burn_in_steps = args.timesteps\n",
    "                logits = encoder(\n",
    "                    data[:, :, step - burn_in_steps : step, :].contiguous(),\n",
    "                    rel_rec,\n",
    "                    rel_send,\n",
    "                )\n",
    "                rel_type = gumbel_softmax(logits, tau=temp, hard=True)\n",
    "\n",
    "            pred, hidden = self.single_step_forward(\n",
    "                ins, rel_rec, rel_send, rel_type, hidden\n",
    "            )\n",
    "            pred_all.append(pred)\n",
    "\n",
    "        preds = torch.stack(pred_all, dim=1)\n",
    "\n",
    "        return preds.transpose(1, 2).contiguous()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### SimulationDecoder.py\n",
    "\n",
    "from model\n",
    "called in model_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import torch.nn as nn\n",
    "# import torch\n",
    "\n",
    "\n",
    "class SimulationDecoder(nn.Module):\n",
    "    \"\"\"Based on https://github.com/ethanfetaya/NRI (MIT License).\"\"\"\n",
    "\n",
    "    def __init__(self, loc_max, loc_min, vel_max, vel_min, suffix):\n",
    "        super(SimulationDecoder, self).__init__()\n",
    "\n",
    "        self.loc_max = loc_max\n",
    "        self.loc_min = loc_min\n",
    "        self.vel_max = vel_max\n",
    "        self.vel_min = vel_min\n",
    "\n",
    "        self.interaction_type = suffix\n",
    "\n",
    "        if \"_springs\" in self.interaction_type:\n",
    "            print(\"Using spring simulation decoder.\")\n",
    "            self.interaction_strength = 0.1\n",
    "            # original simulation used sample_freq, _delta_T = 100, 0.001\n",
    "            # we use 1, 0.1 instead for computational efficiency\n",
    "            self.sample_freq = 1\n",
    "            self._delta_T = 0.1\n",
    "            self.box_size = 5.0\n",
    "        else:\n",
    "            print(\"Simulation type could not be inferred from suffix.\")\n",
    "\n",
    "        self.out = None\n",
    "\n",
    "        # NOTE: For exact reproduction, choose sample_freq=100, delta_T=0.001\n",
    "\n",
    "        self._max_F = 0.1 / self._delta_T\n",
    "\n",
    "    def unnormalize(self, loc, vel):\n",
    "        loc = 0.5 * (loc + 1) * (self.loc_max - self.loc_min) + self.loc_min\n",
    "        vel = 0.5 * (vel + 1) * (self.vel_max - self.vel_min) + self.vel_min\n",
    "        return loc, vel\n",
    "\n",
    "    def renormalize(self, loc, vel):\n",
    "        loc = 2 * (loc - self.loc_min) / (self.loc_max - self.loc_min) - 1\n",
    "        vel = 2 * (vel - self.vel_min) / (self.vel_max - self.vel_min) - 1\n",
    "        return loc, vel\n",
    "\n",
    "    def clamp(self, loc, vel):\n",
    "        over = loc > self.box_size\n",
    "        loc[over] = 2 * self.box_size - loc[over]\n",
    "        vel[over] = -torch.abs(vel[over])\n",
    "\n",
    "        under = loc < -self.box_size\n",
    "        loc[under] = -2 * self.box_size - loc[under]\n",
    "        vel[under] = torch.abs(vel[under])\n",
    "\n",
    "        return loc, vel\n",
    "\n",
    "    def get_offdiag_indices(self, num_nodes):\n",
    "        \"\"\"Linear off-diagonal indices.\"\"\"\n",
    "        ones = torch.ones(num_nodes, num_nodes)\n",
    "        eye = torch.eye(num_nodes, num_nodes)\n",
    "        offdiag_indices = (ones - eye).nonzero().t()\n",
    "        offdiag_indices = offdiag_indices[0] * num_nodes + offdiag_indices[1]\n",
    "        return offdiag_indices\n",
    "\n",
    "    def forward(self, inputs, relations, rel_rec, rel_send, pred_steps=1):\n",
    "        # Input has shape: [num_sims, num_things, num_timesteps, num_dims]\n",
    "        # Relation mx shape: [num_sims, num_things*num_things]\n",
    "\n",
    "        # Only keep single dimension of softmax output\n",
    "        relations = relations[:, :, 1]\n",
    "\n",
    "        loc = inputs[:, :, :-1, :2].contiguous()\n",
    "        vel = inputs[:, :, :-1, 2:].contiguous()\n",
    "\n",
    "        # Broadcasting/shape tricks for parallel processing of time steps\n",
    "        loc = loc.permute(0, 2, 1, 3).contiguous()\n",
    "        vel = vel.permute(0, 2, 1, 3).contiguous()\n",
    "        loc = loc.view(inputs.size(0) * (inputs.size(2) - 1), inputs.size(1), 2)\n",
    "        vel = vel.view(inputs.size(0) * (inputs.size(2) - 1), inputs.size(1), 2)\n",
    "\n",
    "        loc, vel = self.unnormalize(loc, vel)\n",
    "\n",
    "        offdiag_indices = self.get_offdiag_indices(inputs.size(1))\n",
    "        edges = torch.zeros(relations.size(0), inputs.size(1) * inputs.size(1))\n",
    "\n",
    "        if inputs.is_cuda:\n",
    "            edges = edges.cuda()\n",
    "            offdiag_indices = offdiag_indices.cuda()\n",
    "\n",
    "        edges[:, offdiag_indices] = relations.float()\n",
    "\n",
    "        edges = edges.view(relations.size(0), inputs.size(1), inputs.size(1))\n",
    "\n",
    "        self.out = []\n",
    "\n",
    "        for _ in range(0, self.sample_freq):\n",
    "            x = loc[:, :, 0].unsqueeze(-1)\n",
    "            y = loc[:, :, 1].unsqueeze(-1)\n",
    "\n",
    "            xx = x.expand(x.size(0), x.size(1), x.size(1))\n",
    "            yy = y.expand(y.size(0), y.size(1), y.size(1))\n",
    "            dist_x = xx - xx.transpose(1, 2)\n",
    "            dist_y = yy - yy.transpose(1, 2)\n",
    "\n",
    "            forces_size = -self.interaction_strength * edges\n",
    "            pair_dist = torch.cat((dist_x.unsqueeze(-1), dist_y.unsqueeze(-1)), -1)\n",
    "\n",
    "            # Tricks for parallel processing of time steps\n",
    "            pair_dist = pair_dist.view(\n",
    "                inputs.size(0), (inputs.size(2) - 1), inputs.size(1), inputs.size(1), 2,\n",
    "            )\n",
    "            forces = (forces_size.unsqueeze(-1).unsqueeze(1) * pair_dist).sum(3)\n",
    "\n",
    "            forces = forces.view(\n",
    "                inputs.size(0) * (inputs.size(2) - 1), inputs.size(1), 2\n",
    "            )\n",
    "\n",
    "            # Leapfrog integration step\n",
    "            vel = vel + self._delta_T * forces\n",
    "            loc = loc + self._delta_T * vel\n",
    "\n",
    "            # Handle box boundaries\n",
    "            loc, vel = self.clamp(loc, vel)\n",
    "\n",
    "        loc, vel = self.renormalize(loc, vel)\n",
    "\n",
    "        loc = loc.view(inputs.size(0), (inputs.size(2) - 1), inputs.size(1), 2)\n",
    "        vel = vel.view(inputs.size(0), (inputs.size(2) - 1), inputs.size(1), 2)\n",
    "\n",
    "        loc = loc.permute(0, 2, 1, 3)\n",
    "        vel = vel.permute(0, 2, 1, 3)\n",
    "\n",
    "        out = torch.cat((loc, vel), dim=-1)\n",
    "        # Output has shape: [num_sims, num_things, num_timesteps-1, num_dims]\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### DecoderGlobalTemp.py\n",
    "\n",
    "from model\n",
    "called in model_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from model.modules import *\n",
    "# from model.SimulationDecoder import SimulationDecoder\n",
    "# from model import utils\n",
    "\n",
    "\n",
    "class MLPDecoderGlobalTemp(nn.Module):\n",
    "    \"\"\"Based on https://github.com/ethanfetaya/NRI (MIT License).\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_in_node,\n",
    "        edge_types,\n",
    "        msg_hid,\n",
    "        msg_out,\n",
    "        n_hid,\n",
    "        do_prob=0.0,\n",
    "        skip_first=False,\n",
    "        latent_dim=32,\n",
    "    ):\n",
    "        super(MLPDecoderGlobalTemp, self).__init__()\n",
    "        self.msg_fc1 = nn.ModuleList(\n",
    "            # [nn.Linear(2 * n_in_node + latent_dim, msg_hid) for _ in range(edge_types)]\n",
    "            [nn.Linear(2 * n_in_node, msg_hid) for _ in range(edge_types)]\n",
    "        )\n",
    "        self.msg_fc2 = nn.ModuleList(\n",
    "            [nn.Linear(msg_hid, msg_out) for _ in range(edge_types)]\n",
    "        )\n",
    "        self.msg_out_shape = msg_out\n",
    "        self.skip_first_edge_type = skip_first\n",
    "\n",
    "        self.out_fc1 = nn.Linear(n_in_node + msg_out, n_hid)\n",
    "        self.out_fc2 = nn.Linear(n_hid, n_hid)\n",
    "        self.out_fc3 = nn.Linear(n_hid, n_in_node)\n",
    "\n",
    "        print(\"Using learned interaction net decoder.\")\n",
    "\n",
    "        self.dropout_prob = do_prob\n",
    "\n",
    "    def single_step_forward(\n",
    "        self,\n",
    "        single_timestep_inputs,\n",
    "        latents,\n",
    "        rel_rec,\n",
    "        rel_send,\n",
    "        single_timestep_rel_type,\n",
    "    ):\n",
    "\n",
    "        # single_timestep_inputs has shape\n",
    "        # [batch_size, num_timesteps, num_atoms, num_dims]\n",
    "\n",
    "        # single_timestep_rel_type has shape:\n",
    "        # [batch_size, num_timesteps, num_atoms*(num_atoms-1), num_edge_types]\n",
    "\n",
    "        # Node2edge\n",
    "        receivers = torch.matmul(rel_rec, single_timestep_inputs)\n",
    "        senders = torch.matmul(rel_send, single_timestep_inputs)\n",
    "        pre_msg = torch.cat([senders, receivers], dim=-1)\n",
    "\n",
    "        all_msgs = torch.zeros(\n",
    "            pre_msg.size(0), pre_msg.size(1), pre_msg.size(2), self.msg_out_shape\n",
    "        )\n",
    "\n",
    "        if single_timestep_inputs.is_cuda:\n",
    "            all_msgs = all_msgs.cuda()\n",
    "\n",
    "        if self.skip_first_edge_type:\n",
    "            start_idx = 1\n",
    "        else:\n",
    "            start_idx = 0\n",
    "\n",
    "        # Run separate MLP for every edge type\n",
    "        # NOTE: To exclude one edge type, simply offset range by 1\n",
    "        for i in range(start_idx, len(self.msg_fc2)):\n",
    "            msg = F.relu(self.msg_fc1[i](pre_msg))\n",
    "            msg = F.dropout(msg, p=self.dropout_prob)\n",
    "            msg = F.relu(self.msg_fc2[i](msg))\n",
    "            msg = msg * single_timestep_rel_type[:, :, :, i : i + 1]\n",
    "            all_msgs += msg\n",
    "\n",
    "        # Aggregate all msgs to receiver\n",
    "        agg_msgs = all_msgs.transpose(-2, -1).matmul(rel_rec).transpose(-2, -1)\n",
    "        agg_msgs = agg_msgs.contiguous()\n",
    "\n",
    "        # Skip connection\n",
    "        aug_inputs = torch.cat([single_timestep_inputs, agg_msgs], dim=-1)\n",
    "\n",
    "        # Output MLP\n",
    "        pred = F.dropout(F.relu(self.out_fc1(aug_inputs)), p=self.dropout_prob)\n",
    "        pred = F.dropout(F.relu(self.out_fc2(pred)), p=self.dropout_prob)\n",
    "        pred = self.out_fc3(pred)\n",
    "\n",
    "        # Predict position/velocity difference\n",
    "        return single_timestep_inputs + pred\n",
    "\n",
    "    def forward(self, inputs, rel_type, latents, rel_rec, rel_send, pred_steps=1):\n",
    "        # NOTE: Assumes that we have the same graph across all samples.\n",
    "\n",
    "        inputs = inputs.transpose(1, 2).contiguous()\n",
    "\n",
    "        sizes = [\n",
    "            rel_type.size(0),\n",
    "            inputs.size(1),\n",
    "            rel_type.size(1),\n",
    "            rel_type.size(2),\n",
    "        ]  # batch, sequence length, interactions between particles, interaction types\n",
    "        rel_type = rel_type.unsqueeze(1).expand(\n",
    "            sizes\n",
    "        )  # copy relations over sequence length\n",
    "\n",
    "        time_steps = inputs.size(1)\n",
    "        assert pred_steps <= time_steps\n",
    "        preds = []\n",
    "\n",
    "        # Only take n-th timesteps as starting points (n: pred_steps)\n",
    "        last_pred = inputs[:, 0::pred_steps, :, :]\n",
    "        curr_rel_type = rel_type[:, 0::pred_steps, :, :]\n",
    "        # NOTE: Assumes rel_type is constant (i.e. same across all time steps).\n",
    "\n",
    "        # Run n prediction steps\n",
    "        for step in range(0, pred_steps):\n",
    "            last_pred = self.single_step_forward(\n",
    "                last_pred, latents, rel_rec, rel_send, curr_rel_type\n",
    "            )\n",
    "            preds.append(last_pred)\n",
    "\n",
    "        sizes = [\n",
    "            preds[0].size(0),\n",
    "            preds[0].size(1) * pred_steps,\n",
    "            preds[0].size(2),\n",
    "            preds[0].size(3),\n",
    "        ]\n",
    "\n",
    "        output = torch.zeros(sizes)\n",
    "        if inputs.is_cuda:\n",
    "            output = output.cuda()\n",
    "\n",
    "        # Re-assemble correct timeline\n",
    "        for i in range(len(preds)):\n",
    "            output[:, i::pred_steps, :, :] = preds[i]\n",
    "\n",
    "        pred_all = output[:, : (inputs.size(1) - 1), :, :]\n",
    "\n",
    "        return pred_all.transpose(1, 2).contiguous()\n",
    "\n",
    "\n",
    "class SimulationDecoderGlobalTemp(SimulationDecoder):\n",
    "    \"\"\"Based on https://github.com/ethanfetaya/NRI (MIT License).\"\"\"\n",
    "\n",
    "    def __init__(self, loc_max, loc_min, vel_max, vel_min, suffix):\n",
    "        super(SimulationDecoderGlobalTemp, self).__init__(\n",
    "            loc_max, loc_min, vel_max, vel_min, suffix\n",
    "        )\n",
    "\n",
    "    def forward(self, inputs, relations, latents, rel_rec, rel_send, pred_steps=1):\n",
    "        temperature = latents.unsqueeze(2)\n",
    "        # Input has shape: [num_sims, num_things, num_timesteps, num_dims]\n",
    "        # Relation mx shape: [num_sims, num_things*num_things]\n",
    "\n",
    "        # Only keep single dimension of softmax output\n",
    "        relations = relations[:, :, 1]\n",
    "\n",
    "        loc = inputs[:, :, :-1, :2].contiguous()\n",
    "        vel = inputs[:, :, :-1, 2:].contiguous()\n",
    "\n",
    "        # Broadcasting/shape tricks for parallel processing of time steps\n",
    "        loc = loc.permute(0, 2, 1, 3).contiguous()\n",
    "        vel = vel.permute(0, 2, 1, 3).contiguous()\n",
    "        loc = loc.view(inputs.size(0) * (inputs.size(2) - 1), inputs.size(1), 2)\n",
    "        vel = vel.view(inputs.size(0) * (inputs.size(2) - 1), inputs.size(1), 2)\n",
    "\n",
    "        loc, vel = self.unnormalize(loc, vel)\n",
    "\n",
    "        offdiag_indices = get_offdiag_indices(inputs.size(1))\n",
    "        edges = torch.zeros(relations.size(0), inputs.size(1) * inputs.size(1))\n",
    "\n",
    "        if inputs.is_cuda:\n",
    "            edges = edges.cuda()\n",
    "            offdiag_indices = offdiag_indices.cuda()\n",
    "\n",
    "        edges[:, offdiag_indices] = relations.float()\n",
    "\n",
    "        edges = edges.view(relations.size(0), inputs.size(1), inputs.size(1))\n",
    "\n",
    "        self.out = []\n",
    "\n",
    "        for _ in range(0, self.sample_freq):\n",
    "            x = loc[:, :, 0].unsqueeze(-1)\n",
    "            y = loc[:, :, 1].unsqueeze(-1)\n",
    "\n",
    "            xx = x.expand(x.size(0), x.size(1), x.size(1))\n",
    "            yy = y.expand(y.size(0), y.size(1), y.size(1))\n",
    "            dist_x = xx - xx.transpose(1, 2)\n",
    "            dist_y = yy - yy.transpose(1, 2)\n",
    "\n",
    "            if \"_springs\" in self.interaction_type:\n",
    "                forces_size = -temperature * edges\n",
    "                pair_dist = torch.cat((dist_x.unsqueeze(-1), dist_y.unsqueeze(-1)), -1)\n",
    "\n",
    "                # Tricks for parallel processing of time steps\n",
    "                pair_dist = pair_dist.view(\n",
    "                    inputs.size(0),\n",
    "                    (inputs.size(2) - 1),\n",
    "                    inputs.size(1),\n",
    "                    inputs.size(1),\n",
    "                    2,\n",
    "                )\n",
    "                forces = (forces_size.unsqueeze(-1).unsqueeze(1) * pair_dist).sum(3)\n",
    "            else:  # charged particle sim\n",
    "                e = (-1) * (edges * 2 - 1)\n",
    "                forces_size = -temperature * e\n",
    "\n",
    "                l2_dist_power3 = torch.pow(self.pairwise_sq_dist(loc), 3.0 / 2.0)\n",
    "                l2_dist_power3 = self.set_diag_to_one(l2_dist_power3)\n",
    "\n",
    "                l2_dist_power3 = l2_dist_power3.view(\n",
    "                    inputs.size(0), (inputs.size(2) - 1), inputs.size(1), inputs.size(1)\n",
    "                )\n",
    "                forces_size = forces_size.unsqueeze(1) / (l2_dist_power3 + _EPS)\n",
    "\n",
    "                pair_dist = torch.cat((dist_x.unsqueeze(-1), dist_y.unsqueeze(-1)), -1)\n",
    "                pair_dist = pair_dist.view(\n",
    "                    inputs.size(0),\n",
    "                    (inputs.size(2) - 1),\n",
    "                    inputs.size(1),\n",
    "                    inputs.size(1),\n",
    "                    2,\n",
    "                )\n",
    "                forces = (forces_size.unsqueeze(-1) * pair_dist).sum(3)\n",
    "\n",
    "            forces = forces.view(\n",
    "                inputs.size(0) * (inputs.size(2) - 1), inputs.size(1), 2\n",
    "            )\n",
    "\n",
    "            if \"_charged\" in self.interaction_type:  # charged particle sim\n",
    "                # Clip forces\n",
    "                forces[forces > self._max_F] = self._max_F\n",
    "                forces[forces < -self._max_F] = -self._max_F\n",
    "\n",
    "            # Leapfrog integration step\n",
    "            vel = vel + self._delta_T * forces\n",
    "            loc = loc + self._delta_T * vel\n",
    "\n",
    "            # Handle box boundaries\n",
    "            loc, vel = self.clamp(loc, vel)\n",
    "\n",
    "        loc, vel = self.renormalize(loc, vel)\n",
    "\n",
    "        loc = loc.view(inputs.size(0), (inputs.size(2) - 1), inputs.size(1), 2)\n",
    "        vel = vel.view(inputs.size(0), (inputs.size(2) - 1), inputs.size(1), 2)\n",
    "\n",
    "        loc = loc.permute(0, 2, 1, 3)\n",
    "        vel = vel.permute(0, 2, 1, 3)\n",
    "\n",
    "        out = torch.cat((loc, vel), dim=-1)\n",
    "        # Output has shape: [num_sims, num_things, num_timesteps-1, num_dims]\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### -------------------- utils files --------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### argparser.py\n",
    "\n",
    "from utils  \n",
    "called in train.py main\n",
    "\n",
    "--suffix _springs5_s200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import argparse\n",
    "# import torch\n",
    "# import datetime\n",
    "# import numpy as np\n",
    "\n",
    "\n",
    "def parse_args(\n",
    "    seed = 969491451,\n",
    "    GPU_to_use=None,\n",
    "    epochs = 3, #<--- #500\n",
    "    batch_size=128,\n",
    "    lr=0.0005,\n",
    "    lr_decay=200,\n",
    "    gamma=0.5,\n",
    "    training_samples=0,\n",
    "    test_samples=0,\n",
    "    shuffle_traindata=True,\n",
    "    prediction_steps=10,\n",
    "    encoder_hidden=256,\n",
    "    decoder_hidden=256,\n",
    "    encoder='mlp',\n",
    "    decoder='mlp', \n",
    "    prior=1,\n",
    "    edge_types=2, #?\n",
    "    dont_use_encoder=False,\n",
    "    lr_z=0.1,\n",
    "    global_temp=False,\n",
    "    alpha=2,\n",
    "    num_cats=3,\n",
    "    unobserved=0,\n",
    "    model_unobserved=0,\n",
    "    dont_shuffle_unobserved=False,\n",
    "    teacher_forcing=0,\n",
    "    suffix='_energy1', #<--- #_springs5_s200\n",
    "    timesteps= 24, #<---\n",
    "    num_atoms= 7, #<---\n",
    "    dims= 1, #<---\n",
    "    datadir='./data',\n",
    "    save_folder='logs',\n",
    "    expername=\"\",\n",
    "    sym_save_folder=\"../logs\",\n",
    "    load_folder='',\n",
    "    test_time_adapt=False,\n",
    "    lr_logits=0.01,\n",
    "    num_tta_steps=100,\n",
    "    dont_skip_first=False,\n",
    "    temp=0.5,\n",
    "    hard=False,\n",
    "    no_validate=False,\n",
    "    no_cuda=False,\n",
    "    var=5e-7,\n",
    "    encoder_dropout=0.0,\n",
    "    decoder_dropout=0.0,\n",
    "    no_factor=False\n",
    "    ):\n",
    "    \n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--seed\", \n",
    "                        type=int, \n",
    "                        default=seed, #42,\n",
    "                        help=\"Random seed.\")\n",
    "    parser.add_argument(\n",
    "        \"--GPU_to_use\", type=int, default=GPU_to_use, help=\"GPU to use for training\"\n",
    "    )\n",
    "\n",
    "    ############## training hyperparameter ##############\n",
    "    parser.add_argument(\n",
    "        \"--epochs\", type=int, \n",
    "        default = epochs,\n",
    "        # default=500, \n",
    "        help=\"Number of epochs to train.\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--batch_size\", type=int, default=batch_size, #128, \n",
    "        help=\"Number of samples per batch.\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--lr\", type=float, default=lr, #0.0005, \n",
    "        help=\"Initial learning rate.\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--lr_decay\",\n",
    "        type=int,\n",
    "        default=lr_decay,#200,\n",
    "        help=\"After how epochs to decay LR by a factor of gamma.\",\n",
    "    )\n",
    "    parser.add_argument(\"--gamma\", type=float, default=gamma,#0.5\n",
    "                        help=\"LR decay factor.\")\n",
    "    parser.add_argument(\n",
    "        \"--training_samples\", type=int, default=training_samples,\n",
    "        help=\"If 0 use all data available, otherwise reduce number of samples to given number\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--test_samples\", type=int, default=test_samples,\n",
    "        help=\"If 0 use all data available, otherwise reduce number of samples to given number\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--shuffle_traindata\", \n",
    "        action=\"store_true\",\n",
    "        default=shuffle_traindata,\n",
    "        help=\"If False, DataLoader for training data will provide shuffled batches, unshuffled o.w.\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--prediction_steps\",\n",
    "        type=int,\n",
    "        default=prediction_steps,#10,\n",
    "        metavar=\"N\",\n",
    "        help=\"Num steps to predict before re-using teacher forcing.\",\n",
    "    )\n",
    "\n",
    "    ############## architecture ##############\n",
    "    parser.add_argument(\n",
    "        \"--encoder_hidden\", type=int, default=encoder_hidden,#256, \n",
    "        help=\"Number of hidden units.\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--decoder_hidden\", type=int, default=decoder_hidden,#256, \n",
    "        help=\"Number of hidden units.\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--encoder\",\n",
    "        type=str,\n",
    "        default=encoder,#\"mlp\",\n",
    "        help=\"Type of path encoder model (mlp or cnn).\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--decoder\",\n",
    "        type=str,\n",
    "        default=decoder,#\"mlp\",\n",
    "        help=\"Type of decoder model (mlp, rnn, or sim).\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--prior\",\n",
    "        type=float,\n",
    "        default=prior,#1,\n",
    "        help=\"Weight for sparsity prior (if == 1, uniform prior is applied)\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--edge_types\",\n",
    "        type=int,\n",
    "        default=edge_types,#2,\n",
    "        help=\"Number of different edge-types to model\",\n",
    "    )\n",
    "\n",
    "    ########### Different variants for variational distribution q ###############\n",
    "    parser.add_argument(\n",
    "        \"--dont_use_encoder\",\n",
    "        action=\"store_true\",\n",
    "        default=dont_use_encoder,\n",
    "        help=\"If true, replace encoder with distribution to be estimated\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--lr_z\",\n",
    "        type=float,\n",
    "        default=lr_z,#0.1,\n",
    "        help=\"Learning rate for distribution estimation.\",\n",
    "    )\n",
    "\n",
    "    ### global latent temperature ###\n",
    "    parser.add_argument(\n",
    "        \"--global_temp\",\n",
    "        action=\"store_true\",\n",
    "        default=global_temp,\n",
    "        help=\"Should we model temperature confounding?\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--load_temperatures\",\n",
    "        help=\"Should we load temperature data?\",\n",
    "        action=\"store_true\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--alpha\",\n",
    "        type=float,\n",
    "        default=alpha,\n",
    "        help=\"Middle value of temperature distribution.\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--num_cats\",\n",
    "        type=int,\n",
    "        default=num_cats,\n",
    "        help=\"Number of categories in temperature distribution.\",\n",
    "    )\n",
    "\n",
    "    ### unobserved time-series ###\n",
    "    parser.add_argument(\n",
    "        \"--unobserved\",\n",
    "        type=int,\n",
    "        default=unobserved,\n",
    "        help=\"Number of time-series to mask from input.\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--model_unobserved\",\n",
    "        type=int,\n",
    "        default=model_unobserved,\n",
    "        help=\"If 0, use NRI to infer unobserved particle. \"\n",
    "        \"If 1, removes unobserved from data. \"\n",
    "        \"If 2, fills empty slot with mean of observed time-series (mean imputation)\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--dont_shuffle_unobserved\",\n",
    "        action=\"store_true\",\n",
    "        default=dont_shuffle_unobserved,\n",
    "        help=\"If true, always mask out last particle in trajectory. \"\n",
    "        \"If false, mask random particle.\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--teacher_forcing\",\n",
    "        type=int,\n",
    "        default=teacher_forcing,\n",
    "        help=\"Factor to determine how much true trajectory of \"\n",
    "        \"unobserved particle should be used to learn prediction.\",\n",
    "    )\n",
    "\n",
    "    ############## loading and saving ##############\n",
    "    parser.add_argument(\n",
    "        \"--suffix\",\n",
    "        type=str,\n",
    "        default=suffix,\n",
    "        # default=\"_springs5\",\n",
    "        help='Suffix for training data.',\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--timesteps\", type=int, default=timesteps, #49, \n",
    "        help=\"Number of timesteps in input.\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--num_atoms\", type=int, default= num_atoms,#5, \n",
    "        help=\"Number of time-series in input.\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--dims\", type=int, default= dims,#4, \n",
    "        help=\"Dimensionality of input.\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--datadir\",\n",
    "        type=str,\n",
    "        default=datadir,#\"./data\",\n",
    "        help=\"Name of directory where data is stored.\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--save_folder\",\n",
    "        type=str,\n",
    "        default=save_folder,\n",
    "        help=\"Where to save the trained model, leave empty to not save anything.\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--expername\",\n",
    "        type=str,\n",
    "        default=expername,\n",
    "        help=\"If given, creates a symlinked directory by this name in logdir\"\n",
    "        \"linked to the results file in save_folder\"\n",
    "        \"(be careful, this can overwrite previous results)\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--sym_save_folder\",\n",
    "        type=str,\n",
    "        default=sym_save_folder,\n",
    "        help=\"Name of directory where symlinked named experiment is created.\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--load_folder\",\n",
    "        type=str,\n",
    "        default=\"\",\n",
    "        help=\"Where to load pre-trained model if finetuning/evaluating. \"\n",
    "        + \"Leave empty to train from scratch\",\n",
    "    )\n",
    "\n",
    "    ############## fine tuning ##############\n",
    "    parser.add_argument(\n",
    "        \"--test_time_adapt\",\n",
    "        action=\"store_true\",\n",
    "        default=test_time_adapt,\n",
    "        help=\"Test time adapt q(z) on first half of test sequences.\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--lr_logits\",\n",
    "        type=float,\n",
    "        default=lr_logits, #0.01,\n",
    "        help=\"Learning rate for test-time adapting logits.\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--num_tta_steps\",\n",
    "        type=int,\n",
    "        default=num_tta_steps, #100,\n",
    "        help=\"Number of test-time-adaptation steps per batch.\",\n",
    "    )\n",
    "\n",
    "    ############## almost never change these ##############\n",
    "    parser.add_argument(\n",
    "        \"--dont_skip_first\",\n",
    "        action=\"store_true\",\n",
    "        default=dont_skip_first,\n",
    "        help=\"If given as argument, do not skip first edge type in decoder, i.e. it represents no-edge.\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--temp\", type=float, default=temp, help=\"Temperature for Gumbel softmax.\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--hard\",\n",
    "        action=\"store_true\",\n",
    "        default=hard,\n",
    "        help=\"Uses discrete samples in training forward pass.\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--no_validate\", action=\"store_true\", default=no_validate, help=\"Do not validate results throughout training.\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--no_cuda\", action=\"store_true\", default=no_cuda, #False, \n",
    "        help=\"Disables CUDA training.\"\n",
    "    )\n",
    "    parser.add_argument(\"--var\", type=float, default=var, help=\"Output variance.\")\n",
    "    parser.add_argument(\n",
    "        \"--encoder_dropout\",\n",
    "        type=float,\n",
    "        default=encoder_dropout, #0.0,\n",
    "        help=\"Dropout rate (1 - keep probability).\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--decoder_dropout\",\n",
    "        type=float,\n",
    "        default=decoder_dropout, #0.0,\n",
    "        help=\"Dropout rate (1 - keep probability).\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--no_factor\",\n",
    "        action=\"store_true\",\n",
    "        default=no_factor,\n",
    "        help=\"Disables factor graph model.\",\n",
    "    )\n",
    "    ########################################################\n",
    "    parser.add_argument('-f')\n",
    "    \n",
    "    args = parser.parse_args()\n",
    "    args.test = True\n",
    "\n",
    "    ### Presets for different datasets ###\n",
    "    if (\n",
    "        \"fixed\" in args.suffix\n",
    "        or \"uninfluenced\" in args.suffix\n",
    "        or \"influencer\" in args.suffix\n",
    "        or \"conf\" in args.suffix\n",
    "    ):\n",
    "        args.dont_shuffle_unobserved = True\n",
    "\n",
    "    if \"netsim\" in args.suffix:\n",
    "        args.dims = 1\n",
    "        args.num_atoms = 15\n",
    "        args.timesteps = 200\n",
    "        args.no_validate = True\n",
    "        args.test = False\n",
    "\n",
    "    args.device = torch.device(\"cuda:0\" if torch.cuda.is_available() and not args.no_cuda else \"cpu\")\n",
    "    args.cuda = not args.no_cuda and torch.cuda.is_available()\n",
    "    args.factor = not args.no_factor\n",
    "    args.validate = not args.no_validate\n",
    "    args.shuffle_unobserved = not args.dont_shuffle_unobserved\n",
    "    args.skip_first = not args.dont_skip_first\n",
    "    args.use_encoder = not args.dont_use_encoder\n",
    "    # args.time = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    args.time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")#.isoformat()\n",
    "\n",
    "    np.random.seed(args.seed)\n",
    "    torch.manual_seed(args.seed)\n",
    "\n",
    "    if args.device.type != \"cpu\":\n",
    "        if args.GPU_to_use is not None:\n",
    "            torch.cuda.set_device(args.GPU_to_use)\n",
    "        torch.cuda.manual_seed(args.seed)\n",
    "        args.num_GPU = 1  # torch.cuda.device_count()\n",
    "        args.batch_size_multiGPU = args.batch_size * args.num_GPU\n",
    "    else:\n",
    "        args.num_GPU = None\n",
    "        args.batch_size_multiGPU = args.batch_size\n",
    "\n",
    "    return args"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### logger.py\n",
    "\n",
    "from utils  \n",
    "called in train.py main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import time\n",
    "# import os\n",
    "# import torch\n",
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "# import math\n",
    "# import pandas as pd\n",
    "# from collections import defaultdict\n",
    "# import itertools\n",
    "\n",
    "\n",
    "class Logger:\n",
    "    def __init__(self, args):\n",
    "        self.args = args\n",
    "\n",
    "        self.train_losses = pd.DataFrame()\n",
    "        self.train_losses_idx = 0\n",
    "\n",
    "        self.test_losses = pd.DataFrame()\n",
    "        self.test_losses_idx = 0\n",
    "\n",
    "        if args.validate:\n",
    "            self.val_losses = pd.DataFrame()\n",
    "            self.val_losses_idx = 0\n",
    "        else:\n",
    "            self.val_losses = None\n",
    "\n",
    "        self.num_models_to_keep = 1\n",
    "        assert self.num_models_to_keep > 0, \"Dont delete all models!!!\"\n",
    "\n",
    "        self.create_log_path(args)\n",
    "\n",
    "    def create_log_path(self, args, add_path_var=\"\"):\n",
    "\n",
    "        print(type(args.time))\n",
    "        args.log_path = os.path.join(args.save_folder, args.time)#add_path_var, args.time)\n",
    "\n",
    "        if not os.path.exists(args.log_path):\n",
    "            os.makedirs(args.log_path)\n",
    "\n",
    "        if args.expername != \"\":\n",
    "            sympath = os.path.join(args.sym_save_folder, args.expername)\n",
    "            if os.path.islink(sympath):\n",
    "                os.remove(sympath)\n",
    "            ## check whether args.log_path is absolute path and if not concatenate with current working directory\n",
    "            if os.path.isabs(args.log_path):\n",
    "                log_link = args.log_path\n",
    "            else:\n",
    "                log_link = os.path.join(os.getcwd(), args.log_path)\n",
    "            os.symlink(log_link, sympath)\n",
    "\n",
    "        self.log_file = os.path.join(args.log_path, \"log.txt\")\n",
    "        self.write_to_log_file(args)\n",
    "\n",
    "        args.encoder_file = os.path.join(args.log_path, \"encoder.pt\")\n",
    "        args.decoder_file = os.path.join(args.log_path, \"decoder.pt\")\n",
    "        args.optimizer_file = os.path.join(args.log_path, \"optimizer.pt\")\n",
    "\n",
    "        args.plotdir = os.path.join(args.log_path, \"plots\")\n",
    "        if not os.path.exists(args.plotdir):\n",
    "            os.makedirs(args.plotdir)\n",
    "\n",
    "    def save_checkpoint(self, args, encoder, decoder, optimizer, specifier=\"\", rnn=None):\n",
    "        args.encoder_file = os.path.join(args.log_path, \"encoder\" + specifier + \".pt\")\n",
    "        args.decoder_file = os.path.join(args.log_path, \"decoder\" + specifier + \".pt\")\n",
    "        args.optimizer_file = os.path.join(\n",
    "            args.log_path, \"optimizer\" + specifier + \".pt\"\n",
    "        )\n",
    "\n",
    "        if encoder is not None:\n",
    "            torch.save(encoder.state_dict(), args.encoder_file)\n",
    "        if decoder is not None:\n",
    "            torch.save(decoder.state_dict(), args.decoder_file)\n",
    "        if rnn is not None:\n",
    "            args.rnn_file = os.path.join(args.log_path, \"rnn\" + specifier + \".pt\")\n",
    "            torch.save(rnn.state_dict(), args.rnn_file)\n",
    "        if optimizer is not None:\n",
    "            torch.save(optimizer.state_dict(), args.optimizer_file)\n",
    "\n",
    "    def write_to_log_file(self, string):\n",
    "        \"\"\"\n",
    "        Write given string in log-file and print as terminal output\n",
    "        \"\"\"\n",
    "        print(string)\n",
    "        cur_file = open(self.log_file, \"a\")\n",
    "        print(string, file=cur_file)\n",
    "        cur_file.close()\n",
    "\n",
    "    def create_log(\n",
    "        self,\n",
    "        args,\n",
    "        encoder=None,\n",
    "        decoder=None,\n",
    "        rnn=None,\n",
    "        accuracy=None,\n",
    "        optimizer=None,\n",
    "        final_test=False,\n",
    "        test_losses=None,\n",
    "    ):\n",
    "\n",
    "        print(\"Saving model and log-file to \" + args.log_path)\n",
    "\n",
    "        # Save losses throughout training and plot\n",
    "        self.train_losses.to_pickle(os.path.join(self.args.log_path, \"train_loss\"))#if error occurs, omit .csv again\n",
    "        self.train_losses.to_csv(os.path.join(self.args.log_path, \"train_loss.csv\"), index=False)\n",
    "\n",
    "        if self.val_losses is not None:\n",
    "            self.val_losses.to_pickle(os.path.join(self.args.log_path, \"val_loss\"))\n",
    "            self.val_losses.to_csv(os.path.join(self.args.log_path, \"val_loss.csv\"), index=False)\n",
    "\n",
    "\n",
    "        if accuracy is not None:\n",
    "            np.save(os.path.join(self.args.log_path, \"accuracy\"), accuracy)\n",
    "\n",
    "        specifier = \"\"\n",
    "        if final_test:\n",
    "            pd_test_losses = pd.DataFrame(\n",
    "                [\n",
    "                    [k] + [np.mean(v)]\n",
    "                    for k, v in test_losses.items()\n",
    "                    if type(v) != defaultdict\n",
    "                ],\n",
    "                columns=[\"loss\", \"score\"],\n",
    "            )\n",
    "            pd_test_losses.to_pickle(os.path.join(self.args.log_path, \"test_loss\"))\n",
    "            pd_test_losses.to_csv(os.path.join(self.args.log_path, \"test_loss.csv\"), index=False)\n",
    "\n",
    "            pd_test_losses_per_influenced = pd.DataFrame(\n",
    "                list(\n",
    "                    itertools.chain(\n",
    "                        *[\n",
    "                            [\n",
    "                                [k]\n",
    "                                + [idx]\n",
    "                                + [np.mean(list(itertools.chain.from_iterable(elem)))]\n",
    "                                for idx, elem in sorted(v.items())\n",
    "                            ]\n",
    "                            for k, v in test_losses.items()\n",
    "                            if type(v) == defaultdict\n",
    "                        ]\n",
    "                    )\n",
    "                ),\n",
    "                columns=[\"loss\", \"num_influenced\", \"score\"],\n",
    "            )\n",
    "            pd_test_losses_per_influenced.to_pickle(\n",
    "                os.path.join(self.args.log_path, \"test_loss_per_influenced\")\n",
    "            )\n",
    "\n",
    "            specifier = \"final\"\n",
    "\n",
    "        # Save the model checkpoint\n",
    "        self.save_checkpoint(args, encoder, decoder, optimizer, specifier=specifier, rnn=rnn)\n",
    "\n",
    "    def draw_loss_curves(self):\n",
    "        for i in self.train_losses.columns:\n",
    "            plt.figure()\n",
    "            plt.plot(self.train_losses[i], \"-b\", label=\"train \" + i)\n",
    "\n",
    "            if self.val_losses is not None and i in self.val_losses:\n",
    "                plt.plot(self.val_losses[i], \"-r\", label=\"val \" + i)\n",
    "\n",
    "            plt.xlabel(\"epoch\")\n",
    "            plt.ylabel(\"loss\")\n",
    "            plt.legend(loc=\"upper right\")\n",
    "\n",
    "            # save image\n",
    "            plt.savefig(os.path.join(self.args.log_path, i + \".png\"))\n",
    "            plt.close()\n",
    "\n",
    "    def append_train_loss(self, loss):\n",
    "        for k, v in loss.items():\n",
    "            self.train_losses.at[str(self.train_losses_idx), k] = np.mean(v)\n",
    "        self.train_losses_idx += 1\n",
    "\n",
    "    def append_val_loss(self, val_loss):\n",
    "        for k, v in val_loss.items():\n",
    "            self.val_losses.at[str(self.val_losses_idx), k] = np.mean(v)\n",
    "        self.val_losses_idx += 1\n",
    "\n",
    "    def append_test_loss(self, test_loss):\n",
    "        for k, v in test_loss.items():\n",
    "            if type(v) != defaultdict:\n",
    "                self.test_losses.at[str(self.test_losses_idx), k] = np.mean(v)\n",
    "        self.test_losses_idx += 1\n",
    "\n",
    "    def result_string(self, trainvaltest, epoch, losses, t=None):\n",
    "        string = \"\"\n",
    "        if trainvaltest == \"test\":\n",
    "            string += (\n",
    "                \"-------------------------------- \\n\"\n",
    "                \"--------Testing----------------- \\n\"\n",
    "                \"-------------------------------- \\n\"\n",
    "            )\n",
    "        else:\n",
    "            string += str(epoch) + \" \" + trainvaltest + \"\\t \\t\"\n",
    "\n",
    "        for loss, value in losses.items():\n",
    "            if type(value) == defaultdict:\n",
    "                string += loss + \" \"\n",
    "                for idx, elem in sorted(value.items()):\n",
    "                    string += str(idx) + \": {:.10f} \\t\".format(\n",
    "                        np.mean(list(itertools.chain.from_iterable(elem)))\n",
    "                    )\n",
    "            elif np.mean(value) != 0 and not math.isnan(np.mean(value)):\n",
    "                string += loss + \" {:.10f} \\t\".format(np.mean(value))\n",
    "\n",
    "        if t is not None:\n",
    "            string += \"time: {:.4f}s \\t\".format(time.time() - t)\n",
    "\n",
    "        return string\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### data_loader.py\n",
    "\n",
    "from utils  \n",
    "called in train.py main\n",
    "\n",
    "contains **(de)normalize()**, **unpack_batches()**  \n",
    "and **load_data()** which calls load_energy_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# import numpy as np\n",
    "# import torch\n",
    "# from torch.utils.data.dataset import TensorDataset\n",
    "# from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "def load_data(args):\n",
    "    loc_max, loc_min, vel_max, vel_min = None, None, None, None\n",
    "    train_loader, valid_loader, test_loader = None, None, None\n",
    "\n",
    "    if \"kuramoto\" in args.suffix:\n",
    "        train_loader, valid_loader, test_loader = load_ode_data(\n",
    "            args,\n",
    "            suffix=args.suffix,\n",
    "            batch_size=args.batch_size_multiGPU,\n",
    "            datadir=args.datadir,\n",
    "        )\n",
    "    elif \"netsim\" in args.suffix:\n",
    "        train_loader, loc_max, loc_min = load_netsim_data(\n",
    "            batch_size=args.batch_size_multiGPU, \n",
    "            datadir=args.datadir\n",
    "        )\n",
    "    elif \"springs\" in args.suffix:\n",
    "        (\n",
    "            train_loader,\n",
    "            valid_loader,\n",
    "            test_loader,\n",
    "            loc_max,\n",
    "            loc_min,\n",
    "            vel_max,\n",
    "            vel_min,\n",
    "        ) = load_springs_data(\n",
    "            args, \n",
    "            args.batch_size_multiGPU, \n",
    "            args.suffix, \n",
    "            datadir=args.datadir\n",
    "        )\n",
    "    elif \"energy\" in args.suffix:\n",
    "        train_loader, valid_loader, test_loader = load_energy_data(\n",
    "            args,\n",
    "            suffix=args.suffix,\n",
    "            batch_size=args.batch_size_multiGPU,\n",
    "            datadir=args.datadir\n",
    "        )\n",
    "    else:\n",
    "        raise NameError(\"Unknown data to be loaded\")\n",
    "\n",
    "    return train_loader, valid_loader, test_loader, loc_max, loc_min, vel_max, vel_min\n",
    "\n",
    "\n",
    "def normalize(x, x_min, x_max):\n",
    "    return (x - x_min) * 2 / (x_max - x_min) - 1\n",
    "\n",
    "\n",
    "def denormalize(x, x_min, x_max): # my addition to later look at prediction\n",
    "    return (x + 1) * (x_max - x_min)/2 + x_min\n",
    "\n",
    "\n",
    "def remove_unobserved_from_data(loc, vel, edge, args):\n",
    "    loc = loc[:, :, :, : -args.unobserved]\n",
    "    vel = vel[:, :, :, : -args.unobserved]\n",
    "    edge = edge[:, : -args.unobserved, : -args.unobserved]\n",
    "    return loc, vel, edge\n",
    "\n",
    "\n",
    "def get_off_diag_idx(num_atoms):\n",
    "    return np.ravel_multi_index(\n",
    "        np.where(np.ones((num_atoms, num_atoms)) - np.eye(num_atoms)),\n",
    "        [num_atoms, num_atoms],\n",
    "    )\n",
    "\n",
    "\n",
    "def data_preparation(\n",
    "    loc,\n",
    "    vel,\n",
    "    edges,\n",
    "    loc_min,\n",
    "    loc_max,\n",
    "    vel_min,\n",
    "    vel_max,\n",
    "    off_diag_idx,\n",
    "    num_atoms,\n",
    "    temperature=None,\n",
    "):\n",
    "    \"\"\"Based on https://github.com/ethanfetaya/NRI (MIT License).\"\"\"\n",
    "\n",
    "    # Normalize to [-1, 1]\n",
    "    loc = normalize(loc, loc_min, loc_max)\n",
    "    vel = normalize(vel, vel_min, vel_max)\n",
    "\n",
    "    # Reshape to: [num_sims, num_atoms, num_timesteps, num_dims]\n",
    "    loc = np.transpose(loc, [0, 3, 1, 2])\n",
    "    vel = np.transpose(vel, [0, 3, 1, 2])\n",
    "    feat = np.concatenate([loc, vel], axis=3)\n",
    "    edges = np.reshape(edges, [-1, num_atoms ** 2])\n",
    "    edges = np.array((edges + 1) / 2, dtype=np.int64)\n",
    "\n",
    "    feat = torch.FloatTensor(feat)\n",
    "    edges = torch.LongTensor(edges)\n",
    "\n",
    "    edges = edges[:, off_diag_idx]\n",
    "\n",
    "    if temperature is not None:\n",
    "        dataset = TensorDataset(feat, edges, temperature)\n",
    "    else:\n",
    "        dataset = TensorDataset(feat, edges)\n",
    "\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def load_springs_data(args, batch_size=1, suffix=\"\", datadir=\"data\"):\n",
    "    \"\"\"Based on https://github.com/ethanfetaya/NRI (MIT License).\"\"\"\n",
    "\n",
    "    print(\"Loading data from {}\".format(datadir))\n",
    "    loc_train = np.load(os.path.join(datadir, \"loc_train\" + suffix + \".npy\"))\n",
    "    vel_train = np.load(os.path.join(datadir, \"vel_train\" + suffix + \".npy\"))\n",
    "    edges_train = np.load(os.path.join(datadir, \"edges_train\" + suffix + \".npy\"))\n",
    "\n",
    "    loc_valid = np.load(os.path.join(datadir, \"loc_valid\" + suffix + \".npy\"))\n",
    "    vel_valid = np.load(os.path.join(datadir, \"vel_valid\" + suffix + \".npy\"))\n",
    "    edges_valid = np.load(os.path.join(datadir, \"edges_valid\" + suffix + \".npy\"))\n",
    "\n",
    "    loc_test = np.load(os.path.join(datadir, \"loc_test\" + suffix + \".npy\"))\n",
    "    vel_test = np.load(os.path.join(datadir, \"vel_test\" + suffix + \".npy\"))\n",
    "    edges_test = np.load(os.path.join(datadir, \"edges_test\" + suffix + \".npy\"))\n",
    "\n",
    "    if args.load_temperatures:\n",
    "        temperatures_train, temperatures_valid, temperatures_test = load_temperatures(\n",
    "            suffix=suffix, datadir=datadir\n",
    "        )\n",
    "    else:\n",
    "        temperatures_train, temperatures_valid, temperatures_test = None, None, None\n",
    "\n",
    "    # [num_samples, num_timesteps, num_dims, num_atoms]\n",
    "    if args.training_samples != 0:\n",
    "        loc_train = loc_train[: args.training_samples]\n",
    "        vel_train = vel_train[: args.training_samples]\n",
    "        edges_train = edges_train[: args.training_samples]\n",
    "\n",
    "    if args.test_samples != 0:\n",
    "        loc_test = loc_test[: args.test_samples]\n",
    "        vel_test = vel_test[: args.test_samples]\n",
    "        edges_test = edges_test[: args.test_samples]\n",
    "\n",
    "    loc_max = loc_train.max()\n",
    "    loc_min = loc_train.min()\n",
    "    vel_max = vel_train.max()\n",
    "    vel_min = vel_train.min()\n",
    "\n",
    "    # Exclude self edges\n",
    "    off_diag_idx = get_off_diag_idx(args.num_atoms)\n",
    "\n",
    "    train_data = data_preparation(\n",
    "        loc_train,\n",
    "        vel_train,\n",
    "        edges_train,\n",
    "        loc_min,\n",
    "        loc_max,\n",
    "        vel_min,\n",
    "        vel_max,\n",
    "        off_diag_idx,\n",
    "        args.num_atoms,\n",
    "        temperature=temperatures_train,\n",
    "    )\n",
    "    valid_data = data_preparation(\n",
    "        loc_valid,\n",
    "        vel_valid,\n",
    "        edges_valid,\n",
    "        loc_min,\n",
    "        loc_max,\n",
    "        vel_min,\n",
    "        vel_max,\n",
    "        off_diag_idx,\n",
    "        args.num_atoms,\n",
    "        temperature=temperatures_valid,\n",
    "    )\n",
    "    test_data = data_preparation(\n",
    "        loc_test,\n",
    "        vel_test,\n",
    "        edges_test,\n",
    "        loc_min,\n",
    "        loc_max,\n",
    "        vel_min,\n",
    "        vel_max,\n",
    "        off_diag_idx,\n",
    "        args.num_atoms,\n",
    "        temperature=temperatures_test,\n",
    "    )\n",
    "    train_data_loader = DataLoader(\n",
    "        train_data, batch_size=batch_size, shuffle=True, num_workers=8\n",
    "    )\n",
    "    valid_data_loader = DataLoader(valid_data, batch_size=batch_size, num_workers=8)\n",
    "    test_data_loader = DataLoader(test_data, batch_size=batch_size, num_workers=8)\n",
    "\n",
    "    return (\n",
    "        train_data_loader,\n",
    "        valid_data_loader,\n",
    "        test_data_loader,\n",
    "        loc_max,\n",
    "        loc_min,\n",
    "        vel_max,\n",
    "        vel_min,\n",
    "    )\n",
    "\n",
    "\n",
    "def load_temperatures(suffix=\"\", datadir=\"data\"):\n",
    "    temperatures_train = np.load(\n",
    "        os.path.join(datadir, \"temperatures_train\" + suffix + \".npy\")\n",
    "    )\n",
    "    temperatures_valid = np.load(\n",
    "        os.path.join(datadir, \"temperatures_valid\" + suffix + \".npy\")\n",
    "    )\n",
    "    temperatures_test = np.load(\n",
    "        os.path.join(datadir, \"temperatures_test\" + suffix + \".npy\")\n",
    "    )\n",
    "\n",
    "    temperatures_train = torch.FloatTensor(temperatures_train)\n",
    "    temperatures_valid = torch.FloatTensor(temperatures_valid)\n",
    "    temperatures_test = torch.FloatTensor(temperatures_test)\n",
    "\n",
    "    return temperatures_train, temperatures_valid, temperatures_test\n",
    "\n",
    "\n",
    "def load_ode_data(args, batch_size=1, suffix=\"\", datadir=\"data\"):\n",
    "    \"\"\"Based on https://github.com/ethanfetaya/NRI (MIT License).\"\"\"\n",
    "\n",
    "    feat_train = np.load(os.path.join(datadir, \"feat_train\" + suffix + \".npy\"))\n",
    "    edges_train = np.load(os.path.join(datadir, \"edges_train\" + suffix + \".npy\"))\n",
    "    feat_valid = np.load(os.path.join(datadir, \"feat_valid\" + suffix + \".npy\"))\n",
    "    edges_valid = np.load(os.path.join(datadir, \"edges_valid\" + suffix + \".npy\"))\n",
    "    feat_test = np.load(os.path.join(datadir, \"feat_test\" + suffix + \".npy\"))\n",
    "    edges_test = np.load(os.path.join(datadir, \"edges_test\" + suffix + \".npy\"))\n",
    "\n",
    "    # [num_sims, num_atoms, num_timesteps, num_dims]\n",
    "    num_atoms = feat_train.shape[1]\n",
    "\n",
    "    if args.training_samples != 0:\n",
    "        feat_train = feat_train[: args.training_samples]\n",
    "        edges_train = edges_train[: args.training_samples]\n",
    "\n",
    "    if args.test_samples != 0:\n",
    "        feat_test = feat_test[: args.test_samples]\n",
    "        edges_test = edges_test[: args.test_samples]\n",
    "\n",
    "    # Reshape to: [num_sims, num_atoms * num_atoms]\n",
    "    edges_train = np.reshape(edges_train, [-1, num_atoms ** 2])\n",
    "    edges_valid = np.reshape(edges_valid, [-1, num_atoms ** 2])\n",
    "    edges_test = np.reshape(edges_test, [-1, num_atoms ** 2])\n",
    "\n",
    "    edges_train = edges_train / np.max(edges_train)\n",
    "    edges_valid = edges_valid / np.max(edges_valid)\n",
    "    edges_test = edges_test / np.max(edges_test)\n",
    "\n",
    "    feat_train = torch.FloatTensor(feat_train)\n",
    "    edges_train = torch.LongTensor(edges_train)\n",
    "    feat_valid = torch.FloatTensor(feat_valid)\n",
    "    edges_valid = torch.LongTensor(edges_valid)\n",
    "    feat_test = torch.FloatTensor(feat_test)\n",
    "    edges_test = torch.LongTensor(edges_test)\n",
    "\n",
    "    # Exclude self edges\n",
    "    off_diag_idx = get_off_diag_idx(num_atoms)\n",
    "    edges_train = edges_train[:, off_diag_idx]\n",
    "    edges_valid = edges_valid[:, off_diag_idx]\n",
    "    edges_test = edges_test[:, off_diag_idx]\n",
    "\n",
    "    train_data = TensorDataset(feat_train, edges_train)\n",
    "    valid_data = TensorDataset(feat_valid, edges_valid)\n",
    "    test_data = TensorDataset(feat_test, edges_test)\n",
    "\n",
    "    train_data_loader = DataLoader(\n",
    "        train_data, batch_size=batch_size, shuffle=True\n",
    "    )  # , num_workers=8\n",
    "    # )\n",
    "    valid_data_loader = DataLoader(valid_data, batch_size=batch_size, num_workers=8)\n",
    "    test_data_loader = DataLoader(\n",
    "        test_data, batch_size=batch_size\n",
    "    )  # , num_workers=8) ##THIS\n",
    "\n",
    "    return train_data_loader, valid_data_loader, test_data_loader\n",
    "\n",
    "\n",
    "def load_data_for_ncg(datadir, data_index, suffix):\n",
    "    \"\"\"Data loading for Neural Granger Causality method (one example at a time).\"\"\"\n",
    "    feat_train = np.load(os.path.join(datadir, \"feat_train_small\" + suffix + \".npy\"))\n",
    "    edges_train = np.load(os.path.join(datadir, \"edges_train_small\" + suffix + \".npy\"))\n",
    "    return feat_train[data_index], edges_train[data_index]\n",
    "\n",
    "\n",
    "def load_netsim_data(batch_size=1, datadir=\"data\"):\n",
    "    print(\"Loading data from {}\".format(datadir))\n",
    "\n",
    "    subject_id = [1, 2, 3, 4, 5]\n",
    "\n",
    "    print(\"Loading data for subjects \", subject_id)\n",
    "\n",
    "    loc_train = torch.zeros(len(subject_id), 15, 200)\n",
    "    edges_train = torch.zeros(len(subject_id), 15, 15)\n",
    "\n",
    "    for idx, elem in enumerate(subject_id):\n",
    "        fileName = \"sim3_subject_%s.npz\" % (elem)\n",
    "        ld = np.load(os.path.join(datadir, \"netsim\", fileName))\n",
    "        loc_train[idx] = torch.FloatTensor(ld[\"X_np\"])\n",
    "        edges_train[idx] = torch.LongTensor(ld[\"Gref\"])\n",
    "\n",
    "    # [num_sims, num_atoms, num_timesteps, num_dims]\n",
    "    loc_train = loc_train.unsqueeze(-1)\n",
    "\n",
    "    loc_max = loc_train.max()\n",
    "    loc_min = loc_train.min()\n",
    "    loc_train = normalize(loc_train, loc_min, loc_max)\n",
    "\n",
    "    # Exclude self edges\n",
    "    num_atoms = loc_train.shape[1]\n",
    "\n",
    "    off_diag_idx = get_off_diag_idx(num_atoms)\n",
    "    edges_train = torch.reshape(edges_train, [-1, num_atoms ** 2])\n",
    "    edges_train = (edges_train + 1) // 2\n",
    "    edges_train = edges_train[:, off_diag_idx]\n",
    "\n",
    "    train_data = TensorDataset(loc_train, edges_train)\n",
    "\n",
    "    train_data_loader = DataLoader(\n",
    "        train_data, batch_size=batch_size, shuffle=True, num_workers=8\n",
    "    )\n",
    "\n",
    "    return (train_data_loader, loc_max, loc_min)\n",
    "\n",
    "def unpack_batches(args, minibatch):\n",
    "    if args.load_temperatures:\n",
    "        (data, relations, temperatures) = minibatch\n",
    "    else:\n",
    "        (data, relations) = minibatch\n",
    "        temperatures = None\n",
    "    if args.cuda:\n",
    "        data, relations = data.cuda(), relations.cuda()\n",
    "        if args.load_temperatures:\n",
    "            temperatures = temperatures.cuda()\n",
    "    return data, relations, temperatures\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load_energy_data function\n",
    "\n",
    "---> shuffle DataLoader: False, originally: True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_energy_data(args, batch_size=1, suffix=\"\", datadir=\"data\"):\n",
    "    print(\"Loading data from {}\".format(datadir))\n",
    "    feat_train = np.load(os.path.join(datadir, \"feat_train\" + suffix + \".npy\"))\n",
    "    edges_train = np.load(os.path.join(datadir, \"edges_train\" + suffix + \".npy\"))\n",
    "    feat_valid = np.load(os.path.join(datadir, \"feat_valid\" + suffix + \".npy\"))\n",
    "    edges_valid = np.load(os.path.join(datadir, \"edges_valid\" + suffix + \".npy\"))\n",
    "    feat_test  = np.load(os.path.join(datadir, \"feat_test\" + suffix + \".npy\"))\n",
    "    edges_test  = np.load(os.path.join(datadir, \"edges_test\" + suffix + \".npy\"))\n",
    "    if 'lstm' in suffix:\n",
    "        target_train = np.load(os.path.join(datadir, \"target_train\" + suffix + \".npy\"))\n",
    "        target_valid = np.load(os.path.join(datadir, \"target_valid\" + suffix + \".npy\"))\n",
    "        target_test  = np.load(os.path.join(datadir, \"target_test\" + suffix + \".npy\"))\n",
    "  \n",
    "    # [num_sims, num_atoms, num_timesteps, num_dims]\n",
    "    num_atoms = feat_train.shape[1]\n",
    "    \n",
    "    if args.training_samples != 0:\n",
    "        feat_train = feat_train[: args.training_samples]\n",
    "        edges_train = edges_train[: args.training_samples]\n",
    "\n",
    "    if args.test_samples != 0:\n",
    "        feat_test = feat_test[: args.test_samples]\n",
    "        edges_test = edges_test[: args.test_samples]\n",
    "\n",
    "    # Reshape to: [num_sims, num_atoms * num_atoms]\n",
    "    edges_train = np.reshape(edges_train, [-1, num_atoms ** 2])\n",
    "    edges_valid = np.reshape(edges_valid, [-1, num_atoms ** 2])\n",
    "    edges_test = np.reshape(edges_test, [-1, num_atoms ** 2])\n",
    "\n",
    "    edges_train = edges_train / np.max(edges_train)\n",
    "    edges_valid = edges_valid / np.max(edges_valid)\n",
    "    edges_test = edges_test / np.max(edges_test)\n",
    "\n",
    "    feat_train = torch.FloatTensor(feat_train)\n",
    "    edges_train = torch.LongTensor(edges_train)\n",
    "    feat_valid = torch.FloatTensor(feat_valid)\n",
    "    edges_valid = torch.LongTensor(edges_valid)\n",
    "    feat_test = torch.FloatTensor(feat_test)\n",
    "    edges_test = torch.LongTensor(edges_test)\n",
    "    \n",
    "    # Exclude self edges\n",
    "    off_diag_idx = get_off_diag_idx(num_atoms)\n",
    "    edges_train = edges_train[:, off_diag_idx]\n",
    "    edges_valid = edges_valid[:, off_diag_idx]\n",
    "    edges_test = edges_test[:, off_diag_idx]\n",
    "    \n",
    "    if 'lstm' not in suffix:\n",
    "        train_data = TensorDataset(feat_train, edges_train)\n",
    "        valid_data = TensorDataset(feat_valid, edges_valid)\n",
    "        test_data = TensorDataset(feat_test, edges_test)\n",
    "    else: \n",
    "        target_train = torch.FloatTensor(target_train)\n",
    "        target_valid = torch.FloatTensor(target_valid) \n",
    "        target_test = torch.FloatTensor(target_test)\n",
    "        train_data = TensorDataset(feat_train, target_train)\n",
    "        valid_data = TensorDataset(feat_valid, target_valid)\n",
    "        test_data = TensorDataset(feat_test, target_test)\n",
    "\n",
    "    train_data_loader = DataLoader(\n",
    "        train_data, \n",
    "        batch_size=batch_size, \n",
    "        shuffle=args.shuffle_traindata #probably what i need without timedims\n",
    "        # shuffle=True #original\n",
    "    )  # , num_workers=8\n",
    "    # )\n",
    "    valid_data_loader = DataLoader(valid_data, batch_size=batch_size, num_workers=8)\n",
    "    test_data_loader = DataLoader(\n",
    "        test_data, batch_size=batch_size\n",
    "    )  # , num_workers=8) ##THIS\n",
    "\n",
    "    return train_data_loader, valid_data_loader, test_data_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### forward_pass_and_eval.py\n",
    "\n",
    "from utils\n",
    "called in train.py train\n",
    "\n",
    "test_time_adapt function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from __future__ import division\n",
    "# from __future__ import print_function\n",
    "\n",
    "# from collections import defaultdict\n",
    "# import time\n",
    "# import torch\n",
    "\n",
    "# import numpy as np\n",
    "\n",
    "# from model.modules import *\n",
    "# from model import utils, utils_unobserved\n",
    "\n",
    "\n",
    "def test_time_adapt(\n",
    "    args,\n",
    "    logits,\n",
    "    decoder,\n",
    "    data_encoder,\n",
    "    rel_rec,\n",
    "    rel_send,\n",
    "    predicted_atoms,\n",
    "    log_prior,\n",
    "):\n",
    "    with torch.enable_grad():\n",
    "        tta_data_decoder = data_encoder.detach()\n",
    "\n",
    "        if args.use_encoder:\n",
    "            ### initialize q(z) with q(z|x)\n",
    "            tta_logits = logits.detach()\n",
    "            tta_logits.requires_grad = True\n",
    "        else:\n",
    "            ### initialize q(z) randomly\n",
    "            tta_logits = torch.randn_like(\n",
    "                logits, device=args.device.type, requires_grad=True\n",
    "            )\n",
    "\n",
    "        tta_optimizer = torch.optim.Adam(\n",
    "            [{\"params\": tta_logits, \"lr\": args.lr_logits}]\n",
    "        )\n",
    "        tta_target = data_encoder[:, :, 1:, :].detach()\n",
    "\n",
    "        ploss = 0\n",
    "        for i in range(args.num_tta_steps):\n",
    "            tta_optimizer.zero_grad()\n",
    "\n",
    "            tta_edges = gumbel_softmax(tta_logits, tau=args.temp, hard=False)\n",
    "\n",
    "            tta_output = decoder(\n",
    "                tta_data_decoder, tta_edges, rel_rec, rel_send, args.prediction_steps\n",
    "            )\n",
    "\n",
    "            loss = nll_gaussian(tta_output, tta_target, args.var)\n",
    "\n",
    "            prob = my_softmax(tta_logits, -1)\n",
    "\n",
    "            if args.prior != 1:\n",
    "                loss += kl_categorical(prob, log_prior, predicted_atoms) \n",
    "            else:\n",
    "                loss += kl_categorical_uniform(\n",
    "                    prob, predicted_atoms, args.edge_types\n",
    "                ) \n",
    "\n",
    "            loss.backward()\n",
    "            tta_optimizer.step()\n",
    "            ploss += loss.cpu().detach()\n",
    "\n",
    "            if i == 0:\n",
    "                first_loss = loss.cpu().detach()\n",
    "            if (i + 1) % 10 == 0:\n",
    "                print(i, \": \", ploss / 10)\n",
    "                ploss = 0\n",
    "\n",
    "    print(\"Fine-tuning improvement: \", first_loss - loss.cpu().detach())\n",
    "\n",
    "    return tta_logits\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "forward_pass_and_eval function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def forward_pass_and_eval(\n",
    "    args,\n",
    "    encoder,\n",
    "    decoder,\n",
    "    data,\n",
    "    relations,\n",
    "    rel_rec,\n",
    "    rel_send,\n",
    "    hard,\n",
    "    data_encoder=None,\n",
    "    data_decoder=None,\n",
    "    edge_probs=None,\n",
    "    testing=False,\n",
    "    log_prior=None,\n",
    "    temperatures=None\n",
    "):\n",
    "    start = time.time()\n",
    "    losses = defaultdict(lambda: torch.zeros((), device=args.device.type))\n",
    "\n",
    "    #################### INPUT DATA ####################\n",
    "    diff_data_enc_dec = False\n",
    "    if data_encoder is not None and data_decoder is not None:\n",
    "        diff_data_enc_dec = True\n",
    "\n",
    "    if data_encoder is None:\n",
    "        data_encoder = data\n",
    "    if data_decoder is None:\n",
    "        data_decoder = data\n",
    "\n",
    "    #################### DATA WITH UNOBSERVED TIME-SERIES ####################\n",
    "    predicted_atoms = args.num_atoms\n",
    "    if args.unobserved > 0:\n",
    "        if args.shuffle_unobserved:\n",
    "            mask_idx = np.random.randint(0, args.num_atoms)\n",
    "        else:\n",
    "            mask_idx = args.num_atoms - 1\n",
    "\n",
    "        ### baselines ###\n",
    "        if args.model_unobserved == 1:\n",
    "            (\n",
    "                data_encoder,\n",
    "                data_decoder,\n",
    "                predicted_atoms,\n",
    "                relations,\n",
    "            ) = baseline_remove_unobserved(\n",
    "                args, data_encoder, data_decoder, mask_idx, relations, predicted_atoms\n",
    "            )\n",
    "            unobserved = 0\n",
    "        if args.model_unobserved == 2:\n",
    "            (\n",
    "                data_encoder,\n",
    "                unobserved,\n",
    "                losses[\"mse_unobserved\"],\n",
    "            ) = baseline_mean_imputation(args, data_encoder, mask_idx)\n",
    "            data_decoder = add_unobserved_to_data(\n",
    "                args, data_decoder, unobserved, mask_idx, diff_data_enc_dec\n",
    "            )\n",
    "    else:\n",
    "        mask_idx = 0\n",
    "        unobserved = 0\n",
    "\n",
    "    #################### TEMPERATURE INFERENCE ####################\n",
    "    if args.global_temp:\n",
    "        ctp = args.categorical_temperature_prior\n",
    "        cmax = ctp[-1]\n",
    "        uniform_prior_mean = cmax\n",
    "        uniform_prior_width = cmax \n",
    "\n",
    "    #################### ENCODER ####################\n",
    "    if args.use_encoder:\n",
    "        if args.unobserved > 0 and args.model_unobserved == 0:\n",
    "            ## model unobserved time-series\n",
    "            (\n",
    "                logits,\n",
    "                unobserved,\n",
    "                losses[\"mse_unobserved\"],\n",
    "            ) = encoder(data_encoder, rel_rec, rel_send, mask_idx=mask_idx)\n",
    "            data_decoder = add_unobserved_to_data(\n",
    "                args, data_decoder, unobserved, mask_idx, diff_data_enc_dec\n",
    "            )\n",
    "        elif args.global_temp:\n",
    "            (logits, temperature_samples, \n",
    "                    inferred_mean, inferred_width) = encoder(\n",
    "                            data_encoder, rel_rec, rel_send)\n",
    "            temperature_samples *= 2 * cmax\n",
    "            inferred_mean *= 2 * cmax \n",
    "            inferred_width *= 2 * cmax\n",
    "        else:\n",
    "            ## model only the edges\n",
    "            logits = encoder(data_encoder, rel_rec, rel_send)\n",
    "    else:\n",
    "        logits = edge_probs.unsqueeze(0).repeat(data_encoder.shape[0], 1, 1)\n",
    "\n",
    "    if args.test_time_adapt and args.num_tta_steps > 0 and testing:\n",
    "        assert args.unobserved == 0, \"No implementation for test-time adaptation when there are unobserved time-series.\"\n",
    "        logits = test_time_adapt(\n",
    "            args,\n",
    "            logits,\n",
    "            decoder,\n",
    "            data_encoder,\n",
    "            rel_rec,\n",
    "            rel_send,\n",
    "            predicted_atoms,\n",
    "            log_prior,\n",
    "        )\n",
    "\n",
    "    edges = gumbel_softmax(logits, tau=args.temp, hard=hard)\n",
    "    prob = my_softmax(logits, -1)\n",
    "\n",
    "    target = data_decoder[:, :, 1:, :]\n",
    "\n",
    "    #################### DECODER ####################\n",
    "    if args.decoder == \"rnn\":\n",
    "        output = decoder(\n",
    "            data_decoder,\n",
    "            edges,\n",
    "            rel_rec,\n",
    "            rel_send,\n",
    "            pred_steps=args.prediction_steps,\n",
    "            burn_in=True,\n",
    "            burn_in_steps=args.timesteps - args.prediction_steps,\n",
    "        )\n",
    "    else:\n",
    "        if args.global_temp:\n",
    "            output = decoder(\n",
    "                data_decoder, \n",
    "                edges, \n",
    "                temperature_samples, \n",
    "                rel_rec, \n",
    "                rel_send, \n",
    "                args.prediction_steps\n",
    "            )\n",
    "        else:\n",
    "            output = decoder(\n",
    "                data_decoder,\n",
    "                edges,\n",
    "                rel_rec,\n",
    "                rel_send,\n",
    "                args.prediction_steps,\n",
    "            )\n",
    "\n",
    "    #################### LOSSES ####################\n",
    "    if args.unobserved > 0:\n",
    "        if args.model_unobserved != 1:\n",
    "            losses[\"mse_observed\"] = calc_mse_observed(\n",
    "                args, output, target, mask_idx\n",
    "            )\n",
    "\n",
    "            if not args.shuffle_unobserved:\n",
    "                losses[\"observed_acc\"] = edge_accuracy_observed(\n",
    "                    logits, relations, num_atoms=args.num_atoms\n",
    "                )\n",
    "                losses[\"observed_auroc\"] = calc_auroc_observed(\n",
    "                    prob, relations, num_atoms=args.num_atoms\n",
    "                )\n",
    "\n",
    "    if args.global_temp:\n",
    "        losses['loss_kl_temp'] = kl_uniform(inferred_width, uniform_prior_width)\n",
    "        losses['temp_logprob'] = get_uniform_logprobs(\n",
    "                inferred_mean.flatten(), inferred_width.flatten(), temperatures)\n",
    "        targets = torch.eq(torch.reshape(ctp, [1, -1]), torch.reshape(temperatures, [-1, 1])).double()\n",
    "        preds = get_preds_from_uniform(inferred_mean, inferred_width, ctp)\n",
    "\n",
    "        losses['temp_precision'] = torch.sum(targets * preds) / torch.sum(preds)\n",
    "        losses['temp_recall'] = torch.sum(targets * preds) / torch.sum(targets)\n",
    "        losses['temp_corr'] = get_correlation(inferred_mean.flatten(), temperatures)\n",
    "\n",
    "    ## calculate performance based on how many particles are influenced by unobserved one/last one\n",
    "    if not args.shuffle_unobserved and args.unobserved > 0:\n",
    "        losses = calc_performance_per_num_influenced(\n",
    "            args,\n",
    "            relations,\n",
    "            output,\n",
    "            target,\n",
    "            logits,\n",
    "            prob,\n",
    "            mask_idx,\n",
    "            losses\n",
    "        )\n",
    "\n",
    "    #################### MAIN LOSSES ####################\n",
    "    ### latent losses ###\n",
    "    losses[\"loss_kl\"] = kl_latent(args, prob, log_prior, predicted_atoms)\n",
    "    losses[\"acc\"] = edge_accuracy(logits, relations)\n",
    "    losses[\"auroc\"] = calc_auroc(prob, relations)\n",
    "\n",
    "    ### output losses ###\n",
    "    losses[\"loss_nll\"] = nll_gaussian(\n",
    "        output, target, args.var\n",
    "    ) \n",
    "\n",
    "    losses[\"loss_mse\"] = F.mse_loss(output, target)\n",
    "\n",
    "    total_loss = losses[\"loss_nll\"] + losses[\"loss_kl\"]\n",
    "    total_loss += args.teacher_forcing * losses[\"mse_unobserved\"]\n",
    "    if args.global_temp:\n",
    "        total_loss += losses['loss_kl_temp']\n",
    "    losses[\"loss\"] = total_loss\n",
    "\n",
    "    losses[\"inference time\"] = time.time() - start\n",
    "\n",
    "    return losses, output, unobserved, edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def forward_pass_rnn(\n",
    "    args,\n",
    "    rnn,\n",
    "    data,\n",
    "    target\n",
    "):\n",
    "    start = time.time()\n",
    "    losses = defaultdict(lambda: torch.zeros((), device=args.device.type))\n",
    "    \n",
    "    output = rnn(data).unsqueeze(1)\n",
    "    \n",
    "    losses[\"loss_mse\"] = F.mse_loss(output, target)\n",
    "    losses[\"inference time\"] = time.time() - start\n",
    "\n",
    "    return losses, output\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### -------------------- train file --------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from __future__ import division\n",
    "# from __future__ import print_function\n",
    "\n",
    "# from collections import defaultdict\n",
    "\n",
    "# import time\n",
    "# import numpy as np\n",
    "# import torch\n",
    "\n",
    "# from model.modules import *\n",
    "# from utils import arg_parser, logger, data_loader, forward_pass_and_eval\n",
    "# from model import utils, model_loader\n",
    "\n",
    "\n",
    "def train():\n",
    "    best_val_loss = np.inf\n",
    "    best_epoch = 0\n",
    "\n",
    "    for epoch in range(args.epochs):\n",
    "        t_epoch = time.time()\n",
    "        train_losses = defaultdict(list)\n",
    "\n",
    "        for batch_idx, minibatch in enumerate(train_loader):\n",
    "\n",
    "            data, relations, temperatures = unpack_batches(args, minibatch)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            losses, _, _, _ = forward_pass_and_eval(\n",
    "                args,\n",
    "                encoder,\n",
    "                decoder,\n",
    "                data,\n",
    "                relations,\n",
    "                rel_rec,\n",
    "                rel_send,\n",
    "                args.hard,\n",
    "                edge_probs=edge_probs,\n",
    "                log_prior=log_prior,\n",
    "                temperatures=temperatures,\n",
    "            )\n",
    "\n",
    "            loss = losses[\"loss\"]\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_losses = append_losses(train_losses, losses)\n",
    "\n",
    "        string = logs.result_string(\"train\", epoch, train_losses, t=t_epoch)\n",
    "        logs.write_to_log_file(string)\n",
    "        logs.append_train_loss(train_losses)\n",
    "        scheduler.step()\n",
    "\n",
    "        if args.validate:\n",
    "            val_losses = val(epoch)\n",
    "            val_loss = np.mean(val_losses[\"loss\"])\n",
    "            if val_loss < best_val_loss:\n",
    "                print(\"Best model so far, saving...\")\n",
    "                logs.create_log(\n",
    "                    args,\n",
    "                    encoder=encoder,\n",
    "                    decoder=decoder,\n",
    "                    optimizer=optimizer,\n",
    "                    accuracy=np.mean(val_losses[\"acc\"]),\n",
    "                )\n",
    "                best_val_loss = val_loss\n",
    "                best_epoch = epoch\n",
    "        elif (epoch + 1) % 100 == 0:\n",
    "            logs.create_log(\n",
    "                args,\n",
    "                encoder=encoder,\n",
    "                decoder=decoder,\n",
    "                optimizer=optimizer,\n",
    "                accuracy=np.mean(train_losses[\"acc\"]),\n",
    "            )\n",
    "\n",
    "        logs.draw_loss_curves()\n",
    "\n",
    "    return best_epoch, epoch\n",
    "\n",
    "\n",
    "def val(epoch):\n",
    "    t_val = time.time()\n",
    "    val_losses = defaultdict(list)\n",
    "\n",
    "    if args.use_encoder:\n",
    "        encoder.eval()\n",
    "    decoder.eval()\n",
    "\n",
    "    for batch_idx, minibatch in enumerate(valid_loader):\n",
    "\n",
    "        data, relations, temperatures = unpack_batches(args, minibatch)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            losses, _, _, _ = forward_pass_and_eval(\n",
    "                args,\n",
    "                encoder,\n",
    "                decoder,\n",
    "                data,\n",
    "                relations,\n",
    "                rel_rec,\n",
    "                rel_send,\n",
    "                True,\n",
    "                edge_probs=edge_probs,\n",
    "                log_prior=log_prior,\n",
    "                testing=True,\n",
    "                temperatures=temperatures,\n",
    "            )\n",
    "\n",
    "        val_losses = append_losses(val_losses, losses)\n",
    "\n",
    "    string = logs.result_string(\"validate\", epoch, val_losses, t=t_val)\n",
    "    logs.write_to_log_file(string)\n",
    "    logs.append_val_loss(val_losses)\n",
    "\n",
    "    if args.use_encoder:\n",
    "        encoder.train()\n",
    "    decoder.train()\n",
    "\n",
    "    return val_losses\n",
    "\n",
    "\n",
    "def test(encoder, decoder, epoch):\n",
    "    args.shuffle_unobserved = False\n",
    "    # args.prediction_steps = 49\n",
    "    test_losses = defaultdict(list)\n",
    "\n",
    "    if args.load_folder == \"\":\n",
    "        ## load model that had the best validation performance during training\n",
    "        if args.use_encoder:\n",
    "            encoder.load_state_dict(torch.load(args.encoder_file))\n",
    "        decoder.load_state_dict(torch.load(args.decoder_file))\n",
    "\n",
    "    if args.use_encoder:\n",
    "        encoder.eval()\n",
    "    decoder.eval()\n",
    "\n",
    "    for batch_idx, minibatch in enumerate(test_loader):\n",
    "\n",
    "        data, relations, temperatures = unpack_batches(args, minibatch)\n",
    "        # print(data.shape)\n",
    "        # print(relations.shape)\n",
    "        # print(data.size(2))\n",
    "        # print(args.timesteps)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            assert (data.size(2) - args.timesteps) >= args.timesteps\n",
    "\n",
    "            data_encoder = data[:, :, : args.timesteps, :].contiguous()\n",
    "            data_decoder = data[:, :, args.timesteps : -1, :].contiguous()\n",
    "\n",
    "            losses, _, _, _, = forward_pass_and_eval(\n",
    "                args,\n",
    "                encoder,\n",
    "                decoder,\n",
    "                data,\n",
    "                relations,\n",
    "                rel_rec,\n",
    "                rel_send,\n",
    "                True,\n",
    "                data_encoder=data_encoder,\n",
    "                data_decoder=data_decoder,\n",
    "                edge_probs=edge_probs,\n",
    "                log_prior=log_prior,\n",
    "                testing=True,\n",
    "                temperatures=temperatures,\n",
    "            )\n",
    "\n",
    "        test_losses = append_losses(test_losses, losses)\n",
    "\n",
    "    string = logs.result_string(\"test\", epoch, test_losses)\n",
    "    logs.write_to_log_file(string)\n",
    "    logs.append_test_loss(test_losses)\n",
    "\n",
    "    logs.create_log(\n",
    "        args,\n",
    "        decoder=decoder,\n",
    "        encoder=encoder,\n",
    "        optimizer=optimizer,\n",
    "        final_test=True,\n",
    "        test_losses=test_losses,\n",
    "    )\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
