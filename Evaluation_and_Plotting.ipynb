{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Master Thesis Machine Learing  \n",
    "Gwen Hirsch  \n",
    "2022\n",
    "\n",
    "# Evaluate model performances and create plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### imports and variable definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\base2\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "#own imports\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import torch\n",
    "import networkx as nx\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import cm\n",
    "from matplotlib import colors\n",
    "import matplotlib.ticker as mticker\n",
    "import matplotlib.dates as mdates\n",
    "import pytz\n",
    "from scipy import stats\n",
    "from statsmodels.tsa.stattools import grangercausalitytests\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from scipy.stats import rv_histogram\n",
    "import gc\n",
    "pd.options.display.max_rows = 4000\n",
    "pd.options.display.max_columns = 4000\n",
    "import properscoring as ps\n",
    "\n",
    "#acd imports\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from collections import defaultdict\n",
    "import time\n",
    "import argparse\n",
    "import os\n",
    "import math\n",
    "import itertools\n",
    "from torch.utils.data.dataset import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.distributions as tdist\n",
    "from torch.autograd import Variable\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from abc import abstractmethod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# lists that contain subsets of names later needed for filtering the dataframe columns\n",
    "# columns I want to predict\n",
    "vars_of_interest = ['load_actual', 'solar_generation', 'wind_generation' , 'price_day_ahead']\n",
    "\n",
    "# countries to include in dataset\n",
    "prefixes = ['DE_', 'FR_', 'CH_', 'GB_']\n",
    "\n",
    "# lists of the columns with variables of interest\n",
    "cols_of_interest = [prefix+var for prefix in prefixes for var in vars_of_interest]\n",
    "cols_of_interest_DE = ['DE_'+var for var in vars_of_interest]\n",
    "cols_of_interest_FR = ['FR_'+var for var in vars_of_interest]\n",
    "cols_of_interest_CH = ['CH_'+var for var in vars_of_interest]\n",
    "cols_of_interest_GB = ['GB_'+var for var in vars_of_interest]\n",
    "\n",
    "# lists of the columns with weather variables\n",
    "vars_weather = ['temperature', 'radiation_direct_horizontal', 'radiation_diffuse_horizontal']\n",
    "cols_weather = [prefix+var for prefix in prefixes for var in vars_weather]\n",
    "cols_weather_DE = ['DE_'+var for var in vars_weather]\n",
    "cols_weather_FR = ['FR_'+var for var in vars_weather]\n",
    "cols_weather_CH = ['CH_'+var for var in vars_weather]\n",
    "cols_weather_GB = ['GB_'+var for var in vars_weather]\n",
    "\n",
    "# all 7 quantities to predict\n",
    "vars_predict = vars_of_interest+vars_weather\n",
    "\n",
    "# save time column names\n",
    "cols_time = ['year', 'month', 'day', 'hour', 'weekday']\n",
    "\n",
    "# save column names in lists and with different orders for plotting...\n",
    "# ...according to countries\n",
    "all_vars_of_interest = [prefix+var for prefix in prefixes for var in vars_of_interest+vars_weather]\n",
    "all_vars_of_interest_DE = cols_of_interest_DE + cols_weather_DE\n",
    "all_vars_of_interest_FR = cols_of_interest_FR + cols_weather_FR\n",
    "all_vars_of_interest_CH = cols_of_interest_CH + cols_weather_CH\n",
    "all_vars_of_interest_GB = cols_of_interest_GB + cols_weather_GB\n",
    "\n",
    "# ...according to variables\n",
    "all_vars_of_interest_varfirst = [prefix+var for var in vars_of_interest+vars_weather for prefix in prefixes]\n",
    "\n",
    "# all original columns in final dataset\n",
    "all_cols_to_keep     = ['utc_timestamp']+ all_vars_of_interest +cols_time\n",
    "all_cols_to_keep_DE  = ['utc_timestamp']+ [var for var in all_vars_of_interest if var.startswith('DE_')] +cols_time\n",
    "all_cols_to_keep_FR  = ['utc_timestamp']+ [var for var in all_vars_of_interest if var.startswith('FR_')] +cols_time\n",
    "all_cols_to_keep_CH  = ['utc_timestamp']+ [var for var in all_vars_of_interest if var.startswith('CH_')] +cols_time\n",
    "all_cols_to_keep_GB  = ['utc_timestamp']+ [var for var in all_vars_of_interest if var.startswith('GB_')] +cols_time\n",
    "\n",
    "# used in dataset generation\n",
    "# contains all aditional time features \n",
    "cols_ts_DE = all_vars_of_interest_DE\n",
    "cols_ts_FR = all_vars_of_interest_FR\n",
    "cols_ts_CH = all_vars_of_interest_CH\n",
    "cols_ts_GB = all_vars_of_interest_GB\n",
    "cols_ts_all = all_vars_of_interest\n",
    "cols_ts_long = vars_of_interest+vars_weather\n",
    "cols_to_cycle = ['month', 'day', 'hour', 'weekday']\n",
    "cols_timedims_cycle = [timedim+version for timedim in cols_to_cycle for version in ['_sin', '_cos']]\n",
    "cols_to_normalize_DE = cols_ts_DE+['year']\n",
    "cols_to_normalize_all = cols_ts_all+['year']\n",
    "cols_to_normalize_long = cols_ts_long+['year', 'ID']\n",
    "\n",
    "idx_firstmonday = 96\n",
    "idx_lastsunday = 43775"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# labels for correlation matrix\n",
    "\n",
    "# labels if correlation matrix is done for Germany only\n",
    "labels_vars_full = {}\n",
    "for v in all_vars_of_interest:\n",
    "    if 'load_actual' in v:\n",
    "        labels_vars_full[v] = (v.partition('_')[0]+' total load', '[GW]')\n",
    "    elif 'load_forecast' in v:\n",
    "        labels_vars_full[v] = (v.partition('_')[0]+' load forecast', '[GW]')\n",
    "    elif 'solar_generation' in v:\n",
    "        labels_vars_full[v] = (v.partition('_')[0]+' solar generation', '[GW]')\n",
    "    elif 'wind_generation' in v:\n",
    "        labels_vars_full[v] = (v.partition('_')[0]+' wind generation', '[GW]')\n",
    "    elif 'price_day_ahead' in v:\n",
    "        if v.partition('_')[0] != 'GB':\n",
    "            labels_vars_full[v] = (v.partition('_')[0]+' price day-ahead', '[EUR]')\n",
    "        else:\n",
    "            labels_vars_full[v] = (v.partition('_')[0]+' price day-ahead', '[GBP]')\n",
    "    elif 'temperature' in v:\n",
    "        labels_vars_full[v] = (v.partition('_')[0]+' temperature', '[°C]')\n",
    "    elif 'radiation_direct_horizontal' in v:\n",
    "        labels_vars_full[v] = (v.partition('_')[0]+' radiation direct', '[W/m²]')\n",
    "    elif 'radiation_diffuse_horizontal' in v:\n",
    "        labels_vars_full[v] = (v.partition('_')[0]+' radiation diffuse', '[W/m²]')\n",
    "        \n",
    "labels_vars_virtual = {}\n",
    "for v in vars_predict:\n",
    "    if 'load_actual' in v:\n",
    "        labels_vars_virtual[v] = ('total load', '[GW]')\n",
    "    elif 'load_forecast' in v:\n",
    "        labels_vars_virtual[v] = ('load forecast', '[GW]')\n",
    "    elif 'solar_generation' in v:\n",
    "        labels_vars_virtual[v] = ('solar generation', '[GW]')\n",
    "    elif 'wind_generation' in v:\n",
    "        labels_vars_virtual[v] = ('wind generation', '[GW]')\n",
    "    elif 'price_day_ahead' in v:\n",
    "        if v.partition('_')[0] != 'GB':\n",
    "            labels_vars_virtual[v] = ('price day-ahead', '[EUR]')\n",
    "        else:\n",
    "            labels_vars_virtual[v] = ('labels_vars_virtual', '[GBP]')\n",
    "    elif 'temperature' in v:\n",
    "        labels_vars_virtual[v] = ('temperature', '[°C]')\n",
    "    elif 'radiation_direct' in v:\n",
    "        labels_vars_virtual[v] = ('radiation direct', '[W/m²]')\n",
    "    elif 'radiation_diffuse' in v:\n",
    "        labels_vars_virtual[v] = ('radiation diffuse', '[W/m²]')\n",
    "        \n",
    "# labels if correlation matrix is done for all countries\n",
    "labels_vars_short = {}\n",
    "for v in all_vars_of_interest:\n",
    "    if 'load_actual' in v:\n",
    "        labels_vars_short[v] = (v.partition('_')[0]+' LO', '[GW]')\n",
    "    elif 'solar_generation' in v:\n",
    "        labels_vars_short[v] = (v.partition('_')[0]+' SO', '[GW]')\n",
    "    elif 'wind_generation' in v:\n",
    "        labels_vars_short[v] = (v.partition('_')[0]+' WI', '[GW]')\n",
    "    elif 'price_day_ahead' in v:\n",
    "        if v.partition('_')[0] != 'GB':\n",
    "            labels_vars_short[v] = (v.partition('_')[0]+' PR', '[EUR]')\n",
    "        else:\n",
    "            labels_vars_short[v] = (v.partition('_')[0]+' PR', '[GBP]')\n",
    "    elif 'temperature' in v:\n",
    "        labels_vars_short[v] = (v.partition('_')[0]+' TE', '[°C]')\n",
    "    elif 'radiation_direct_horizontal' in v:\n",
    "        labels_vars_short[v] = (v.partition('_')[0]+' R1', '[W/m²]')\n",
    "    elif 'radiation_diffuse_horizontal' in v:\n",
    "        labels_vars_short[v] = (v.partition('_')[0]+' R2', '[W/m²]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dimgray = np.array(colors.to_rgba('dimgray'))\n",
    "lightgray = np.array(colors.to_rgba('lightgrey'))\n",
    "gray = np.array(colors.to_rgba('grey'))\n",
    "black = np.array(colors.to_rgba('black'))\n",
    "white = np.array(colors.to_rgba('white'))\n",
    "darkdimgray = (dimgray+black)/2\n",
    "darkorange = np.array(colors.to_rgba('darkorange'))\n",
    "green = np.array(colors.to_rgba('green'))\n",
    "dodgerblue = np.array(colors.to_rgba('dodgerblue'))\n",
    "\n",
    "# colors partially from cm.paired and set1\n",
    "dark_blue    = np.array([0.21568627450980393, 0.49411764705882355, 0.7215686274509804, 1.0])\n",
    "light_blue   = np.array([0.6509803921568628, 0.807843137254902, 0.8901960784313725, 1.0])\n",
    "dark_green   = np.array([0.30196078431372547, 0.6862745098039216, 0.2901960784313726, 1.0])\n",
    "light_green  = np.array([0.6980392156862745, 0.8745098039215686, 0.5411764705882353, 1.0])\n",
    "dark_orange  = np.array([1.0, 0.4980392156862745, 0.0, 1.0])\n",
    "light_orange = np.array([0.9921568627450981, 0.7490196078431373, 0.43529411764705883, 1.0])\n",
    "dark_purple  = np.array([0.41568627450980394, 0.23921568627450981, 0.6039215686274509, 1.0])\n",
    "light_purple = np.array([0.792156862745098, 0.6980392156862745, 0.8392156862745098, 1.0])\n",
    "\n",
    "\n",
    "palette='bright'\n",
    "snspalette = sns.color_palette(palette, n_colors=7)\n",
    "snspalette = [np.array(list(elt)+[0]) for elt in snspalette]\n",
    "color_code_snspalette = {'load_actual': snspalette[0],\n",
    "                    'solar_generation': snspalette[1],\n",
    "                    'wind_generation': snspalette[2],\n",
    "                    'price_day_ahead': snspalette[4],\n",
    "                    'temperature': snspalette[3],\n",
    "                    'radiation_direct_horizontal': snspalette[5], \n",
    "                    'radiation_diffuse_horizontal': snspalette[6]\n",
    "                   }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### settings for training runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# choose dataset\n",
    "# suffix = \"_energy_DE_1d\"\n",
    "# suffix = \"_energy_all_1d\"\n",
    "suffix = \"_energy_long_1d\"\n",
    "# suffix = \"_energy_DE_7d\"\n",
    "# suffix = \"_energy_all_7d\"\n",
    "# suffix = \"_energy_long_7d\"\n",
    "\n",
    "# choose acd version -> either a gcn encoder or variational distribution\n",
    "# version = 'gcn'\n",
    "version = 'variational'\n",
    "\n",
    "# whether to make predictions with ACD model\n",
    "predict_acd = False\n",
    "# predict_acd = True\n",
    "\n",
    "# whether to make predictions with ACD with random graphs\n",
    "predict_rnd = False\n",
    "# predict_rnd = True\n",
    "\n",
    "# whether to make predictions with MLR baseline\n",
    "predict_mlr = False\n",
    "# predict_mlr = True\n",
    "\n",
    "# whether to make predictions with LSTM baseline\n",
    "predict_rnn = False\n",
    "# predict_rnn = True\n",
    "\n",
    "# further settings\n",
    "epochs = 100\n",
    "batch_size = 16\n",
    "no_cuda = False\n",
    "# no_cuda=True\n",
    "\n",
    "# whether to save the prediction csv\n",
    "save_pred_csv = False\n",
    "# save_pred_csv = True\n",
    "\n",
    "# load csv containing all predictions for the above specified dataset\n",
    "load_pred_csv = False\n",
    "load_pred_csv = True\n",
    "\n",
    "# load all preds\n",
    "load_allpreds = False\n",
    "# load_allpreds = True\n",
    "\n",
    "# whether to to calculate crps scores\n",
    "do_calc_crps = False\n",
    "# do_calc_crps = True\n",
    "\n",
    "# whether to combine preds from same datasets into 3 large csv files\n",
    "create_country_dfs = False\n",
    "# create_country_dfs = True\n",
    "\n",
    "# whether to instead load these preds for plotting\n",
    "load_country_dfs = False\n",
    "load_country_dfs = True\n",
    "\n",
    "# show plots or not\n",
    "show_figure=True\n",
    "show_figure=False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Specify settings and load normed dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    ".npy input files for acd have shape  \n",
    "[num_samples, num_ts, num_timesteps, num_dims]   \n",
    "e.g. [3*365, 7, 24/48, 1+num_features]  \n",
    "(in acd code [num_sims, num_atoms, num_timesteps, num_dims]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### function definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def denormalize_columns(df_norm, save_folder=\"data/\", suffix=\"\"):\n",
    "    ''' Takes normalized dataframe and saved normalization parameters to arrive at the origianl data.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    \n",
    "    df_norm: normed dataframe\n",
    "    \n",
    "    save_folder: where should the normalization parameters be retrieved from\n",
    "    \n",
    "    suffix: whats the name of the file\n",
    "    \n",
    "    Return\n",
    "    ------\n",
    "    \n",
    "    df: denormalized dataframe\n",
    "    '''\n",
    "    df=df_norm.copy()\n",
    "    df_norm_params = pd.read_csv(save_folder + 'norm_params' + suffix + '.csv')\n",
    "    cols_to_denormalize = df_norm_params['cols']\n",
    "    # pred_cols = [col.removesuffix('_pred') for col in df.columns if col.endswith('_pred')]\n",
    "    cols_df = df.columns.values\n",
    "    \n",
    "    for col_df in cols_df:\n",
    "        for col_to_denormalize in cols_to_denormalize:\n",
    "            if col_df.startswith(col_to_denormalize):\n",
    "                col_min = df_norm_params.loc[df_norm_params['cols'] == col_to_denormalize, 'min'].values[0]\n",
    "                col_max = df_norm_params.loc[df_norm_params['cols'] == col_to_denormalize, 'max'].values[0]\n",
    "                df[col_df] = denormalize(df[col_df], col_min, col_max)\n",
    "        # if col in pred_cols:\n",
    "        #     df[col+\"_pred\"] = denormalize(df[col+'_pred'], col_min, col_max)\n",
    "            \n",
    "    return df      \n",
    "    \n",
    "def generate_df(df_norm, pred, cols_ts, lstm_format=False, pred_name='_pred'):\n",
    "    ''' Takes normed prediction from model and adds it as columns to normed dataframe\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    \n",
    "    df_norm: normed dataframe\n",
    "    \n",
    "    pred: model prediction in the form of an array\n",
    "    \n",
    "    cols_ts: list with names of the predicted columns\n",
    "    \n",
    "    Return\n",
    "    ------\n",
    "    \n",
    "    df_norm: normed dataframe with prediction\n",
    "    '''\n",
    "    \n",
    "    if not lstm_format:\n",
    "        zero_row = torch.zeros((1, pred.shape[1], pred.shape[2], pred.shape[3]))\n",
    "    else:\n",
    "        zero_row = torch.zeros((1, pred.shape[1], pred.shape[2]))\n",
    "    pred = torch.cat((zero_row,pred.cpu()), dim=0)\n",
    "\n",
    "    for i, col in enumerate(cols_ts):\n",
    "        if not lstm_format:\n",
    "            col_pred = pred[:, i, :, 0]\n",
    "            col_pred = col_pred.flatten().tolist()\n",
    "        else:\n",
    "            col_pred = [0]+pred[:, :, i].squeeze().tolist()\n",
    "            \n",
    "        df_norm[col+pred_name] = col_pred\n",
    "    \n",
    "    return df_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### load dataframe and norm params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if suffix == \"_energy_DE_1d\":\n",
    "    num_samples_train = 3*365+1 \n",
    "    num_samples_valid = 365\n",
    "    num_samples_test = 365\n",
    "    cols_ts = cols_ts_DE\n",
    "    cols_timedims = ['year']+cols_timedims_cycle\n",
    "    num_ts = len(cols_ts)\n",
    "    num_timesteps = 24\n",
    "    num_dims = 1 +len(cols_timedims)\n",
    "    dataframe = pd.read_csv('data/normed' +suffix+'.csv', parse_dates=['utc_timestamp'])\n",
    "    df_norm_params = pd.read_csv('data/norm_params' +suffix+'.csv')\n",
    "    \n",
    "if suffix == \"_energy_all_1d\":\n",
    "    num_samples_train = 3*365+1 \n",
    "    num_samples_valid = 365\n",
    "    num_samples_test = 365\n",
    "    cols_ts = cols_ts_all\n",
    "    cols_timedims = ['year']+cols_timedims_cycle\n",
    "    num_ts = len(cols_ts)\n",
    "    num_timesteps = 24\n",
    "    num_dims = 1 +len(cols_timedims)\n",
    "    dataframe = pd.read_csv('data/normed' +suffix+'.csv', parse_dates=['utc_timestamp'])\n",
    "    df_norm_params = pd.read_csv('data/norm_params' +suffix+'.csv')\n",
    "        \n",
    "if suffix == \"_energy_long_1d\":\n",
    "    num_samples_train = (3*365+1)*len(prefixes)\n",
    "    num_samples_valid = 365*len(prefixes)\n",
    "    num_samples_test = 365*len(prefixes)\n",
    "    cols_ts = cols_ts_long\n",
    "    cols_timedims = ['year']+cols_timedims_cycle+['ID']\n",
    "    num_ts = len(cols_ts)\n",
    "    num_timesteps = 24\n",
    "    num_dims = 1 +len(cols_timedims)\n",
    "    dataframe = pd.read_csv('data/normed' +suffix+'.csv', parse_dates=['utc_timestamp'])\n",
    "    df_norm_params = pd.read_csv('data/norm_params' +suffix+'.csv')\n",
    "        \n",
    "if suffix == \"_energy_DE_7d\":\n",
    "    num_samples_train = 3*52\n",
    "    num_samples_valid = 52\n",
    "    num_samples_test = 52\n",
    "    cols_ts = cols_ts_DE\n",
    "    cols_timedims = ['year']+cols_timedims_cycle\n",
    "    num_ts = len(cols_ts)\n",
    "    num_timesteps = 24*7\n",
    "    num_dims = 1 +len(cols_timedims)\n",
    "    idx_start = idx_firstmonday\n",
    "    idx_end = idx_firstmonday+260*7*24    \n",
    "    dataframe = pd.read_csv('data/normed' +suffix+'.csv', parse_dates=['utc_timestamp'])\n",
    "    df_norm_params = pd.read_csv('data/norm_params' +suffix+'.csv')\n",
    "        \n",
    "if suffix == \"_energy_all_7d\":\n",
    "    num_samples_train = 3*52\n",
    "    num_samples_valid = 52\n",
    "    num_samples_test  = 52\n",
    "    cols_ts = cols_ts_all\n",
    "    cols_timedims = ['year']+cols_timedims_cycle\n",
    "    num_ts = len(cols_ts)\n",
    "    num_timesteps = 24*7\n",
    "    num_dims = 1 + len(cols_timedims)\n",
    "    idx_start = idx_firstmonday\n",
    "    idx_end = idx_firstmonday+260*7*24    \n",
    "    dataframe = pd.read_csv('data/normed' +suffix+'.csv', parse_dates=['utc_timestamp'])\n",
    "    df_norm_params = pd.read_csv('data/norm_params' +suffix+'.csv')\n",
    "        \n",
    "if suffix == \"_energy_long_7d\":\n",
    "    num_samples_train = 3*52*len(prefixes)\n",
    "    num_samples_valid = 52*len(prefixes)\n",
    "    num_samples_test = 52*len(prefixes)\n",
    "    cols_ts = cols_ts_long\n",
    "    cols_timedims = ['year']+cols_timedims_cycle+['ID']\n",
    "    num_ts = len(cols_ts)\n",
    "    num_timesteps = 24*7\n",
    "    num_dims = 1 +len(cols_timedims)\n",
    "    idx_start = idx_firstmonday*len(prefixes)\n",
    "    idx_end = idx_firstmonday*len(prefixes)+260*7*24*len(prefixes)\n",
    "    dataframe = pd.read_csv('data/normed' +suffix+'.csv', parse_dates=['utc_timestamp'])\n",
    "    df_norm_params = pd.read_csv('data/norm_params' +suffix+'.csv')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Model implementations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### -------------------- ACD Code --------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "This acd implementation is adapted from the original implementation at  \n",
    "https://github.com/loeweX/AmortizedCausalDiscovery.  \n",
    "All individual files from there (potentially modified) are stored in ACD_code.py\n",
    "\n",
    "Optionally, instead of importing the .py file, one can copy the cells from the    \n",
    "ACD_code_notebook.ipynb in here for easier handling when editing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from ACD_code import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from __future__ import division\n",
    "# from __future__ import print_function\n",
    "\n",
    "# from collections import defaultdict\n",
    "\n",
    "# import time\n",
    "# import numpy as np\n",
    "# import torch\n",
    "\n",
    "# from model.modules import *\n",
    "# from utils import arg_parser, logger, data_loader, forward_pass_and_eval\n",
    "# from model import utils, model_loader\n",
    "\n",
    "\n",
    "def train():\n",
    "    best_val_loss = np.inf\n",
    "    best_epoch = 0\n",
    "\n",
    "    for epoch in range(args.epochs):\n",
    "        t_epoch = time.time()\n",
    "        train_losses = defaultdict(list)\n",
    "\n",
    "        for batch_idx, minibatch in enumerate(train_loader):\n",
    "\n",
    "            data, relations, temperatures = unpack_batches(args, minibatch)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            losses, _, _, _ = forward_pass_and_eval(\n",
    "                args,\n",
    "                encoder,\n",
    "                decoder,\n",
    "                data,\n",
    "                relations,\n",
    "                rel_rec,\n",
    "                rel_send,\n",
    "                args.hard,\n",
    "                edge_probs=edge_probs,\n",
    "                log_prior=log_prior,\n",
    "                temperatures=temperatures,\n",
    "            )\n",
    "\n",
    "            loss = losses[\"loss\"]\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_losses = append_losses(train_losses, losses)\n",
    "\n",
    "        string = logs.result_string(\"train\", epoch, train_losses, t=t_epoch)\n",
    "        logs.write_to_log_file(string)\n",
    "        logs.append_train_loss(train_losses)\n",
    "        scheduler.step()\n",
    "\n",
    "        if args.validate:\n",
    "            val_losses = val(epoch)\n",
    "            val_loss = np.mean(val_losses[\"loss\"])\n",
    "            if val_loss < best_val_loss:\n",
    "                print(\"Best model so far, saving...\")\n",
    "                logs.create_log(\n",
    "                    args,\n",
    "                    encoder=encoder,\n",
    "                    decoder=decoder,\n",
    "                    optimizer=optimizer,\n",
    "                    accuracy=np.mean(val_losses[\"acc\"]),\n",
    "                )\n",
    "                best_val_loss = val_loss\n",
    "                best_epoch = epoch\n",
    "        elif (epoch + 1) % 100 == 0:\n",
    "            logs.create_log(\n",
    "                args,\n",
    "                encoder=encoder,\n",
    "                decoder=decoder,\n",
    "                optimizer=optimizer,\n",
    "                accuracy=np.mean(train_losses[\"acc\"]),\n",
    "            )\n",
    "\n",
    "        logs.draw_loss_curves()\n",
    "\n",
    "    return best_epoch, epoch\n",
    "\n",
    "\n",
    "def val(epoch):\n",
    "    t_val = time.time()\n",
    "    val_losses = defaultdict(list)\n",
    "\n",
    "    if args.use_encoder:\n",
    "        encoder.eval()\n",
    "    decoder.eval()\n",
    "\n",
    "    for batch_idx, minibatch in enumerate(valid_loader):\n",
    "\n",
    "        data, relations, temperatures = unpack_batches(args, minibatch)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            losses, _, _, _ = forward_pass_and_eval(\n",
    "                args,\n",
    "                encoder,\n",
    "                decoder,\n",
    "                data,\n",
    "                relations,\n",
    "                rel_rec,\n",
    "                rel_send,\n",
    "                True,\n",
    "                edge_probs=edge_probs,\n",
    "                log_prior=log_prior,\n",
    "                testing=True,\n",
    "                temperatures=temperatures,\n",
    "            )\n",
    "\n",
    "        val_losses = append_losses(val_losses, losses)\n",
    "\n",
    "    string = logs.result_string(\"validate\", epoch, val_losses, t=t_val)\n",
    "    logs.write_to_log_file(string)\n",
    "    logs.append_val_loss(val_losses)\n",
    "\n",
    "    if args.use_encoder:\n",
    "        encoder.train()\n",
    "    decoder.train()\n",
    "\n",
    "    return val_losses\n",
    "\n",
    "\n",
    "def test(encoder, decoder, epoch):\n",
    "    args.shuffle_unobserved = False\n",
    "    # args.prediction_steps = 49\n",
    "    test_losses = defaultdict(list)\n",
    "\n",
    "    if args.load_folder == \"\":\n",
    "        ## load model that had the best validation performance during training\n",
    "        if args.use_encoder:\n",
    "            encoder.load_state_dict(torch.load(args.encoder_file))\n",
    "        decoder.load_state_dict(torch.load(args.decoder_file))\n",
    "\n",
    "    if args.use_encoder:\n",
    "        encoder.eval()\n",
    "    decoder.eval()\n",
    "\n",
    "    for batch_idx, minibatch in enumerate(test_loader):\n",
    "\n",
    "        data, relations, temperatures = unpack_batches(args, minibatch)\n",
    "        # print(data.shape)\n",
    "        # print(relations.shape)\n",
    "        # print(data.size(2))\n",
    "        # print(args.timesteps)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            assert (data.size(2) - args.timesteps) >= args.timesteps\n",
    "\n",
    "            data_encoder = data[:, :, : args.timesteps, :].contiguous()\n",
    "            data_decoder = data[:, :, args.timesteps : -1, :].contiguous()\n",
    "\n",
    "            losses, _, _, _, = forward_pass_and_eval(\n",
    "                args,\n",
    "                encoder,\n",
    "                decoder,\n",
    "                data,\n",
    "                relations,\n",
    "                rel_rec,\n",
    "                rel_send,\n",
    "                True,\n",
    "                data_encoder=data_encoder,\n",
    "                data_decoder=data_decoder,\n",
    "                edge_probs=edge_probs,\n",
    "                log_prior=log_prior,\n",
    "                testing=True,\n",
    "                temperatures=temperatures,\n",
    "            )\n",
    "\n",
    "        test_losses = append_losses(test_losses, losses)\n",
    "\n",
    "    string = logs.result_string(\"test\", epoch, test_losses)\n",
    "    logs.write_to_log_file(string)\n",
    "    logs.append_test_loss(test_losses)\n",
    "\n",
    "    logs.create_log(\n",
    "        args,\n",
    "        decoder=decoder,\n",
    "        encoder=encoder,\n",
    "        optimizer=optimizer,\n",
    "        final_test=True,\n",
    "        test_losses=test_losses,\n",
    "    )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### -------------------- MLR Code --------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_MLR(df, cols_ts, cols_timedims, \n",
    "            num_samples_train=(3*365+1)*24,\n",
    "            num_samples_valid=365*24, \n",
    "            num_samples_test=365*24,\n",
    "            epochs=100,\n",
    "            suffix='_energy',\n",
    "            print_every=100,\n",
    "            lr=0.1\n",
    "            ):\n",
    "    \n",
    "    num_ts = len(cols_ts)\n",
    "    len_df = len(df)\n",
    "    offset_valid = num_samples_train\n",
    "    offset_test = num_samples_train+num_samples_valid\n",
    "    linear_regression_models = {}\n",
    "    test_losses = {}\n",
    "    for target in cols_ts:\n",
    "        x_whole = torch.FloatTensor(df.loc[:(len_df-1)-1, cols_ts+cols_timedims].values).T\n",
    "        y_whole = torch.FloatTensor(df.loc[1:(len_df-1), target].values).T\n",
    "        \n",
    "        x_train = torch.FloatTensor(df.loc[0:num_samples_train-1, cols_ts+cols_timedims].values.T)#.values)\n",
    "        y_train = torch.FloatTensor(df.loc[1:num_samples_train, target].values.T)#.values)\n",
    "        \n",
    "        x_valid = torch.FloatTensor(df.loc[offset_valid+0:offset_valid+num_samples_valid-1, \n",
    "                                          cols_ts+cols_timedims].values).T\n",
    "        y_valid = torch.FloatTensor(df.loc[offset_valid+1:offset_valid+num_samples_valid, \n",
    "                                          target].values).T        \n",
    "        \n",
    "        x_test = torch.FloatTensor(df.loc[offset_test+0:offset_test+num_samples_test-1-1, \n",
    "                                          cols_ts+cols_timedims].values).T\n",
    "        y_test = torch.FloatTensor(df.loc[offset_test+1:offset_test+num_samples_test-1, \n",
    "                                          target].values).T\n",
    "        \n",
    "        n_predictors = x_train.shape[0]\n",
    "        A = torch.randn((1, n_predictors), requires_grad=True)\n",
    "        b = torch.randn(1, requires_grad=True)\n",
    "        \n",
    "        optimizer = optim.Adam([A, b], lr=lr)\n",
    "\n",
    "        for i in range(epochs):\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            train_pred = A.mm(x_train) + b\n",
    "            train_loss = ((train_pred - y_train)**2).sum()/num_samples_train\n",
    "            train_loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            valid_pred = A.detach()@x_valid + b.detach()\n",
    "            val_loss = ((valid_pred - y_valid)**2).sum()/num_samples_valid\n",
    "            \n",
    "            if (i+1)%print_every==0:\n",
    "                string = f\"i={i+1} target {target} train_loss {train_loss} val_loss {val_loss}\" \n",
    "                logs.write_to_log_file(string)\n",
    "                \n",
    "        test_pred = A.detach()@x_test + b.detach()\n",
    "        test_loss = ((test_pred - y_test)**2).sum()/num_samples_test\n",
    "        test_losses[target]=test_loss.item()\n",
    "        \n",
    "        string = f\"target = {target}, test loss = {test_loss}\" \n",
    "        logs.write_to_log_file(string)   \n",
    "        \n",
    "        linear_regression_models[target]=(A, b)\n",
    "        \n",
    "        df[target+'_pred'] = 0\n",
    "        df.loc[1:,target+'_pred'] = (A.detach() @ x_whole + b.detach())[0].tolist()\n",
    "        \n",
    "    avg_test_loss = np.mean(list(test_losses.values()))\n",
    "    string = f\"average test loss= {avg_test_loss}\" \n",
    "    logs.write_to_log_file(string)   \n",
    "    \n",
    "    return linear_regression_models, df, test_losses, avg_test_loss\n",
    "\n",
    "def predict_MLR(df, MLR_models, cols_ts, cols_timedims):\n",
    "    for target in cols_ts:\n",
    "        pred_len = len(df)-1\n",
    "        x = torch.FloatTensor(df.loc[0:pred_len-1, cols_ts+cols_timedims].values).T\n",
    "        y = torch.FloatTensor(df.loc[1:pred_len, target].values).T\n",
    "        (A, b) = MLR_models[target]\n",
    "        df[target+'_pred_mlr'] = 0\n",
    "        df.loc[1:,target+'_pred_mlr'] = (A.detach() @ x + b.detach())[0].tolist()        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### -------------------- RNN Code --------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class RNN_baseline(nn.Module):\n",
    "    def __init__(self, lstm_layers, input_dim, target_dim, batch_size, hidden_dim, device):\n",
    "        super(RNN_baseline, self).__init__()\n",
    "        self.lstm_layers = lstm_layers\n",
    "        self.batch_size = batch_size\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.input_dim = input_dim\n",
    "        self.target_dim = target_dim\n",
    "        self.device = device\n",
    "        \n",
    "        self.lstm = nn.LSTM(self.input_dim, self.hidden_dim, self.lstm_layers, batch_first=True)\n",
    "        self.linear = nn.Linear(self.hidden_dim, self.target_dim)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        hidden_state = torch.zeros(self.lstm_layers, self.batch_size, self.hidden_dim).to(self.device)\n",
    "        cell_state = torch.zeros(self.lstm_layers, self.batch_size, self.hidden_dim).to(self.device)\n",
    "        hidden = (hidden_state, cell_state)\n",
    "        \n",
    "        outputs, hidden = self.lstm(inputs)\n",
    "        \n",
    "        return self.linear(outputs).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_rnn(args):\n",
    "    best_val_loss = np.inf\n",
    "    best_epoch = 0\n",
    "\n",
    "    for epoch in range(args.epochs):\n",
    "        t_epoch = time.time()\n",
    "        train_losses = defaultdict(list)\n",
    "        \n",
    "        (train_loader, \n",
    "         valid_loader,\n",
    "         test_loader,\n",
    "         loc_max,\n",
    "         loc_min,\n",
    "         vel_max,\n",
    "         vel_min,\n",
    "        ) = load_data(args)\n",
    "\n",
    "        for batch_idx, minibatch in enumerate(train_loader):\n",
    "            \n",
    "            data, target, _ = unpack_batches(args, minibatch)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            losses, output = forward_pass_rnn(\n",
    "                args,\n",
    "                rnn,\n",
    "                data,\n",
    "                target)\n",
    "\n",
    "            loss = losses[\"loss_mse\"]\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "            train_losses = append_losses(train_losses, losses)\n",
    "\n",
    "        string = logs.result_string(\"train\", epoch, train_losses, t=t_epoch)\n",
    "        logs.write_to_log_file(string)\n",
    "        logs.append_train_loss(train_losses)\n",
    "        scheduler.step()\n",
    "\n",
    "        if args.validate:\n",
    "            val_losses = val_rnn(epoch, rnn_args)\n",
    "            val_loss = np.mean(val_losses[\"loss_mse\"])\n",
    "            if val_loss < best_val_loss:\n",
    "                print(\"Best model so far, saving...\")\n",
    "                logs.create_log(\n",
    "                    rnn_args,\n",
    "                    rnn=rnn,\n",
    "                    optimizer=optimizer,\n",
    "                )\n",
    "                best_val_loss = val_loss\n",
    "                best_epoch = epoch\n",
    "        elif (epoch + 1) % 100 == 0:\n",
    "            logs.create_log(\n",
    "                rnn_args,\n",
    "                rnn=rnn,\n",
    "                optimizer=optimizer,\n",
    "            )\n",
    "\n",
    "        logs.draw_loss_curves()\n",
    "\n",
    "    return best_epoch, epoch\n",
    "\n",
    "\n",
    "def val_rnn(epoch, args):\n",
    "    t_val = time.time()\n",
    "    val_losses = defaultdict(list)\n",
    "\n",
    "    rnn.eval()\n",
    "\n",
    "    for batch_idx, minibatch in enumerate(valid_loader):\n",
    "\n",
    "        data, target, _ = unpack_batches(args, minibatch)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            losses, output = forward_pass_rnn(\n",
    "                args,\n",
    "                rnn,\n",
    "                data,\n",
    "                target\n",
    "            )\n",
    "\n",
    "        val_losses = append_losses(val_losses, losses)\n",
    "\n",
    "    string = logs.result_string(\"validate\", epoch, val_losses, t=t_val)\n",
    "    logs.write_to_log_file(string)\n",
    "    logs.append_val_loss(val_losses)\n",
    "\n",
    "    rnn.train()\n",
    "\n",
    "    return val_losses\n",
    "\n",
    "\n",
    "def test_rnn(rnn, epoch, args):\n",
    "    test_losses = defaultdict(list)\n",
    "\n",
    "    if args.load_folder == \"\":\n",
    "        ## load model that had the best validation performance during training\n",
    "        rnn.load_state_dict(torch.load(args.rnn_file))\n",
    "    \n",
    "    rnn.eval()    \n",
    "    \n",
    "    for batch_idx, minibatch in enumerate(test_loader):\n",
    "\n",
    "        data, target, _ = unpack_batches(args, minibatch)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            losses, output = forward_pass_rnn(\n",
    "                args,\n",
    "                rnn,\n",
    "                data,\n",
    "                target#.unsqueeze(1)\n",
    "            )\n",
    "\n",
    "        test_losses = append_losses(test_losses, losses)\n",
    "\n",
    "    string = logs.result_string(\"test\", epoch, test_losses)\n",
    "    logs.write_to_log_file(string)\n",
    "    logs.append_test_loss(test_losses)\n",
    "\n",
    "    logs.create_log(   \n",
    "        args,\n",
    "        rnn=rnn,\n",
    "        optimizer=optimizer,\n",
    "        final_test=True,\n",
    "        test_losses=test_losses\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Make predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### -------------------- ACD predictions --------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### make prediction on whole dataset with final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_samples=num_samples_train\n",
    "test_samples=num_samples_test\n",
    "timesteps=num_timesteps\n",
    "num_atoms=num_ts\n",
    "dims=num_dims\n",
    "if version == 'gcn':\n",
    "    dont_use_encoder = False\n",
    "elif version == 'variational':\n",
    "    dont_use_encoder = True \n",
    "\n",
    "args = parse_args(\n",
    "    epochs=epochs, \n",
    "    training_samples=training_samples, \n",
    "    test_samples=test_samples,\n",
    "    shuffle_traindata=True,\n",
    "    suffix=suffix,\n",
    "    timesteps=timesteps,\n",
    "    num_atoms=num_atoms,\n",
    "    dims=dims,\n",
    "    no_cuda=no_cuda,\n",
    "    dont_use_encoder=dont_use_encoder,\n",
    "    batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "do_predict = predict_acd\n",
    "if do_predict:\n",
    "    if version == 'gcn':\n",
    "        if   suffix == '_energy_DE_1d':\n",
    "            current_log = '20221106-171315'\n",
    "        elif suffix == '_energy_all_1d':\n",
    "            current_log = '20221106-192314'\n",
    "        elif suffix == '_energy_long_1d':\n",
    "            current_log = '20221106-201437'\n",
    "        elif suffix == '_energy_DE_7d':\n",
    "            current_log = '20221108-090152'\n",
    "        elif suffix == '_energy_all_7d':\n",
    "            current_log = '20221109-155852'\n",
    "        elif suffix == '_energy_long_7d':\n",
    "            current_log = '20221108-105258'\n",
    "        args.encoder_file = 'logs\\\\'+current_log+'\\\\encoderfinal.pt'\n",
    "    elif version == 'variational':\n",
    "        if   suffix == '_energy_DE_1d':\n",
    "            current_log = '20221109-163905'\n",
    "        elif suffix == '_energy_all_1d':\n",
    "            current_log = '20221109-165322'\n",
    "        elif suffix == '_energy_long_1d':\n",
    "            current_log = '20221109-174204'\n",
    "        elif suffix == '_energy_DE_7d':\n",
    "            current_log = '20221109-180817'\n",
    "        elif suffix == '_energy_all_7d':\n",
    "            current_log = '20221109-223004'\n",
    "        elif suffix == '_energy_long_7d':\n",
    "            current_log = '20221109-212831'\n",
    "        args.edge_probs_file  = 'logs\\\\'+current_log+'\\\\edge_probs_final.pt'\n",
    "    args.decoder_file = 'logs\\\\'+current_log+'\\\\decoderfinal.pt'   \n",
    "    \n",
    "    rel_rec, rel_send = create_rel_rec_send(args, args.num_atoms)\n",
    "\n",
    "    encoder, decoder, optimizer, scheduler, edge_probs = load_model(\n",
    "        args, None, None, None, None)\n",
    "\n",
    "    if args.use_encoder:\n",
    "        encoder.load_state_dict(torch.load(args.encoder_file))\n",
    "        encoder.eval()\n",
    "    else:\n",
    "        edge_probs = torch.load(args.edge_probs_file)\n",
    "\n",
    "    decoder.load_state_dict(torch.load(args.decoder_file))\n",
    "    decoder.eval()\n",
    "\n",
    "    if args.device.type=='cpu':\n",
    "        encoder = encoder.module.to(args.device)\n",
    "        decoder = decoder.module.to(args.device)\n",
    "\n",
    "    data_full = torch.FloatTensor(np.load('data/feat_predict' +suffix+'.npy')).cpu()\n",
    "\n",
    "    outputs=[]\n",
    "    adjacency_matrix_list=[]\n",
    "    losses_list = []\n",
    "    \n",
    "    for i in range(int(np.ceil(data_full.shape[0]/batch_size))):\n",
    "        losses = defaultdict(lambda: torch.zeros((), device=args.device.type))\n",
    "        \n",
    "        data = data_full[i*batch_size:(i+1)*batch_size]\n",
    "        if args.cuda:\n",
    "            data = data.cuda()\n",
    "        data_encoder = data[:, :, : args.timesteps, :].contiguous()\n",
    "        data_decoder = data[:, :, args.timesteps-1 : , :].contiguous()\n",
    "\n",
    "        if args.use_encoder:\n",
    "            logits = encoder(data_encoder, rel_rec, rel_send).detach()\n",
    "        else:\n",
    "            logits = edge_probs.unsqueeze(0).repeat(data_encoder.shape[0], 1, 1)\n",
    "        edges = gumbel_softmax(logits, tau=args.temp, hard=True)\n",
    "        prob = my_softmax(logits, -1)\n",
    "        \n",
    "        offdiag_indices = get_offdiag_indices(args.num_atoms)\n",
    "        adjacency_matrix = torch.zeros(edges.size(0), args.num_atoms * args.num_atoms)\n",
    "        adjacency_matrix[:, offdiag_indices] = edges[:, :, 1].float().cpu()\n",
    "\n",
    "        adjacency_matrix = adjacency_matrix.view(edges.size(0), args.num_atoms, args.num_atoms)\n",
    "        adjacency_matrix_list += [adjacency_matrix]\n",
    "\n",
    "        target = data_decoder[:, :, 1:, :]\n",
    "\n",
    "        output = decoder(\n",
    "                    data_decoder,\n",
    "                    edges,\n",
    "                    rel_rec,\n",
    "                    rel_send,\n",
    "                    args.prediction_steps).detach()\n",
    "\n",
    "        outputs += [output]\n",
    "        \n",
    "        losses[\"loss_mse\"] = F.mse_loss(output, target).item()\n",
    "        losses_list += [losses]\n",
    "    df_losses = pd.DataFrame(losses_list)\n",
    "    losses = dict(df_losses.mean())\n",
    "    print(\"Original losses \")\n",
    "    print(losses) \n",
    "\n",
    "    pred = torch.cat(outputs, 0)\n",
    "    dataframe = generate_df(dataframe, pred, cols_ts, lstm_format=False, pred_name='_pred_acd')\n",
    "    adjacency_matrices = torch.cat(adjacency_matrix_list)\n",
    "    \n",
    "    if save_pred_csv:\n",
    "        np.save('data/adjacency_' + version + suffix + '.npy', adjacency_matrices.detach().numpy())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### make prediction with random graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "do_predict = predict_rnd\n",
    "if do_predict:\n",
    "    if version == 'gcn':\n",
    "        if   suffix == '_energy_DE_1d':\n",
    "            current_log = '20221106-171315'\n",
    "        elif suffix == '_energy_all_1d':\n",
    "            current_log = '20221106-192314'\n",
    "        elif suffix == '_energy_long_1d':\n",
    "            current_log = '20221106-201437'\n",
    "        elif suffix == '_energy_DE_7d':\n",
    "            current_log = '20221108-090152'\n",
    "        elif suffix == '_energy_all_7d':\n",
    "            current_log = '20221109-155852'\n",
    "        elif suffix == '_energy_long_7d':\n",
    "            current_log = '20221108-105258'\n",
    "        args.encoder_file = 'logs\\\\'+current_log+'\\\\encoderfinal.pt'\n",
    "    elif version == 'variational':\n",
    "        if   suffix == '_energy_DE_1d':\n",
    "            current_log = '20221109-163905'\n",
    "        elif suffix == '_energy_all_1d':\n",
    "            current_log = '20221109-165322'\n",
    "        elif suffix == '_energy_long_1d':\n",
    "            current_log = '20221109-174204'\n",
    "        elif suffix == '_energy_DE_7d':\n",
    "            current_log = '20221109-180817'\n",
    "        elif suffix == '_energy_all_7d':\n",
    "            current_log = '20221109-223004'\n",
    "        elif suffix == '_energy_long_7d':\n",
    "            current_log = '20221109-212831'\n",
    "        args.edge_probs_file  = 'logs\\\\'+current_log+'\\\\edge_probs_final.pt'\n",
    "    args.decoder_file = 'logs\\\\'+current_log+'\\\\decoderfinal.pt'\n",
    "\n",
    "    rel_rec, rel_send = create_rel_rec_send(args, args.num_atoms)\n",
    "\n",
    "    encoder, decoder, optimizer, scheduler, edge_probs = load_model(\n",
    "        args, None, None, None, None\n",
    "    )\n",
    "\n",
    "    if args.use_encoder:\n",
    "        encoder.load_state_dict(torch.load(args.encoder_file))\n",
    "        encoder.eval()\n",
    "    else:\n",
    "        edge_probs = torch.load(args.edge_probs_file)\n",
    "\n",
    "    decoder.load_state_dict(torch.load(args.decoder_file))\n",
    "    decoder.eval()\n",
    "\n",
    "    if args.device.type=='cpu':\n",
    "        encoder = encoder.module.to(args.device)\n",
    "        decoder = decoder.module.to(args.device)\n",
    "\n",
    "    data_full = torch.FloatTensor(np.load('data/feat_predict' +suffix+'.npy')).cpu()\n",
    "\n",
    "    outputs=[]\n",
    "    outputs_random_edges=[]\n",
    "    losses_list = []\n",
    "    losses_random_edges_list = []\n",
    "    \n",
    "    for i in range(int(np.ceil(data_full.shape[0]/batch_size))):\n",
    "        losses = defaultdict(lambda: torch.zeros((), device=args.device.type))\n",
    "        losses_random_edges = defaultdict(lambda: torch.zeros((), device=args.device.type))\n",
    "\n",
    "        data = data_full[i*batch_size:(i+1)*batch_size]\n",
    "        if args.cuda:\n",
    "            data = data.cuda()\n",
    "        data_encoder = data[:, :, : args.timesteps, :].contiguous()\n",
    "        data_decoder = data[:, :, args.timesteps-1 : , :].contiguous()\n",
    "\n",
    "        if args.use_encoder:\n",
    "            logits = encoder(data_encoder, rel_rec, rel_send).detach()\n",
    "        else:\n",
    "            logits = edge_probs.unsqueeze(0).repeat(data_encoder.shape[0], 1, 1)\n",
    "        edges = gumbel_softmax(logits, tau=args.temp, hard=True)\n",
    "        prob = my_softmax(logits, -1)\n",
    "\n",
    "        offdiag_indices = get_offdiag_indices(args.num_atoms)\n",
    "\n",
    "        target = data_decoder[:, :, 1:, :]\n",
    "                      \n",
    "        random_logits = torch.FloatTensor(np.random.uniform(torch.min(logits).cpu().detach().numpy(), \n",
    "                                          torch.max(logits).cpu().detach().numpy(), size=logits.shape))\n",
    "        random_edges = gumbel_softmax(random_logits, tau=args.temp, hard=True)\n",
    "        random_prob = my_softmax(random_logits, -1)\n",
    "\n",
    "        output_random_edges = decoder(\n",
    "                    data_decoder,\n",
    "                    random_edges,\n",
    "                    rel_rec,\n",
    "                    rel_send,\n",
    "                    args.prediction_steps).detach()\n",
    "        outputs_random_edges += [output_random_edges]\n",
    "        \n",
    "        losses_random_edges[\"loss_mse\"] = F.mse_loss(output_random_edges, target)\n",
    "        losses_random_edges_list += [losses_random_edges]\n",
    "    df_losses_random_edges = pd.DataFrame(losses_random_edges_list)\n",
    "    losses_random_edges = dict(df_losses_random_edges.mean())\n",
    "    print(\"Losses with random edges \")\n",
    "    print(losses_random_edges)  \n",
    "\n",
    "    pred_random_edges = torch.cat(outputs_random_edges, 0)\n",
    "    dataframe = generate_df(dataframe, pred_random_edges, cols_ts, pred_name='_pred_rnd')\n",
    "    # df_pred_random_edges = denormalize_columns(df_norm_random_edges, suffix=suffix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### -------------------- MLR predictions --------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### make prediction on whole dataset with final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "mlr_args = parse_args(\n",
    "    epochs=epochs,\n",
    "    training_samples=num_samples_train*num_timesteps, \n",
    "    test_samples=num_samples_test*num_timesteps,\n",
    "    shuffle_traindata=True,\n",
    "    suffix=suffix+'_MLR',\n",
    "    timesteps=1,\n",
    "    num_atoms=num_ts,\n",
    "    dims=num_dims,\n",
    "    no_cuda=no_cuda,\n",
    "    dont_use_encoder=dont_use_encoder,\n",
    "    batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if predict_mlr:\n",
    "    if   suffix.startswith('_energy_DE'):\n",
    "        current_log = '20221213-203817'\n",
    "    elif suffix.startswith('_energy_all'):\n",
    "        current_log = '20221213-203954'\n",
    "    elif suffix.startswith('_energy_long'):\n",
    "        current_log = '20221213-204054'\n",
    "    mlr_args.mlr_file = 'logs\\\\'+current_log+\"\\MLR_models\"+suffix[:-3]+\".npy\"\n",
    "\n",
    "    MLR_models_loaded = np.load(mlr_args.mlr_file,allow_pickle='TRUE').item()\n",
    "    \n",
    "    dataframe = predict_MLR(dataframe, MLR_models_loaded, cols_ts, cols_timedims)\n",
    "# df_MLRpred2 = denormalize_columns(df_MLRpred2, suffix=suffix)\n",
    "# display(dataframe.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### -------------------- RNN predictions --------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### make prediction on whole dataset with final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if predict_rnn:\n",
    "        # suffix = suffix[:-3]+'_lstm'\n",
    "        num_samples_train = num_samples_train*num_timesteps\n",
    "        num_samples_valid = num_samples_valid*num_timesteps\n",
    "        num_samples_test = num_samples_test*num_timesteps\n",
    "        num_dims = num_ts + len(cols_timedims)\n",
    "        num_timesteps=1\n",
    "\n",
    "training_samples=num_samples_train\n",
    "test_samples=num_samples_test\n",
    "timesteps=num_timesteps\n",
    "num_atoms=num_ts\n",
    "dims=num_dims\n",
    "lstm_layers = 1\n",
    "input_dim = num_atoms+len(cols_timedims)\n",
    "target_dim = num_atoms\n",
    "hidden_dim = 128\n",
    "\n",
    "rnn_args = parse_args(\n",
    "    epochs=epochs, \n",
    "    training_samples=training_samples, \n",
    "    test_samples=test_samples,\n",
    "    shuffle_traindata=True,\n",
    "    suffix=suffix[:-3]+'_lstm',\n",
    "    timesteps=timesteps,\n",
    "    num_atoms=num_atoms,\n",
    "    dims=dims,\n",
    "    no_cuda=no_cuda,\n",
    "    dont_use_encoder=dont_use_encoder,\n",
    "    batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if predict_rnn:\n",
    "    if   suffix.startswith('_energy_DE'):\n",
    "        current_log = '20221126-135959'\n",
    "    elif suffix.startswith('_energy_all'):\n",
    "        current_log = '20221126-141143'\n",
    "    elif suffix.startswith('_energy_long'):\n",
    "        current_log = '20221126-163840'\n",
    "    rnn_args.rnn_file = 'logs\\\\'+current_log+'\\\\rnnfinal.pt'\n",
    "\n",
    "    rnn = RNN_baseline(lstm_layers, \n",
    "                       input_dim, \n",
    "                       target_dim, \n",
    "                       batch_size, \n",
    "                       hidden_dim,\n",
    "                      rnn_args.device)\n",
    "    if rnn_args.cuda:\n",
    "        rnn = rnn.cuda()\n",
    "\n",
    "    optimizer = optim.Adam(list(rnn.parameters()), lr=rnn_args.lr)\n",
    "    scheduler = lr_scheduler.StepLR(optimizer, \n",
    "                                    step_size=rnn_args.lr_decay, \n",
    "                                    gamma=rnn_args.gamma)\n",
    "\n",
    "    rnn.load_state_dict (torch.load(rnn_args.rnn_file))\n",
    "    rnn.eval()\n",
    "    \n",
    "    data_full = torch.FloatTensor(np.load('data/feat_predict' +rnn_args.suffix+'.npy')).cpu()\n",
    "    target_full = torch.FloatTensor(np.load('data/target_predict' +rnn_args.suffix+'.npy')).cpu()\n",
    "    \n",
    "    if 'DE_7d' in suffix or 'all_7d' in suffix:\n",
    "        print('here???')\n",
    "        data_full = data_full[idx_firstmonday:(idx_lastsunday-1)]\n",
    "        target_full = target_full[idx_firstmonday:(idx_lastsunday-1)]\n",
    "    \n",
    "    if 'long_7d' in suffix:\n",
    "        length_factor=4\n",
    "        data_full = data_full[idx_firstmonday*length_factor:(idx_lastsunday+1)*length_factor-2]\n",
    "        target_full = target_full[idx_firstmonday*length_factor:(idx_lastsunday+1)*length_factor-2]\n",
    "    \n",
    "    outputs=[]\n",
    "    losses_list = []\n",
    "    for i in range(int(np.ceil(data_full.shape[0]/batch_size))):\n",
    "        losses = defaultdict(lambda: torch.zeros((), device=rnn_rgs.device.type))\n",
    "\n",
    "        data = data_full[i*batch_size:(i+1)*batch_size]\n",
    "        target = target_full[i*batch_size:(i+1)*batch_size]\n",
    "        \n",
    "        if rnn_args.cuda:\n",
    "            data = data.cuda()\n",
    "            target = target.cuda()\n",
    "\n",
    "        output = rnn(data).unsqueeze(1)\n",
    "        target = target\n",
    "\n",
    "        outputs += [output]\n",
    "        \n",
    "    #     losses[\"loss_mse\"] = F.mse_loss(output, target)\n",
    "    #     losses_list += [losses]\n",
    "    # df_losses = pd.DataFrame(losses_list)\n",
    "    # losses = dict(df_losses.mean())\n",
    "    # print(\"Original losses \")\n",
    "    print(losses)  \n",
    "\n",
    "    pred = torch.cat(outputs, 0)\n",
    "    # print(len(outputs))\n",
    "    dataframe = generate_df(dataframe, pred, cols_ts, lstm_format=True, pred_name ='_pred_rnn')\n",
    "    # df_pred = denormalize_columns(df_norm, suffix=suffix)\n",
    "    # if save_pred_csv:\n",
    "    #     df_pred.to_csv('data/rnn_pred_'+ suffix + '.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Load CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35040\n"
     ]
    }
   ],
   "source": [
    "if save_pred_csv:\n",
    "    dataframe.to_csv('data/predictions'+ suffix + '_'+version + '.csv', index=False)\n",
    "\n",
    "if load_pred_csv:\n",
    "    dataframe = pd.read_csv('data/predictions' +suffix+ '_'+version +'.csv', parse_dates=['utc_timestamp'])\n",
    "\n",
    "dataframe = dataframe.loc[(num_samples_train+num_samples_valid)*num_timesteps:,:]\n",
    "print(len(dataframe))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Calculate errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calc_MSE(df, cols_ts, pred_name='_pred_acd'):\n",
    "    mse_list = []\n",
    "    for col in cols_ts:\n",
    "        x = df[col].to_numpy()\n",
    "        x_pred = df[col+pred_name].to_numpy()\n",
    "        len_x = len(x)\n",
    "        mse_col = ((x_pred - x)**2).sum()/len_x\n",
    "        mse_list += [mse_col]\n",
    "    mse=np.mean(mse_list)\n",
    "    return mse\n",
    "\n",
    "def calc_skill(df, cols_ts, pred_name='_pred_acd'):\n",
    "    mse_forecast = calc_MSE(df, cols_ts, pred_name)\n",
    "    mse_ref = calc_MSE(df, cols_ts, pred_name='_pred_mlr')\n",
    "    skill = 1-mse_forecast/mse_ref\n",
    "    return skill\n",
    "\n",
    "def calc_MAE(df, cols_ts, pred_name='_pred_acd'):\n",
    "    mae_list = []\n",
    "    for col in cols_ts:\n",
    "        x = df[col].to_numpy()\n",
    "        x_pred = df[col+pred_name].to_numpy()\n",
    "        len_x = len(x)\n",
    "        mae_col = np.abs(x_pred - x).sum()/len_x\n",
    "        mae_list += [mae_col]\n",
    "    mae=np.mean(mae_list)\n",
    "    return mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calc_CRPS(df, cols_ts, pred_name='_pred_acd', show_figure=True,\n",
    "              save_figure=False, only_figure=False, try_numeric=False,\n",
    "              plot_name='CRPS_'):\n",
    "    crps_list = []\n",
    "    for col in cols_ts:\n",
    "        print(col)\n",
    "        \n",
    "        x = df[col].to_numpy()\n",
    "        x_pred = df[col+pred_name].to_numpy()\n",
    "        \n",
    "        bins=100\n",
    "        \n",
    "        xmin = np.min([np.min(x), np.min(x_pred)])\n",
    "        xmax = np.max([np.max(x), np.max(x_pred)])\n",
    "        tol=0.01\n",
    "        \n",
    "        if 'solar' in col or 'radiation' in col:\n",
    "            indices_to_keep = np.where(x >= -0.99)[0]\n",
    "            x = x[indices_to_keep]\n",
    "            x_pred = x_pred[indices_to_keep]\n",
    "            tol=0.05\n",
    "        hist_data = np.histogram(x, bins=bins)\n",
    "        hist_pred = np.histogram(x_pred, bins=bins)\n",
    "        \n",
    "        r_data = rv_histogram(hist_data)\n",
    "        r_pred = rv_histogram(np.histogram(x_pred, bins=bins))\n",
    "        \n",
    "        lower = np.min([np.min(x), np.min(x_pred)])\n",
    "        upper = np.max([np.max(x), np.max(x_pred)])\n",
    "        x_values = np.linspace(lower,upper,100)\n",
    "        r_data_sample = r_data.pdf(x_values)\n",
    "        r_pred_sample = r_pred.pdf(x_values)\n",
    "        \n",
    "        crps_col = 1\n",
    "        if not only_figure:\n",
    "            if try_numeric:\n",
    "                crps_col = ps.crps_quadrature(r_data_sample, r_pred, xmin = xmin, xmax = xmax\n",
    "                                              , tol = tol\n",
    "                                             )\n",
    "                crps_col = np.mean(crps_col)\n",
    "            else:\n",
    "                crps_col = ps.crps_quadrature(x, r_pred, xmin = xmin, xmax = xmax\n",
    "                                              , tol = tol\n",
    "                                             )\n",
    "                crps_col = np.mean(crps_col)\n",
    "        \n",
    "        if show_figure or only_figure:\n",
    "            fig, ax = plt.subplots()\n",
    "            fs=12\n",
    "            plt.plot(x_values, r_data_sample, label='PDF data')\n",
    "            plt.plot(x_values, r_pred_sample, label='PDF ACD')\n",
    "            ax.set_facecolor(color=lightgray)#white)\n",
    "            ax.tick_params(axis='both', which='major', labelsize=fs)\n",
    "            plt.legend(loc='upper right', fontsize=fs)\n",
    "            plt.ylim(bottom=0)\n",
    "            plt.xlabel('x', fontsize=fs)\n",
    "            plt.ylabel('P(x)', fontsize=fs)\n",
    "            crps_result =  ''\n",
    "            if not only_figure:\n",
    "                crps_result = ', CRPS = '+str(np.round(crps_col, 3)) \n",
    "            labels_vars = labels_vars_full\n",
    "            if 'long' in plot_name:\n",
    "                labels_vars = labels_vars_virtual\n",
    "            ax.set_title(labels_vars[col][0]+crps_result, fontsize=fs)\n",
    "            plt.gca()\n",
    "            ax.grid(color='w', linestyle='-')\n",
    "            if save_figure:\n",
    "                dpi = fig.get_dpi()\n",
    "                factor=4\n",
    "                plt.savefig(\"plots/crps\"+pred_name[-4:]+\"/\"+plot_name+col+pred_name+\".jpg\", bbox_inches='tight', dpi=dpi*factor)\n",
    "            plt.show()\n",
    "            \n",
    "        print(crps_col)\n",
    "        \n",
    "        crps_list += [np.mean(crps_col)]\n",
    "    crps = np.mean(crps_list)\n",
    "    return crps, crps_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if do_calc_crps:\n",
    "    pred_name='_pred_acd'\n",
    "    # pred_name='_pred_rnd'\n",
    "    cols_error = [col for col in cols_ts for var in vars_of_interest if var in col]    \n",
    "    try_numeric=True\n",
    "    # try_numeric=False\n",
    "    plot_name= 'CRPS'+suffix[7:]+'_'+version+'_'\n",
    "    crps, crps_list = calc_CRPS(dataframe, cols_error,\n",
    "                                pred_name = pred_name,\n",
    "                                show_figure=True, \n",
    "                                save_figure=True, \n",
    "                                only_figure=False,\n",
    "                                try_numeric=try_numeric,\n",
    "                                plot_name=plot_name)\n",
    "    print(plot_name+pred_name)\n",
    "    print(np.round(crps, 3))\n",
    "    print(crps)\n",
    "    print(crps_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if do_calc_crps:\n",
    "    print(plot_name+pred_name)\n",
    "    print(np.round(crps, 3))\n",
    "    print(crps)\n",
    "    print(crps_list)\n",
    "    \n",
    "# CRPS_DE_1d_gcn__pred_acd\n",
    "# 0.454\n",
    "# 0.45446718268236197\n",
    "# [0.27243392124499105, 0.6010017214565841, 0.5134143595126992, 0.4310187285151734]\n",
    "\n",
    "# CRPS_all_1d_gcn__pred_acd\n",
    "# 0.538\n",
    "# 0.5381001711590523\n",
    "# [0.30933440267233675, 0.4473102657404175, 0.5295711192286578, 0.4738692352579487, 0.5527753024632593, 0.3901372792404163, 0.5344099861473914, 0.6875934728889086, 0.6978378187705733, 0.6080978542089889, 0.7143834015757387, 0.5564387915756605, 0.36485022929689864, 0.6198008675426786, 0.3302064557800891, 0.7929862561548723]\n",
    "\n",
    "# CRPS_long_1d_gcn__pred_acd\n",
    "# 0.85\n",
    "# 0.8495240232873867\n",
    "# [0.6432965201829526, 1.1404297252853743, 1.1098047992752504, 0.5045650484059699]\n",
    "\n",
    "# CRPS_DE_7d_gcn__pred_acd\n",
    "# 0.452\n",
    "# 0.4524633377425769\n",
    "# [0.2900535600044421, 0.6628197006695608, 0.4438478321839146, 0.41313225811239024]\n",
    "\n",
    "# CRPS_all_7d_gcn__pred_acd\n",
    "# 0.489\n",
    "# 0.4885586364080369\n",
    "# [0.3989477873899765, 0.3970110948534627, 0.5170078414766979, 0.433889338157785, 0.5508538811128255, 0.39813586086137376, 0.516382186950765, 0.6033313441028422, 0.46956910622411596, 0.46428847906138043, 0.6897192888547983, 0.45962763955862285, 0.4128633988466182, 0.48746412753386437, 0.36477070686855156, 0.6530761006749102]\n",
    "\n",
    "# CRPS_long_7d_gcn__pred_acd\n",
    "# 0.743\n",
    "# 0.7426931351493793\n",
    "# [0.535761958796867, 0.9431677611750834, 0.9735202127406866, 0.51832260788488]\n",
    "\n",
    "# CRPS_DE_1d_variational__pred_acd\n",
    "# 0.466\n",
    "# 0.4658145566392282\n",
    "# [0.3070725098653312, 0.5610995723050224, 0.5306456273565616, 0.46444051702999767]\n",
    "\n",
    "# CRPS_all_1d_variational__pred_acd\n",
    "# 0.566\n",
    "# 0.5663838763957928\n",
    "# [0.3699089026919278, 0.5456389456044942, 0.5288369965205645, 0.467088872976844, 0.6071105243396644, 0.4669126408712975, 0.5454408015065817, 0.6646724800371974, 0.7106914650393886, 0.7329569054917766, 0.7547014641790157, 0.5445754088303602, 0.3951076282143467, 0.6309626766407217, 0.3368437030718154, 0.760692606316687]\n",
    "\n",
    "# CRPS_long_1d_variational__pred_acd\n",
    "# 0.861\n",
    "# 0.8611935667281285\n",
    "# [0.7810179689556953, 1.041000808315432, 1.082464190660267, 0.5402912989811199]\n",
    "\n",
    "# CRPS_DE_7d_variational__pred_acd\n",
    "# 0.49\n",
    "# 0.49044659597141077\n",
    "# [0.3761198236282869, 0.5797862348809066, 0.5362974356861732, 0.4695828896902763]\n",
    "\n",
    "# CRPS_all_7d_variational__pred_acd\n",
    "# 0.565\n",
    "# 0.5650587201535673\n",
    "# [0.3446236714608004, 0.46056006859350906, 0.5493281859804754, 0.44159893321915855, 0.6468134491380814, 0.45009462780833703, 0.5544616516298121, 0.7330209868063148, 0.6540162230614014, 0.7091008822380911, 0.7583443391820309, 0.5757695420823647, 0.4039345901241161, 0.6254580531806951, 0.3333084948718233, 0.800505823080066]\n",
    "\n",
    "# CRPS_long_7d_variational__pred_acd\n",
    "# 0.741\n",
    "# 0.740699281792291\n",
    "# [0.541224907977652, 0.9176433443885397, 0.9667757193629152, 0.5371531554400573]\n",
    "\n",
    "# CRPS_DE_1d_gcn__pred_rnd\n",
    "# 0.488\n",
    "# 0.4881817688063123\n",
    "# [0.4411355017377492, 0.5102402630596765, 0.5225306267992204, 0.478820683628603]\n",
    "\n",
    "# CRPS_all_1d_gcn__pred_rnd\n",
    "# 0.256\n",
    "# 0.25626502984853883\n",
    "# [0.22856092273036793, 0.2454135460379611, 0.2553122858712047, 0.2864366575501139, 0.25235180702655746, 0.22672746094719165, 0.25899689320802427, 0.28796210292990665, 0.27180307191907416, 0.2374007656741792, 0.28795060043756054, 0.2897284832955482, 0.23165669357693286, 0.2214875028395956, 0.2198961982688774, 0.2985554852635261]\n",
    "\n",
    "# CRPS_long_1d_gcn__pred_rnd\n",
    "# 0.842\n",
    "# 0.841781189055082\n",
    "# [0.7677538962425753, 1.042963313078347, 1.0415018139944971, 0.5149057329049085]\n",
    "\n",
    "# CRPS_DE_7d_gcn__pred_rnd\n",
    "# 0.433\n",
    "# 0.4327228001542079\n",
    "# [0.3671019035482409, 0.5934939089258144, 0.41764037486858746, 0.35265501327418874]\n",
    "\n",
    "# CRPS_all_7d_gcn__pred_rnd\n",
    "# 0.546\n",
    "# 0.5459355399857604\n",
    "# [0.3979816100591825, 0.5602444384186486, 0.5101960696795215, 0.4576127943051778, 0.5840693260143973, 0.48055165446154724, 0.5215733205788645, 0.6293730810913203, 0.4993381385708673, 0.7425839126285428, 0.687869943233202, 0.5241247112063406, 0.4418178122255511, 0.6406483604554642, 0.38592170234643325, 0.6710617644971046]\n",
    "\n",
    "# CRPS_long_7d_gcn__pred_rnd\n",
    "# 0.751\n",
    "# 0.750948587042794\n",
    "# [0.5194662316405595, 1.0047646889094994, 0.9608501981184421, 0.5187132295026751]\n",
    "\n",
    "# CRPS_DE_1d_variational__pred_rnd\n",
    "# 0.426\n",
    "# 0.4261205946430343\n",
    "# [0.3229173323257023, 0.4967906653397833, 0.4809249129007529, 0.4038494680058988]\n",
    "\n",
    "# CRPS_all_1d_variational__pred_rnd\n",
    "# 0.709\n",
    "# 0.7091127738198684\n",
    "# [0.6541982643096058, 0.5839661914616603, 0.7524275660062472, 0.6775260999391771, 0.7611436563780376, 0.5336338938114163, 0.767842046210852, 0.7556879935205449, 0.7071310590316026, 0.7214807919889832, 0.8750291539944461, 0.7272608008965216, 0.6799212100328011, 0.6924292044807281, 0.6230206175646077, 0.8331058314906628]\n",
    "\n",
    "# CRPS_long_1d_variational__pred_rnd\n",
    "# 0.775\n",
    "# 0.7750263547515867\n",
    "# [0.6469821205765358, 1.0249318551935132, 1.0164266353995552, 0.4117648078367428]\n",
    "\n",
    "# CRPS_DE_7d_variational__pred_rnd\n",
    "# 0.382\n",
    "# 0.38203754957458547\n",
    "# [0.26446339023424964, 0.5535747329109544, 0.40160323696371203, 0.30850883818942576]\n",
    "\n",
    "# CRPS_all_7d_variational__pred_rnd\n",
    "# 0.462\n",
    "# 0.4624774034323944\n",
    "# [0.35082377317227825, 0.44289246077251543, 0.4511911563874712, 0.411684364292732, 0.47780440169635713, 0.4087154268326805, 0.4585611891623192, 0.5517892162567205, 0.4216790306437555, 0.5789270917926737, 0.5975868479914535, 0.41369176949139885, 0.3499574056303219, 0.5455121904063988, 0.35691732842752316, 0.5819048019617103]\n",
    "\n",
    "# CRPS_long_7d_variational__pred_rnd\n",
    "# 0.593\n",
    "# 0.5925785078270781\n",
    "# [0.40206844099208633, 0.8146595966211038, 0.7140200363575008, 0.43956595733762155]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_energy_long_1dvariational\n",
      "_pred_acd\n",
      "MAE:  0.293\n",
      "MSE:  0.181\n",
      "skill:  -3.197\n",
      "_pred_rnd\n",
      "MAE:  0.319\n",
      "MSE:  0.217\n",
      "skill:  -4.031\n",
      "_pred_mlr\n",
      "MAE:  0.14\n",
      "MSE:  0.043\n",
      "skill:  0.0\n",
      "_pred_rnn\n",
      "MAE:  0.255\n",
      "MSE:  0.143\n",
      "skill:  -2.305\n"
     ]
    }
   ],
   "source": [
    "print(suffix+version)\n",
    "cols_error = [col for col in cols_ts for var in vars_of_interest if var in col]\n",
    "for predname in ['_pred_acd', '_pred_rnd', '_pred_mlr', '_pred_rnn']:\n",
    "    print(predname)\n",
    "    mse = calc_MSE(dataframe, cols_error, pred_name=predname)\n",
    "    mae =  calc_MAE(dataframe, cols_error, pred_name=predname)\n",
    "    skill = calc_skill(dataframe, cols_error, pred_name=predname)\n",
    "    print('MAE: ', np.round(mae, 3))\n",
    "    print('MSE: ', np.round(mse, 3))\n",
    "    print('skill: ', np.round(skill, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# _energy_long_1dgcn\n",
    "# _pred_acd\n",
    "# MAE:  0.248\n",
    "# MSE:  0.136\n",
    "# skill:  -2.154\n",
    "# _pred_rnd\n",
    "# MAE:  0.313\n",
    "# MSE:  0.204\n",
    "# skill:  -3.726\n",
    "# _pred_mlr\n",
    "# MAE:  0.14\n",
    "# MSE:  0.043\n",
    "# skill:  0.0\n",
    "# _pred_rnn\n",
    "# MAE:  0.255\n",
    "# MSE:  0.143\n",
    "# skill:  -2.305\n",
    "\n",
    "\n",
    "# _energy_all_1dgcn\n",
    "# _pred_acd\n",
    "# MAE:  0.141\n",
    "# MSE:  0.047\n",
    "# skill:  0.684\n",
    "# _pred_rnd\n",
    "# MAE:  0.217\n",
    "# MSE:  0.105\n",
    "# skill:  0.296\n",
    "# _pred_mlr\n",
    "# MAE:  0.288\n",
    "# MSE:  0.149\n",
    "# skill:  0.0\n",
    "# _pred_rnn\n",
    "# MAE:  0.087\n",
    "# MSE:  0.018\n",
    "# skill:  0.877\n",
    "\n",
    "# _energy_all_7dgcn\n",
    "# _pred_acd\n",
    "# MAE:  0.386\n",
    "# MSE:  0.257\n",
    "# skill:  -0.736\n",
    "# _pred_rnd\n",
    "# MAE:  0.341\n",
    "# MSE:  0.208\n",
    "# skill:  -0.406\n",
    "# _pred_mlr\n",
    "# MAE:  0.288\n",
    "# MSE:  0.148\n",
    "# skill:  0.0\n",
    "# _pred_rnn\n",
    "# MAE:  0.087\n",
    "# MSE:  0.018\n",
    "# skill:  0.877\n",
    "\n",
    "# _energy_long_7dgcn\n",
    "# _pred_acd\n",
    "# MAE:  0.119\n",
    "# MSE:  0.053\n",
    "# skill:  -0.241\n",
    "# _pred_rnd\n",
    "# MAE:  0.196\n",
    "# MSE:  0.106\n",
    "# skill:  -1.474\n",
    "# _pred_mlr\n",
    "# MAE:  0.14\n",
    "# MSE:  0.043\n",
    "# skill:  0.0\n",
    "# _pred_rnn\n",
    "# MAE:  0.255\n",
    "# MSE:  0.142\n",
    "# skill:  -2.326\n",
    "\n",
    "# _energy_DE_1dvariational\n",
    "# _pred_acd\n",
    "# MAE:  0.12\n",
    "# MSE:  0.033\n",
    "# skill:  -1.122\n",
    "# _pred_rnd\n",
    "# MAE:  0.275\n",
    "# MSE:  0.185\n",
    "# skill:  -10.903\n",
    "# _pred_mlr\n",
    "# MAE:  0.089\n",
    "# MSE:  0.016\n",
    "# skill:  0.0\n",
    "# _pred_rnn\n",
    "# MAE:  0.085\n",
    "# MSE:  0.015\n",
    "# skill:  0.023\n",
    "\n",
    "# _energy_all_1dvariational\n",
    "# _pred_acd\n",
    "# MAE:  0.133\n",
    "# MSE:  0.04\n",
    "# skill:  0.73\n",
    "# _pred_rnd\n",
    "# MAE:  0.429\n",
    "# MSE:  0.33\n",
    "# skill:  -1.218\n",
    "# _pred_mlr\n",
    "# MAE:  0.288\n",
    "# MSE:  0.149\n",
    "# skill:  0.0\n",
    "# _pred_rnn\n",
    "# MAE:  0.087\n",
    "# MSE:  0.018\n",
    "# skill:  0.877\n",
    "\n",
    "# _energy_long_1dvariational\n",
    "# _pred_acd\n",
    "# MAE:  0.293\n",
    "# MSE:  0.181\n",
    "# skill:  -3.197\n",
    "# _pred_rnd\n",
    "# MAE:  0.319\n",
    "# MSE:  0.217\n",
    "# skill:  -4.031\n",
    "# _pred_mlr\n",
    "# MAE:  0.14\n",
    "# MSE:  0.043\n",
    "# skill:  0.0\n",
    "# _pred_rnn\n",
    "# MAE:  0.255\n",
    "# MSE:  0.143\n",
    "# skill:  -2.305\n",
    "\n",
    "# _energy_DE_7dvariational\n",
    "# _pred_acd\n",
    "# MAE:  0.155\n",
    "# MSE:  0.047\n",
    "# skill:  -2.064\n",
    "# _pred_rnd\n",
    "# MAE:  0.328\n",
    "# MSE:  0.226\n",
    "# skill:  -13.61\n",
    "# _pred_mlr\n",
    "# MAE:  0.089\n",
    "# MSE:  0.015\n",
    "# skill:  0.0\n",
    "# _pred_rnn\n",
    "# MAE:  0.085\n",
    "# MSE:  0.015\n",
    "# skill:  0.018\n",
    "\n",
    "# _energy_all_7dvariational\n",
    "# _pred_acd\n",
    "# MAE:  0.166\n",
    "# MSE:  0.057\n",
    "# skill:  0.614\n",
    "# _pred_rnd\n",
    "# MAE:  0.397\n",
    "# MSE:  0.274\n",
    "# skill:  -0.853\n",
    "# _pred_mlr\n",
    "# MAE:  0.288\n",
    "# MSE:  0.148\n",
    "# skill:  0.0\n",
    "# _pred_rnn\n",
    "# MAE:  0.087\n",
    "# MSE:  0.018\n",
    "# skill:  0.877\n",
    "\n",
    "# _energy_long_7dvariational\n",
    "# _pred_acd\n",
    "# MAE:  0.115\n",
    "# MSE:  0.039\n",
    "# skill:  0.098\n",
    "# _pred_rnd\n",
    "# MAE:  0.212\n",
    "# MSE:  0.114\n",
    "# skill:  -1.667\n",
    "# _pred_mlr\n",
    "# MAE:  0.14\n",
    "# MSE:  0.043\n",
    "# skill:  0.0\n",
    "# _pred_rnn\n",
    "# MAE:  0.255\n",
    "# MSE:  0.142\n",
    "# skill:  -2.326\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Plot Time Series, Predictions and Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if create_country_dfs:\n",
    "    suffixes_DE   = [\"_energy_DE_1d_gcn\", \"_energy_DE_7d_gcn\", \"_energy_DE_1d_variational\", \"_energy_DE_7d_variational\"]\n",
    "    suffixes_all  = [\"_energy_all_1d_gcn\", \"_energy_all_7d_gcn\", \"_energy_all_1d_variational\", \"_energy_all_7d_variational\"] \n",
    "    suffixes_long = [\"_energy_long_1d_gcn\", \"_energy_long_7d_gcn\", \"_energy_long_1d_variational\", \"_energy_long_7d_variational\"]\n",
    "\n",
    "    if load_allpreds:\n",
    "        dfs_DE = {}\n",
    "        dfs_all = {}\n",
    "        dfs_long = {}\n",
    "        for s in suffixes_DE:\n",
    "            df_norm = pd.read_csv('data/predictions' +s+ '.csv', parse_dates=['utc_timestamp'])\n",
    "            part = '_gcn'\n",
    "            if 'variational' in s:\n",
    "                part='_variational'\n",
    "            df_pred = denormalize_columns(df_norm, suffix=s.partition(part)[0])\n",
    "            dfs_DE[s] = df_pred\n",
    "        for s in suffixes_all:\n",
    "            df_norm = pd.read_csv('data/predictions' +s+ '.csv', parse_dates=['utc_timestamp'])\n",
    "            part = '_gcn'\n",
    "            if 'variational' in s:\n",
    "                part='_variational'\n",
    "            df_pred = denormalize_columns(df_norm, suffix=s.partition(part)[0])\n",
    "            dfs_all[s] = df_pred\n",
    "        for s in suffixes_long:\n",
    "            df_norm = pd.read_csv('data/predictions' +s+ '.csv', parse_dates=['utc_timestamp'])\n",
    "            part = '_gcn'\n",
    "            if 'variational' in s:\n",
    "                part='_variational'\n",
    "            df_pred = denormalize_columns(df_norm, suffix=s.partition(part)[0])\n",
    "            dfs_long[s] = df_pred\n",
    "\n",
    "    df_DE = dfs_DE['_energy_DE_1d_gcn']\n",
    "    acd_pred_cols = [col for col in df_DE.columns.values if '_pred_acd' in col]\n",
    "    acd_pred_cols_names = [col+'_G1' for col in df_DE.columns.values if '_pred_acd' in col]\n",
    "    name_dict = dict(zip(acd_pred_cols, acd_pred_cols_names))\n",
    "    df_DE = df_DE.rename(columns=name_dict)\n",
    "    for s in suffixes_DE[1:]:\n",
    "        df_DE2 = dfs_DE[s]\n",
    "        acd_pred_cols = [col for col in df_DE2.columns.values if '_pred_acd' in col]\n",
    "        for col in acd_pred_cols:\n",
    "            v = '_G'\n",
    "            d = '1'\n",
    "            if 'variational' in s:\n",
    "                v = '_V'\n",
    "            if '7d' in s:\n",
    "                d = '7'\n",
    "            df_DE[col+v+d] = df_DE2[col]  \n",
    "\n",
    "    df_all = dfs_all['_energy_all_1d_gcn']\n",
    "    acd_pred_cols = [col for col in df_all.columns.values if '_pred_acd' in col]\n",
    "    acd_pred_cols_names = [col+'_G1' for col in df_all.columns.values if '_pred_acd' in col]\n",
    "    name_dict = dict(zip(acd_pred_cols, acd_pred_cols_names))\n",
    "    df_all = df_all.rename(columns=name_dict)\n",
    "    for s in suffixes_all[1:]:\n",
    "        df_all2 = dfs_all[s]\n",
    "        acd_pred_cols = [col for col in df_all2.columns.values if '_pred_acd' in col]\n",
    "        for col in acd_pred_cols:\n",
    "            v = '_G'\n",
    "            d = '1'\n",
    "            if 'variational' in s:\n",
    "                v = '_V'\n",
    "            if '7d' in s:\n",
    "                d = '7'\n",
    "            df_all[col+v+d] = df_all2[col] \n",
    "\n",
    "    df_long = dfs_long['_energy_long_1d_gcn']\n",
    "    acd_pred_cols = [col for col in df_long.columns.values if '_pred_acd' in col]\n",
    "    acd_pred_cols_names = [col+'_G1' for col in df_long.columns.values if '_pred_acd' in col]\n",
    "    name_dict = dict(zip(acd_pred_cols, acd_pred_cols_names))\n",
    "    df_long = df_long.rename(columns=name_dict)\n",
    "    for s in suffixes_long[1:]:\n",
    "        df_long2 = dfs_long[s]\n",
    "        acd_pred_cols = [col for col in df_long2.columns.values if '_pred_acd' in col]\n",
    "        for col in acd_pred_cols:\n",
    "            v = '_G'\n",
    "            d = '1'\n",
    "            if 'variational' in s:\n",
    "                v = '_V'\n",
    "            if '7d' in s:\n",
    "                d = '7'\n",
    "            df_long[col+v+d] = df_long2[col]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if create_country_dfs:\n",
    "    df_DE.to_csv('data/df_DE.csv', index=False)\n",
    "    df_all.to_csv('data/df_all.csv', index=False)\n",
    "    df_long.to_csv('data/df_long.csv', index=False)\n",
    "                   \n",
    "if load_country_dfs:\n",
    "    df_DE = pd.read_csv('data/df_DE.csv', parse_dates=['utc_timestamp'])\n",
    "    df_all = pd.read_csv('data/df_all.csv', parse_dates=['utc_timestamp'])\n",
    "    df_long = pd.read_csv('data/df_long.csv', parse_dates=['utc_timestamp'])\n",
    "# display(df_DE)\n",
    "# display(df_all)\n",
    "# display(df_long)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### -------------------- plot data --------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.style.use('bmh')\n",
    "def plot_ts(df_plot, cols_to_plot, labels, \n",
    "            plot_pred=True, plot_mean=True, plot_dif=False, \n",
    "            datemin=[2015, 1, 1], datemax=[2020, 1, 1], \n",
    "            color=None, legend_color=None, pred_color=None,\n",
    "            bg_color=lightgray, \n",
    "            legend_alpha=0.8, legend_text_alpha = 1.0,\n",
    "            gray_share = 0.25,\n",
    "            face_color=None, alpha_ts=1, alpha_pred=1,\n",
    "            avg_color=None, avg_pred_color='white', \n",
    "            show_mean=False, time_unit='', do_set_fc=True,\n",
    "            fs=18, fig_width=20, subplot_height=1.5, \n",
    "            save_figure=False, plot_name=\"plot_ts\",\n",
    "            prefix='DE ', linebreak = '', title='',\n",
    "            annotate=False):\n",
    "    \n",
    "    nplots = len(cols_to_plot)\n",
    "    \n",
    "    if color is None:\n",
    "        color = cm.turbo(np.linspace(0, 1, nplots))[::-1]\n",
    "        if legend_color is not None:\n",
    "            color = [black for c in color]\n",
    "        \n",
    "    datemin = datetime.datetime(datemin[0], datemin[1], datemin[2], tzinfo=pytz.UTC)\n",
    "    datemax = datetime.datetime(datemax[0], datemax[1], datemax[2], tzinfo=pytz.UTC)\n",
    "\n",
    "    fig = plt.figure(figsize=(fig_width, subplot_height*nplots))\n",
    "    if do_set_fc:\n",
    "        ax.set_facecolor(color=bg_color)\n",
    "\n",
    "    for i, col in enumerate(cols_to_plot):\n",
    "        ax = plt.subplot(nplots, 1, i+1)\n",
    "        if annotate:\n",
    "            where = (0.05,0.9)\n",
    "            ax.annotate(labels[i][0], xy=where, xytext=where, xycoords='axes fraction',\n",
    "                        fontsize=fs, ha='left', va='bottom',\n",
    "                        color=white,\n",
    "                        bbox=dict(boxstyle='round', fc=(1-gray_share)*legend_color[i]+gray_share*gray),\n",
    "                       )\n",
    "        myFmt = mdates.DateFormatter('%m-%d')\n",
    "        ax.xaxis.set_major_formatter(myFmt)\n",
    "        if col+'_pred_acd_G1' in df_plot.columns:\n",
    "            ax.plot(df_plot[col+'_pred_acd_G1']\n",
    "                    , c=light_green\n",
    "                    , alpha = alpha_pred\n",
    "                    , linestyle='dashed'\n",
    "                    , label = 'ACD G1'\n",
    "                   )\n",
    "        if col+'_pred_acd_G7' in df_plot.columns:\n",
    "            ax.plot(df_plot[col+'_pred_acd_G7']\n",
    "                    , c=dark_green\n",
    "                    , alpha = alpha_pred\n",
    "                    , label = 'ACD G7'                \n",
    "                   )\n",
    "        if col+'_pred_acd_V1' in df_plot.columns:\n",
    "            ax.plot(df_plot[col+'_pred_acd_V1']\n",
    "                    , c=light_orange\n",
    "                    , alpha = alpha_pred\n",
    "                    , linestyle='dashed'\n",
    "                    , label = 'ACD V1'\n",
    "                   )\n",
    "        if col+'_pred_acd_V7' in df_plot.columns:\n",
    "            ax.plot(df_plot[col+'_pred_acd_V7']\n",
    "                    , c=dark_orange\n",
    "                    , alpha = alpha_pred\n",
    "                    , label = 'ACD V7'\n",
    "                   )\n",
    "        if col+'_pred_mlr' in df_plot.columns:\n",
    "            ax.plot(df_plot[col+'_pred_mlr']\n",
    "                    , c=light_blue\n",
    "                    , alpha = alpha_pred\n",
    "                    , label = 'MLR'\n",
    "                   )\n",
    "        if col+'_pred_rnn' in df_plot.columns:\n",
    "            ax.plot(df_plot[col+'_pred_rnn']\n",
    "                    , c=dark_blue\n",
    "                    , alpha = alpha_pred\n",
    "                    , linestyle='dashed'\n",
    "                    , label = 'LSTM'\n",
    "                   )\n",
    "        ax.plot(df_plot[col]\n",
    "                    , c=color[i]\n",
    "                    , alpha = alpha_ts\n",
    "                    , label='data'\n",
    "                   )\n",
    "\n",
    "        ax.set_xlim(datemin, datemax)\n",
    "        ax.set_ylabel(labels[i][1], fontsize=fs)\n",
    "        ax.tick_params(axis='both', which='major', labelsize=fs-6)\n",
    "        if any([var in col for var in ['load', 'solar_generation', 'wind_generation']]):\n",
    "            ticks_loc = ax.get_yticks()\n",
    "            ax.yaxis.set_major_locator(mticker.FixedLocator(ticks_loc))\n",
    "            if labels[i][1] == '[MW]':\n",
    "                ax.set_yticklabels(['{}'.format(int(tick/1000))+'k' if int(tick)>1000 else '{}'.format(int(tick)) for tick in ticks_loc])\n",
    "            elif labels[i][1] == '[GW]':\n",
    "                ax.set_yticklabels([str(int(tick)) for tick in ticks_loc/1000])\n",
    "\n",
    "        if i < nplots-1:\n",
    "            ax.xaxis.set_ticklabels([])\n",
    "        else:\n",
    "            ax.set_xlabel('date'+ time_unit, fontsize=fs)\n",
    "        leg = plt.legend(loc = \"upper right\", fontsize=fs-6,\n",
    "                         )\n",
    "        for text in leg.get_texts():\n",
    "            text.set_alpha(legend_text_alpha)\n",
    "    fig.suptitle(title, fontsize=fs+4, y=1)        \n",
    "    fig.align_ylabels()\n",
    "    fig.tight_layout()\n",
    "    plt.subplots_adjust(hspace=0.1)\n",
    "\n",
    "    factor=8\n",
    "    if save_figure:\n",
    "        dpi = fig.get_dpi()\n",
    "        plt.savefig(\"plots/\"+plot_name+\".jpg\", bbox_inches='tight', dpi=dpi*factor)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_plot = df_DE.set_index('utc_timestamp')\n",
    "cols_to_plot = cols_of_interest_DE\n",
    "labels = [labels_vars_full[col] for col in cols_to_plot]\n",
    "datasetID = '_DE'\n",
    "title = 'Single country forecasts'\n",
    "\n",
    "# df_plot = df_all.set_index('utc_timestamp')\n",
    "\n",
    "# # cols_to_plot = cols_of_interest_DE\n",
    "# # country='_DE'\n",
    "# # title = 'Multiple countries forecasts for DE'\n",
    "\n",
    "# # cols_to_plot = cols_of_interest_FR\n",
    "# # country='_FR'\n",
    "# # title = 'Multiple countries forecasts for FR'\n",
    "\n",
    "# cols_to_plot = cols_of_interest_CH\n",
    "# country='_CH'\n",
    "# title = 'Multiple countries forecasts for CH'\n",
    "\n",
    "# # cols_to_plot = cols_of_interest_GB\n",
    "# # country='_GB'\n",
    "# # title = 'Multiple countries forecasts for GB'\n",
    "\n",
    "# labels = [labels_vars_full[col] for col in cols_to_plot]\n",
    "# datasetID = '_all'+country\n",
    "\n",
    "\n",
    "# df_plot = df_long[df_long['ID']==0.0].set_index('utc_timestamp')\n",
    "# cols_to_plot = vars_of_interest\n",
    "# labels = [labels_vars_virtual[col] for col in cols_to_plot]\n",
    "# datasetID = '_long'\n",
    "# title = 'Virtual country forecast for DE'\n",
    "\n",
    "# df_plot = df_long[df_long['ID']==1.0].set_index('utc_timestamp')\n",
    "# cols_to_plot = vars_of_interest\n",
    "# labels = [labels_vars_virtual[col] for col in cols_to_plot]\n",
    "# datasetID = '_long'\n",
    "# title = 'Virtual country forecast for FR'\n",
    "\n",
    "# df_plot = df_long[df_long['ID']==2.0].set_index('utc_timestamp')\n",
    "# cols_to_plot = vars_of_interest\n",
    "# labels = [labels_vars_virtual[col] for col in cols_to_plot]\n",
    "# datasetID = '_long'\n",
    "# title = 'Virtual country forecast for CH'\n",
    "\n",
    "# df_plot = df_long[df_long['ID']==3.0].set_index('utc_timestamp')\n",
    "# cols_to_plot = vars_of_interest\n",
    "# labels = [labels_vars_virtual[col] for col in cols_to_plot]\n",
    "# datasetID = '_long'\n",
    "# title = 'Virtual country forecast for GB'\n",
    "\n",
    "\n",
    "color = cm.turbo(np.linspace(0, 1, len(vars_of_interest+vars_weather)))[::-1]\n",
    "color = list(color)#*len(prefixes)\n",
    "        \n",
    "bg_color_error=white\n",
    "\n",
    "plot_name_base = \"pred\"\n",
    "# datemin=[2015, 1, 1]\n",
    "# datemax=[2020, 1, 1]\n",
    "datemin=[2019, 5, 1]\n",
    "datemax=[2019, 6, 1]\n",
    "# datemin=[2019, 1, 1]\n",
    "# datemax=[2020, 1, 1]\n",
    "\n",
    "save_figure=True\n",
    "# save_figure=False\n",
    "plot_name=plot_name_base+datasetID\n",
    "if show_figure:\n",
    "    plot_ts(df_plot, cols_to_plot=cols_to_plot, labels=labels, \n",
    "            color=None, \n",
    "            legend_color = color,\n",
    "            legend_alpha = 1,\n",
    "            legend_text_alpha = 1,\n",
    "            gray_share=0.25,#0.25,\n",
    "            plot_pred=True, \n",
    "            datemin=datemin, datemax=datemax, \n",
    "            bg_color=lightgray, \n",
    "            alpha_ts=1, \n",
    "            alpha_pred=0.95,\n",
    "            avg_color=black,#darkdimgray,\n",
    "            save_figure=save_figure, plot_name=plot_name,\n",
    "            show_mean=True, time_unit='', do_set_fc=False,\n",
    "            fs=22, fig_width=22, subplot_height=5,\n",
    "            annotate=True,\n",
    "            title=title\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### -------------------- plot graphs --------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "save_figure=True\n",
    "# save_figure=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def show_graph_with_labels(adjacency_matrix, graph_labels, \n",
    "                           node_colors=None, edge_colors_dict=None,\n",
    "                          save_figure = True, plotname='',\n",
    "                          title=''):\n",
    "\n",
    "    rows, cols = np.where(adjacency_matrix >= 0.5)\n",
    "    edges_list = list(zip(rows.tolist(), cols.tolist()))\n",
    "\n",
    "    edges = zip(rows.tolist(), cols.tolist())\n",
    "    num_edges = len(edges_list)\n",
    "\n",
    "    edge_weights = np.array([adjacency_matrix[rows[i],cols[i]] for i in range(num_edges)])\n",
    "    edge_colors = [edge_colors_dict[edge[0]] for edge in edges_list]\n",
    "    \n",
    "    edges = zip(rows.tolist(), cols.tolist())\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(5,5))\n",
    "    \n",
    "    \n",
    "    G = nx.DiGraph()\n",
    "    G.add_nodes_from(list(range(len(graph_labels))))\n",
    "    G.add_edges_from(edges)\n",
    "    nx.draw_circular(G, \n",
    "                     connectionstyle='arc3, rad = 0.05',\n",
    "                     node_size=500, \n",
    "                     labels=graph_labels, \n",
    "                     with_labels=True, \n",
    "                     arrows=True, \n",
    "                     node_color=node_colors,\n",
    "                     font_color = white,\n",
    "                     font_size=14,\n",
    "                     linewidths=5,\n",
    "                     width=edge_weights*3,\n",
    "                     # edge_labels=edge_weights,\n",
    "                     edge_color=edge_colors,\n",
    "                     arrowsize=14)\n",
    "    country = 'DE'\n",
    "    c= 'single country'\n",
    "    if 'all' in plotname:\n",
    "        country = 'all'\n",
    "        c='multiple countries'\n",
    "    elif 'long' in plotname:\n",
    "        country='long'\n",
    "        c='virtual country'\n",
    "    num_days='1'\n",
    "    if '7' in plotname:\n",
    "        num_days='7'\n",
    "    version = 'G'\n",
    "    if 'variational' in plotname:\n",
    "        version='V'\n",
    "    \n",
    "    ax.set_title('ACD '+version+num_days+' '+c, fontsize=14)    \n",
    "        \n",
    "    factor=8\n",
    "    if save_figure:\n",
    "        dpi = fig.get_dpi()\n",
    "        plt.savefig(\"plots/Graph_\"+country+\"_\"+suffix+\"_\"+version+\".jpg\", bbox_inches='tight', dpi=dpi*factor)\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "file_name = 'data\\\\adjacency_'+version+suffix+\".npy\"\n",
    "adjacency_matrices = np.load(file_name,allow_pickle='TRUE')\n",
    "# print(adjacency_matrices.shape)\n",
    "\n",
    "gray_share=0.25\n",
    "graph_labels={0:'LO', 1:'SO', 2:'WI', 3:'PR', 4:'TE', 5:'R1', 6:'R2'}\n",
    "\n",
    "node_colors = cm.turbo(np.linspace(0, 1, len(graph_labels)))[::-1]\n",
    "node_colors = [((1-gray_share)*color+gray_share*gray) for color in node_colors]\n",
    "\n",
    "edge_colors = {}\n",
    "for key in list(graph_labels.keys()):\n",
    "    edge_colors[key] = node_colors[key]\n",
    "    \n",
    "avg_adj = np.mean(adjacency_matrices, axis=0)\n",
    "\n",
    "#comment out for multiple country version and run following two cells\n",
    "show_graph_with_labels(avg_adj, graph_labels, \n",
    "                       node_colors, edge_colors,\n",
    "                       plotname=suffix+'_'+version)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# variant for multiple countries\n",
    "def show_graph_with_labels2(adjacency_matrix, graph_labels, \n",
    "                           node_colors=None, edge_colors_dict=None,\n",
    "                          save_figure = True, plotname='',\n",
    "                          title=''):\n",
    "\n",
    "    rows, cols = np.where(adjacency_matrix >= 0.5)\n",
    "    edges_list = list(zip(rows.tolist(), cols.tolist()))\n",
    "\n",
    "    edges = zip(rows.tolist(), cols.tolist())\n",
    "    num_edges = len(edges_list)\n",
    "\n",
    "    edge_weights = np.array([adjacency_matrix[rows[i],cols[i]] for i in range(num_edges)])\n",
    "    edge_colors = [edge_colors_dict[edge[0]] for edge in edges_list]\n",
    "    \n",
    "    edges = zip(rows.tolist(), cols.tolist())\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(25,25))\n",
    "    \n",
    "    \n",
    "    G = nx.DiGraph()\n",
    "    G.add_nodes_from(list(range(len(graph_labels))))\n",
    "    G.add_edges_from(edges)\n",
    "    nx.draw_circular(G, \n",
    "                     connectionstyle='arc3, rad = 0.05',\n",
    "                     node_size=1800, \n",
    "                     labels=graph_labels, \n",
    "                     with_labels=True, \n",
    "                     arrows=True, \n",
    "                     node_color=node_colors,\n",
    "                     font_color = white,\n",
    "                     font_size=14,\n",
    "                     linewidths=5,\n",
    "                     width=edge_weights*3,\n",
    "                     # edge_labels=edge_weights,\n",
    "                     edge_color=edge_colors,\n",
    "                     arrowsize=14)\n",
    "    country = 'DE'\n",
    "    c= 'single country'\n",
    "    if 'all' in plotname:\n",
    "        country = 'all'\n",
    "        c='multiple countries'\n",
    "    elif 'long' in plotname:\n",
    "        country='long'\n",
    "        c='virtual country'\n",
    "    num_days='1'\n",
    "    if '7' in plotname:\n",
    "        num_days='7'\n",
    "    version = 'G'\n",
    "    if 'variational' in plotname:\n",
    "        version='V'\n",
    "    \n",
    "    ax.set_title('ACD '+version+num_days+' '+c, fontsize=14)    \n",
    "        \n",
    "    factor=8\n",
    "    if save_figure:\n",
    "        dpi = fig.get_dpi()\n",
    "        plt.savefig(\"plots/Graph_\"+country+\"_\"+suffix+\"_\"+version+\".jpg\", bbox_inches='tight', dpi=dpi*factor)\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "graph_labels={0:'DE LO', 1:'DE SO', 2:'DE WI', 3:'DE PR', 4:'DE TE', 5:'DE R1', 6:'DE R2',\n",
    "               7:'FR LO', 8:'FR SO', 9:'FR WI', 10:'FR PR', 11:'FR TE', 12:'FR R1', 13:'FR R2',\n",
    "              14:'CH LO', 15:'CH SO', 16:'CH WI', 17:'CH PR', 18:'CH TE', 19:'CH R1', 20:'CH R2',\n",
    "              21:'GB LO', 22:'GB SO', 23:'GB WI', 24:'GB PR', 25:'GB TE', 26:'GB R1', 27:'GB R2',}\n",
    "\n",
    "node_colors2 = node_colors*4\n",
    "edge_colors = {}\n",
    "for key in list(graph_labels.keys()):\n",
    "    edge_colors[key] = node_colors2[key%7]\n",
    "\n",
    "# comment in to plot multiple country graphs\n",
    "# show_graph_with_labels2(avg_adj, graph_labels, \n",
    "#                        node_colors2, edge_colors,\n",
    "#                        plotname=suffix+'_'+version)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
